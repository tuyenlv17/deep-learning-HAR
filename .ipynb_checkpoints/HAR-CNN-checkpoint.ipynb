{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAR CNN training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_score, \\\n",
    "    recall_score, confusion_matrix, classification_report, \\\n",
    "    accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utils/utilities.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label_vn = [u\"Cổ tay\",u\"Cổ chân\",u\"Bả vai\",u\"Xoay người\",u\"Xoay đầu gối\",u\"Đi bộ\",u\"Chạy\",u\"Đá bóng\",u\"Đạp\",u\"Đánh răng\",u\"Rửa tay\",u\"Lau bàn\",u\"Quét nhà\",u\"Nạo\",u\"Thái\",u\"Trộn\",u\"Lên cầu thang\",u\"Xuống cầu thang\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_sensor_acc\n",
      "x_watch_acc\n",
      "x_watch_gyr\n",
      "y_sensor_acc\n",
      "y_watch_acc\n",
      "y_watch_gyr\n",
      "z_sensor_acc\n",
      "z_watch_acc\n",
      "z_watch_gyr\n",
      "x_sensor_acc\n",
      "x_watch_acc\n",
      "x_watch_gyr\n",
      "y_sensor_acc\n",
      "y_watch_acc\n",
      "y_watch_gyr\n",
      "z_sensor_acc\n",
      "z_watch_acc\n",
      "z_watch_gyr\n"
     ]
    }
   ],
   "source": [
    "rootDatasetDir = \"./datasets/PTIT/normalized\"\n",
    "X_train, labels_train, list_ch_train = read_data(data_path=\"./datasets/PTIT/normalized\", split=\"train\") # train\n",
    "X_test, labels_test, list_ch_test = read_data(data_path=rootDatasetDir, split=\"test\") # test\n",
    "assert list_ch_train == list_ch_test, \"Mistmatch in channels!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize?\n",
    "X_train, X_test = standardize(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_vld, lab_tr, lab_vld = train_test_split(X_train, labels_train, \n",
    "                                                stratify = labels_train, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = one_hot(lab_tr)\n",
    "y_vld = one_hot(lab_vld)\n",
    "y_test = one_hot(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_channels 9\n"
     ]
    }
   ],
   "source": [
    "batch_size = 600       # Batch size\n",
    "seq_len = WINDOWN_SIZE          # Number of steps or window size\n",
    "learning_rate = 0.0001\n",
    "epochs = 4000\n",
    "\n",
    "n_classes = NUM_CLASS\n",
    "n_channels = NUM_CHANNEL\n",
    "print \"n_channels %d\" % n_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the graph\n",
    "Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "# Construct placeholders\n",
    "with graph.as_default():\n",
    "    inputs_ = tf.placeholder(tf.float32, [None, seq_len, n_channels], name = 'inputs')\n",
    "    labels_ = tf.placeholder(tf.float32, [None, n_classes], name = 'labels')\n",
    "    keep_prob_ = tf.placeholder(tf.float32, name = 'keep')\n",
    "    learning_rate_ = tf.placeholder(tf.float32, name = 'learning_rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Convolutional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    # (batch, 128, 9) --> (batch, 64, 18)\n",
    "    conv1 = tf.layers.conv1d(inputs=inputs_, filters=18, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_1 = tf.layers.max_pooling1d(inputs=conv1, pool_size=2, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 64, 18) --> (batch, 32, 36)\n",
    "    conv2 = tf.layers.conv1d(inputs=max_pool_1, filters=36, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_2 = tf.layers.max_pooling1d(inputs=conv2, pool_size=2, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 32, 36) --> (batch, 16, 72)\n",
    "    conv3 = tf.layers.conv1d(inputs=max_pool_2, filters=72, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_3 = tf.layers.max_pooling1d(inputs=conv3, pool_size=2, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 16, 72) --> (batch, 8, 144)\n",
    "    conv4 = tf.layers.conv1d(inputs=max_pool_3, filters=144, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_4 = tf.layers.max_pooling1d(inputs=conv4, pool_size=2, strides=2, padding='same')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, flatten and pass to the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    # Flatten and add dropout\n",
    "    flat = tf.reshape(max_pool_4, (-1, 8*144))\n",
    "    flat = tf.nn.dropout(flat, keep_prob=keep_prob_)\n",
    "    \n",
    "    # Predictions\n",
    "    logits = tf.layers.dense(flat, n_classes)\n",
    "    \n",
    "    # Cost function and optimizer\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels_))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate_).minimize(cost)\n",
    "    \n",
    "    # Accuracy\n",
    "    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (os.path.exists('checkpoints-cnn') == False):\n",
    "    !mkdir checkpoints-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0/1000', 'Iteration: 5', 'Train loss: 2.931217', 'Train acc: 0.041667')\n",
      "('Epoch: 1/1000', 'Iteration: 10', 'Train loss: 2.894500', 'Train acc: 0.063333')\n",
      "('Epoch: 1/1000', 'Iteration: 10', 'Validation loss: 2.842135', 'Validation acc: 0.073333')\n",
      "('Epoch: 2/1000', 'Iteration: 15', 'Train loss: 2.859332', 'Train acc: 0.071667')\n",
      "('Epoch: 3/1000', 'Iteration: 20', 'Train loss: 2.820496', 'Train acc: 0.070000')\n",
      "('Epoch: 3/1000', 'Iteration: 20', 'Validation loss: 2.785660', 'Validation acc: 0.081667')\n",
      "('Epoch: 4/1000', 'Iteration: 25', 'Train loss: 2.805601', 'Train acc: 0.091667')\n",
      "('Epoch: 5/1000', 'Iteration: 30', 'Train loss: 2.803388', 'Train acc: 0.081667')\n",
      "('Epoch: 5/1000', 'Iteration: 30', 'Validation loss: 2.743469', 'Validation acc: 0.081667')\n",
      "('Epoch: 6/1000', 'Iteration: 35', 'Train loss: 2.776217', 'Train acc: 0.076667')\n",
      "('Epoch: 7/1000', 'Iteration: 40', 'Train loss: 2.757503', 'Train acc: 0.095000')\n",
      "('Epoch: 7/1000', 'Iteration: 40', 'Validation loss: 2.707323', 'Validation acc: 0.086667')\n",
      "('Epoch: 8/1000', 'Iteration: 45', 'Train loss: 2.730123', 'Train acc: 0.110000')\n",
      "('Epoch: 9/1000', 'Iteration: 50', 'Train loss: 2.728611', 'Train acc: 0.115000')\n",
      "('Epoch: 9/1000', 'Iteration: 50', 'Validation loss: 2.672473', 'Validation acc: 0.091667')\n",
      "('Epoch: 10/1000', 'Iteration: 55', 'Train loss: 2.721456', 'Train acc: 0.098333')\n",
      "('Epoch: 11/1000', 'Iteration: 60', 'Train loss: 2.698423', 'Train acc: 0.113333')\n",
      "('Epoch: 11/1000', 'Iteration: 60', 'Validation loss: 2.636408', 'Validation acc: 0.108333')\n",
      "('Epoch: 12/1000', 'Iteration: 65', 'Train loss: 2.686043', 'Train acc: 0.125000')\n",
      "('Epoch: 13/1000', 'Iteration: 70', 'Train loss: 2.651973', 'Train acc: 0.131667')\n",
      "('Epoch: 13/1000', 'Iteration: 70', 'Validation loss: 2.597398', 'Validation acc: 0.130000')\n",
      "('Epoch: 14/1000', 'Iteration: 75', 'Train loss: 2.632623', 'Train acc: 0.118333')\n",
      "('Epoch: 15/1000', 'Iteration: 80', 'Train loss: 2.629111', 'Train acc: 0.136667')\n",
      "('Epoch: 15/1000', 'Iteration: 80', 'Validation loss: 2.554272', 'Validation acc: 0.145000')\n",
      "('Epoch: 16/1000', 'Iteration: 85', 'Train loss: 2.592882', 'Train acc: 0.146667')\n",
      "('Epoch: 17/1000', 'Iteration: 90', 'Train loss: 2.562886', 'Train acc: 0.166667')\n",
      "('Epoch: 17/1000', 'Iteration: 90', 'Validation loss: 2.507142', 'Validation acc: 0.163333')\n",
      "('Epoch: 18/1000', 'Iteration: 95', 'Train loss: 2.566685', 'Train acc: 0.156667')\n",
      "('Epoch: 19/1000', 'Iteration: 100', 'Train loss: 2.519991', 'Train acc: 0.158333')\n",
      "('Epoch: 19/1000', 'Iteration: 100', 'Validation loss: 2.456548', 'Validation acc: 0.178333')\n",
      "('Epoch: 20/1000', 'Iteration: 105', 'Train loss: 2.535388', 'Train acc: 0.155000')\n",
      "('Epoch: 21/1000', 'Iteration: 110', 'Train loss: 2.484279', 'Train acc: 0.180000')\n",
      "('Epoch: 21/1000', 'Iteration: 110', 'Validation loss: 2.403682', 'Validation acc: 0.193333')\n",
      "('Epoch: 22/1000', 'Iteration: 115', 'Train loss: 2.440036', 'Train acc: 0.218333')\n",
      "('Epoch: 23/1000', 'Iteration: 120', 'Train loss: 2.422331', 'Train acc: 0.193333')\n",
      "('Epoch: 23/1000', 'Iteration: 120', 'Validation loss: 2.348590', 'Validation acc: 0.211667')\n",
      "('Epoch: 24/1000', 'Iteration: 125', 'Train loss: 2.420006', 'Train acc: 0.205000')\n",
      "('Epoch: 25/1000', 'Iteration: 130', 'Train loss: 2.372050', 'Train acc: 0.230000')\n",
      "('Epoch: 25/1000', 'Iteration: 130', 'Validation loss: 2.292175', 'Validation acc: 0.238333')\n",
      "('Epoch: 26/1000', 'Iteration: 135', 'Train loss: 2.365212', 'Train acc: 0.215000')\n",
      "('Epoch: 27/1000', 'Iteration: 140', 'Train loss: 2.341104', 'Train acc: 0.223333')\n",
      "('Epoch: 27/1000', 'Iteration: 140', 'Validation loss: 2.234465', 'Validation acc: 0.275000')\n",
      "('Epoch: 28/1000', 'Iteration: 145', 'Train loss: 2.310854', 'Train acc: 0.265000')\n",
      "('Epoch: 29/1000', 'Iteration: 150', 'Train loss: 2.265374', 'Train acc: 0.283333')\n",
      "('Epoch: 29/1000', 'Iteration: 150', 'Validation loss: 2.176257', 'Validation acc: 0.308333')\n",
      "('Epoch: 30/1000', 'Iteration: 155', 'Train loss: 2.251348', 'Train acc: 0.263333')\n",
      "('Epoch: 31/1000', 'Iteration: 160', 'Train loss: 2.225913', 'Train acc: 0.278333')\n",
      "('Epoch: 31/1000', 'Iteration: 160', 'Validation loss: 2.117816', 'Validation acc: 0.355000')\n",
      "('Epoch: 32/1000', 'Iteration: 165', 'Train loss: 2.205958', 'Train acc: 0.288333')\n",
      "('Epoch: 33/1000', 'Iteration: 170', 'Train loss: 2.186003', 'Train acc: 0.291667')\n",
      "('Epoch: 33/1000', 'Iteration: 170', 'Validation loss: 2.059083', 'Validation acc: 0.380000')\n",
      "('Epoch: 34/1000', 'Iteration: 175', 'Train loss: 2.145420', 'Train acc: 0.310000')\n",
      "('Epoch: 35/1000', 'Iteration: 180', 'Train loss: 2.121911', 'Train acc: 0.330000')\n",
      "('Epoch: 35/1000', 'Iteration: 180', 'Validation loss: 2.001910', 'Validation acc: 0.411667')\n",
      "('Epoch: 36/1000', 'Iteration: 185', 'Train loss: 2.092032', 'Train acc: 0.316667')\n",
      "('Epoch: 37/1000', 'Iteration: 190', 'Train loss: 2.063063', 'Train acc: 0.303333')\n",
      "('Epoch: 37/1000', 'Iteration: 190', 'Validation loss: 1.945207', 'Validation acc: 0.426667')\n",
      "('Epoch: 38/1000', 'Iteration: 195', 'Train loss: 2.017919', 'Train acc: 0.363333')\n",
      "('Epoch: 39/1000', 'Iteration: 200', 'Train loss: 1.985579', 'Train acc: 0.360000')\n",
      "('Epoch: 39/1000', 'Iteration: 200', 'Validation loss: 1.889329', 'Validation acc: 0.440000')\n",
      "('Epoch: 40/1000', 'Iteration: 205', 'Train loss: 1.969566', 'Train acc: 0.368333')\n",
      "('Epoch: 41/1000', 'Iteration: 210', 'Train loss: 1.952818', 'Train acc: 0.376667')\n",
      "('Epoch: 41/1000', 'Iteration: 210', 'Validation loss: 1.835877', 'Validation acc: 0.461667')\n",
      "('Epoch: 42/1000', 'Iteration: 215', 'Train loss: 1.942513', 'Train acc: 0.371667')\n",
      "('Epoch: 43/1000', 'Iteration: 220', 'Train loss: 1.912998', 'Train acc: 0.368333')\n",
      "('Epoch: 43/1000', 'Iteration: 220', 'Validation loss: 1.783881', 'Validation acc: 0.475000')\n",
      "('Epoch: 44/1000', 'Iteration: 225', 'Train loss: 1.866808', 'Train acc: 0.420000')\n",
      "('Epoch: 45/1000', 'Iteration: 230', 'Train loss: 1.832852', 'Train acc: 0.398333')\n",
      "('Epoch: 45/1000', 'Iteration: 230', 'Validation loss: 1.734114', 'Validation acc: 0.496667')\n",
      "('Epoch: 46/1000', 'Iteration: 235', 'Train loss: 1.827710', 'Train acc: 0.400000')\n",
      "('Epoch: 47/1000', 'Iteration: 240', 'Train loss: 1.800907', 'Train acc: 0.418333')\n",
      "('Epoch: 47/1000', 'Iteration: 240', 'Validation loss: 1.685348', 'Validation acc: 0.506667')\n",
      "('Epoch: 48/1000', 'Iteration: 245', 'Train loss: 1.778940', 'Train acc: 0.420000')\n",
      "('Epoch: 49/1000', 'Iteration: 250', 'Train loss: 1.760961', 'Train acc: 0.438333')\n",
      "('Epoch: 49/1000', 'Iteration: 250', 'Validation loss: 1.639794', 'Validation acc: 0.526667')\n",
      "('Epoch: 50/1000', 'Iteration: 255', 'Train loss: 1.771981', 'Train acc: 0.430000')\n",
      "('Epoch: 51/1000', 'Iteration: 260', 'Train loss: 1.693004', 'Train acc: 0.446667')\n",
      "('Epoch: 51/1000', 'Iteration: 260', 'Validation loss: 1.596792', 'Validation acc: 0.545000')\n",
      "('Epoch: 52/1000', 'Iteration: 265', 'Train loss: 1.677629', 'Train acc: 0.433333')\n",
      "('Epoch: 53/1000', 'Iteration: 270', 'Train loss: 1.655898', 'Train acc: 0.475000')\n",
      "('Epoch: 53/1000', 'Iteration: 270', 'Validation loss: 1.553758', 'Validation acc: 0.551667')\n",
      "('Epoch: 54/1000', 'Iteration: 275', 'Train loss: 1.643009', 'Train acc: 0.440000')\n",
      "('Epoch: 55/1000', 'Iteration: 280', 'Train loss: 1.623635', 'Train acc: 0.460000')\n",
      "('Epoch: 55/1000', 'Iteration: 280', 'Validation loss: 1.512629', 'Validation acc: 0.566667')\n",
      "('Epoch: 56/1000', 'Iteration: 285', 'Train loss: 1.598690', 'Train acc: 0.478333')\n",
      "('Epoch: 57/1000', 'Iteration: 290', 'Train loss: 1.612936', 'Train acc: 0.448333')\n",
      "('Epoch: 57/1000', 'Iteration: 290', 'Validation loss: 1.474610', 'Validation acc: 0.566667')\n",
      "('Epoch: 58/1000', 'Iteration: 295', 'Train loss: 1.552554', 'Train acc: 0.485000')\n",
      "('Epoch: 59/1000', 'Iteration: 300', 'Train loss: 1.537941', 'Train acc: 0.510000')\n",
      "('Epoch: 59/1000', 'Iteration: 300', 'Validation loss: 1.439415', 'Validation acc: 0.580000')\n",
      "('Epoch: 60/1000', 'Iteration: 305', 'Train loss: 1.512759', 'Train acc: 0.518333')\n",
      "('Epoch: 61/1000', 'Iteration: 310', 'Train loss: 1.488532', 'Train acc: 0.505000')\n",
      "('Epoch: 61/1000', 'Iteration: 310', 'Validation loss: 1.403189', 'Validation acc: 0.596667')\n",
      "('Epoch: 62/1000', 'Iteration: 315', 'Train loss: 1.472718', 'Train acc: 0.500000')\n",
      "('Epoch: 63/1000', 'Iteration: 320', 'Train loss: 1.477572', 'Train acc: 0.495000')\n",
      "('Epoch: 63/1000', 'Iteration: 320', 'Validation loss: 1.371633', 'Validation acc: 0.593333')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 64/1000', 'Iteration: 325', 'Train loss: 1.456309', 'Train acc: 0.510000')\n",
      "('Epoch: 65/1000', 'Iteration: 330', 'Train loss: 1.410827', 'Train acc: 0.526667')\n",
      "('Epoch: 65/1000', 'Iteration: 330', 'Validation loss: 1.339897', 'Validation acc: 0.603333')\n",
      "('Epoch: 66/1000', 'Iteration: 335', 'Train loss: 1.473915', 'Train acc: 0.491667')\n",
      "('Epoch: 67/1000', 'Iteration: 340', 'Train loss: 1.426582', 'Train acc: 0.508333')\n",
      "('Epoch: 67/1000', 'Iteration: 340', 'Validation loss: 1.310915', 'Validation acc: 0.610000')\n",
      "('Epoch: 68/1000', 'Iteration: 345', 'Train loss: 1.399155', 'Train acc: 0.541667')\n",
      "('Epoch: 69/1000', 'Iteration: 350', 'Train loss: 1.371071', 'Train acc: 0.516667')\n",
      "('Epoch: 69/1000', 'Iteration: 350', 'Validation loss: 1.280630', 'Validation acc: 0.613333')\n",
      "('Epoch: 70/1000', 'Iteration: 355', 'Train loss: 1.330434', 'Train acc: 0.575000')\n",
      "('Epoch: 71/1000', 'Iteration: 360', 'Train loss: 1.311707', 'Train acc: 0.566667')\n",
      "('Epoch: 71/1000', 'Iteration: 360', 'Validation loss: 1.255226', 'Validation acc: 0.613333')\n",
      "('Epoch: 72/1000', 'Iteration: 365', 'Train loss: 1.337593', 'Train acc: 0.535000')\n",
      "('Epoch: 73/1000', 'Iteration: 370', 'Train loss: 1.282998', 'Train acc: 0.566667')\n",
      "('Epoch: 73/1000', 'Iteration: 370', 'Validation loss: 1.228835', 'Validation acc: 0.625000')\n",
      "('Epoch: 74/1000', 'Iteration: 375', 'Train loss: 1.315712', 'Train acc: 0.555000')\n",
      "('Epoch: 75/1000', 'Iteration: 380', 'Train loss: 1.288734', 'Train acc: 0.573333')\n",
      "('Epoch: 75/1000', 'Iteration: 380', 'Validation loss: 1.201395', 'Validation acc: 0.630000')\n",
      "('Epoch: 76/1000', 'Iteration: 385', 'Train loss: 1.264420', 'Train acc: 0.570000')\n",
      "('Epoch: 77/1000', 'Iteration: 390', 'Train loss: 1.285353', 'Train acc: 0.578333')\n",
      "('Epoch: 77/1000', 'Iteration: 390', 'Validation loss: 1.180305', 'Validation acc: 0.638333')\n",
      "('Epoch: 78/1000', 'Iteration: 395', 'Train loss: 1.241397', 'Train acc: 0.606667')\n",
      "('Epoch: 79/1000', 'Iteration: 400', 'Train loss: 1.210495', 'Train acc: 0.586667')\n",
      "('Epoch: 79/1000', 'Iteration: 400', 'Validation loss: 1.156707', 'Validation acc: 0.645000')\n",
      "('Epoch: 80/1000', 'Iteration: 405', 'Train loss: 1.185516', 'Train acc: 0.621667')\n",
      "('Epoch: 81/1000', 'Iteration: 410', 'Train loss: 1.189258', 'Train acc: 0.626667')\n",
      "('Epoch: 81/1000', 'Iteration: 410', 'Validation loss: 1.136641', 'Validation acc: 0.650000')\n",
      "('Epoch: 82/1000', 'Iteration: 415', 'Train loss: 1.169784', 'Train acc: 0.626667')\n",
      "('Epoch: 83/1000', 'Iteration: 420', 'Train loss: 1.159839', 'Train acc: 0.616667')\n",
      "('Epoch: 83/1000', 'Iteration: 420', 'Validation loss: 1.116246', 'Validation acc: 0.656667')\n",
      "('Epoch: 84/1000', 'Iteration: 425', 'Train loss: 1.194301', 'Train acc: 0.613333')\n",
      "('Epoch: 85/1000', 'Iteration: 430', 'Train loss: 1.164451', 'Train acc: 0.630000')\n",
      "('Epoch: 85/1000', 'Iteration: 430', 'Validation loss: 1.098164', 'Validation acc: 0.663333')\n",
      "('Epoch: 86/1000', 'Iteration: 435', 'Train loss: 1.144022', 'Train acc: 0.623333')\n",
      "('Epoch: 87/1000', 'Iteration: 440', 'Train loss: 1.167146', 'Train acc: 0.601667')\n",
      "('Epoch: 87/1000', 'Iteration: 440', 'Validation loss: 1.077607', 'Validation acc: 0.668333')\n",
      "('Epoch: 88/1000', 'Iteration: 445', 'Train loss: 1.144832', 'Train acc: 0.613333')\n",
      "('Epoch: 89/1000', 'Iteration: 450', 'Train loss: 1.114111', 'Train acc: 0.611667')\n",
      "('Epoch: 89/1000', 'Iteration: 450', 'Validation loss: 1.059394', 'Validation acc: 0.676667')\n",
      "('Epoch: 90/1000', 'Iteration: 455', 'Train loss: 1.093702', 'Train acc: 0.653333')\n",
      "('Epoch: 91/1000', 'Iteration: 460', 'Train loss: 1.085668', 'Train acc: 0.628333')\n",
      "('Epoch: 91/1000', 'Iteration: 460', 'Validation loss: 1.042212', 'Validation acc: 0.683333')\n",
      "('Epoch: 92/1000', 'Iteration: 465', 'Train loss: 1.072442', 'Train acc: 0.643333')\n",
      "('Epoch: 93/1000', 'Iteration: 470', 'Train loss: 1.100896', 'Train acc: 0.643333')\n",
      "('Epoch: 93/1000', 'Iteration: 470', 'Validation loss: 1.025113', 'Validation acc: 0.695000')\n",
      "('Epoch: 94/1000', 'Iteration: 475', 'Train loss: 1.060152', 'Train acc: 0.656667')\n",
      "('Epoch: 95/1000', 'Iteration: 480', 'Train loss: 1.034541', 'Train acc: 0.653333')\n",
      "('Epoch: 95/1000', 'Iteration: 480', 'Validation loss: 1.011132', 'Validation acc: 0.696667')\n",
      "('Epoch: 96/1000', 'Iteration: 485', 'Train loss: 1.040477', 'Train acc: 0.656667')\n",
      "('Epoch: 97/1000', 'Iteration: 490', 'Train loss: 1.048393', 'Train acc: 0.628333')\n",
      "('Epoch: 97/1000', 'Iteration: 490', 'Validation loss: 0.993841', 'Validation acc: 0.705000')\n",
      "('Epoch: 98/1000', 'Iteration: 495', 'Train loss: 1.050560', 'Train acc: 0.656667')\n",
      "('Epoch: 99/1000', 'Iteration: 500', 'Train loss: 1.015077', 'Train acc: 0.663333')\n",
      "('Epoch: 99/1000', 'Iteration: 500', 'Validation loss: 0.979266', 'Validation acc: 0.703333')\n",
      "('Epoch: 100/1000', 'Iteration: 505', 'Train loss: 1.029785', 'Train acc: 0.643333')\n",
      "('Epoch: 101/1000', 'Iteration: 510', 'Train loss: 1.014199', 'Train acc: 0.668333')\n",
      "('Epoch: 101/1000', 'Iteration: 510', 'Validation loss: 0.966879', 'Validation acc: 0.713333')\n",
      "('Epoch: 102/1000', 'Iteration: 515', 'Train loss: 1.011818', 'Train acc: 0.685000')\n",
      "('Epoch: 103/1000', 'Iteration: 520', 'Train loss: 1.011919', 'Train acc: 0.670000')\n",
      "('Epoch: 103/1000', 'Iteration: 520', 'Validation loss: 0.953293', 'Validation acc: 0.713333')\n",
      "('Epoch: 104/1000', 'Iteration: 525', 'Train loss: 0.967870', 'Train acc: 0.661667')\n",
      "('Epoch: 105/1000', 'Iteration: 530', 'Train loss: 0.951923', 'Train acc: 0.690000')\n",
      "('Epoch: 105/1000', 'Iteration: 530', 'Validation loss: 0.940133', 'Validation acc: 0.718333')\n",
      "('Epoch: 106/1000', 'Iteration: 535', 'Train loss: 0.971493', 'Train acc: 0.688333')\n",
      "('Epoch: 107/1000', 'Iteration: 540', 'Train loss: 0.954714', 'Train acc: 0.688333')\n",
      "('Epoch: 107/1000', 'Iteration: 540', 'Validation loss: 0.924752', 'Validation acc: 0.723333')\n",
      "('Epoch: 108/1000', 'Iteration: 545', 'Train loss: 0.956114', 'Train acc: 0.673333')\n",
      "('Epoch: 109/1000', 'Iteration: 550', 'Train loss: 0.941953', 'Train acc: 0.675000')\n",
      "('Epoch: 109/1000', 'Iteration: 550', 'Validation loss: 0.912635', 'Validation acc: 0.736667')\n",
      "('Epoch: 110/1000', 'Iteration: 555', 'Train loss: 0.962438', 'Train acc: 0.686667')\n",
      "('Epoch: 111/1000', 'Iteration: 560', 'Train loss: 0.912392', 'Train acc: 0.708333')\n",
      "('Epoch: 111/1000', 'Iteration: 560', 'Validation loss: 0.900474', 'Validation acc: 0.730000')\n",
      "('Epoch: 112/1000', 'Iteration: 565', 'Train loss: 0.956856', 'Train acc: 0.695000')\n",
      "('Epoch: 113/1000', 'Iteration: 570', 'Train loss: 0.891859', 'Train acc: 0.698333')\n",
      "('Epoch: 113/1000', 'Iteration: 570', 'Validation loss: 0.887102', 'Validation acc: 0.731667')\n",
      "('Epoch: 114/1000', 'Iteration: 575', 'Train loss: 0.903903', 'Train acc: 0.725000')\n",
      "('Epoch: 115/1000', 'Iteration: 580', 'Train loss: 0.898542', 'Train acc: 0.721667')\n",
      "('Epoch: 115/1000', 'Iteration: 580', 'Validation loss: 0.879465', 'Validation acc: 0.735000')\n",
      "('Epoch: 116/1000', 'Iteration: 585', 'Train loss: 0.881095', 'Train acc: 0.721667')\n",
      "('Epoch: 117/1000', 'Iteration: 590', 'Train loss: 0.902091', 'Train acc: 0.725000')\n",
      "('Epoch: 117/1000', 'Iteration: 590', 'Validation loss: 0.867419', 'Validation acc: 0.740000')\n",
      "('Epoch: 118/1000', 'Iteration: 595', 'Train loss: 0.854207', 'Train acc: 0.723333')\n",
      "('Epoch: 119/1000', 'Iteration: 600', 'Train loss: 0.869443', 'Train acc: 0.723333')\n",
      "('Epoch: 119/1000', 'Iteration: 600', 'Validation loss: 0.856408', 'Validation acc: 0.743333')\n",
      "('Epoch: 120/1000', 'Iteration: 605', 'Train loss: 0.871741', 'Train acc: 0.740000')\n",
      "('Epoch: 121/1000', 'Iteration: 610', 'Train loss: 0.828627', 'Train acc: 0.728333')\n",
      "('Epoch: 121/1000', 'Iteration: 610', 'Validation loss: 0.849043', 'Validation acc: 0.748333')\n",
      "('Epoch: 122/1000', 'Iteration: 615', 'Train loss: 0.863765', 'Train acc: 0.721667')\n",
      "('Epoch: 123/1000', 'Iteration: 620', 'Train loss: 0.864271', 'Train acc: 0.735000')\n",
      "('Epoch: 123/1000', 'Iteration: 620', 'Validation loss: 0.836346', 'Validation acc: 0.755000')\n",
      "('Epoch: 124/1000', 'Iteration: 625', 'Train loss: 0.832144', 'Train acc: 0.728333')\n",
      "('Epoch: 125/1000', 'Iteration: 630', 'Train loss: 0.830247', 'Train acc: 0.736667')\n",
      "('Epoch: 125/1000', 'Iteration: 630', 'Validation loss: 0.828920', 'Validation acc: 0.746667')\n",
      "('Epoch: 126/1000', 'Iteration: 635', 'Train loss: 0.834717', 'Train acc: 0.738333')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 127/1000', 'Iteration: 640', 'Train loss: 0.806685', 'Train acc: 0.741667')\n",
      "('Epoch: 127/1000', 'Iteration: 640', 'Validation loss: 0.817582', 'Validation acc: 0.756667')\n",
      "('Epoch: 128/1000', 'Iteration: 645', 'Train loss: 0.819939', 'Train acc: 0.731667')\n",
      "('Epoch: 129/1000', 'Iteration: 650', 'Train loss: 0.816517', 'Train acc: 0.741667')\n",
      "('Epoch: 129/1000', 'Iteration: 650', 'Validation loss: 0.813389', 'Validation acc: 0.751667')\n",
      "('Epoch: 130/1000', 'Iteration: 655', 'Train loss: 0.816526', 'Train acc: 0.725000')\n",
      "('Epoch: 131/1000', 'Iteration: 660', 'Train loss: 0.843561', 'Train acc: 0.718333')\n",
      "('Epoch: 131/1000', 'Iteration: 660', 'Validation loss: 0.801367', 'Validation acc: 0.763333')\n",
      "('Epoch: 132/1000', 'Iteration: 665', 'Train loss: 0.803931', 'Train acc: 0.745000')\n",
      "('Epoch: 133/1000', 'Iteration: 670', 'Train loss: 0.795558', 'Train acc: 0.728333')\n",
      "('Epoch: 133/1000', 'Iteration: 670', 'Validation loss: 0.792569', 'Validation acc: 0.770000')\n",
      "('Epoch: 134/1000', 'Iteration: 675', 'Train loss: 0.782935', 'Train acc: 0.741667')\n",
      "('Epoch: 135/1000', 'Iteration: 680', 'Train loss: 0.791641', 'Train acc: 0.751667')\n",
      "('Epoch: 135/1000', 'Iteration: 680', 'Validation loss: 0.784749', 'Validation acc: 0.770000')\n",
      "('Epoch: 136/1000', 'Iteration: 685', 'Train loss: 0.767775', 'Train acc: 0.748333')\n",
      "('Epoch: 137/1000', 'Iteration: 690', 'Train loss: 0.740348', 'Train acc: 0.768333')\n",
      "('Epoch: 137/1000', 'Iteration: 690', 'Validation loss: 0.780071', 'Validation acc: 0.768333')\n",
      "('Epoch: 138/1000', 'Iteration: 695', 'Train loss: 0.748642', 'Train acc: 0.753333')\n",
      "('Epoch: 139/1000', 'Iteration: 700', 'Train loss: 0.735293', 'Train acc: 0.766667')\n",
      "('Epoch: 139/1000', 'Iteration: 700', 'Validation loss: 0.770566', 'Validation acc: 0.770000')\n",
      "('Epoch: 140/1000', 'Iteration: 705', 'Train loss: 0.752371', 'Train acc: 0.761667')\n",
      "('Epoch: 141/1000', 'Iteration: 710', 'Train loss: 0.752853', 'Train acc: 0.763333')\n",
      "('Epoch: 141/1000', 'Iteration: 710', 'Validation loss: 0.762331', 'Validation acc: 0.770000')\n",
      "('Epoch: 142/1000', 'Iteration: 715', 'Train loss: 0.761446', 'Train acc: 0.766667')\n",
      "('Epoch: 143/1000', 'Iteration: 720', 'Train loss: 0.726033', 'Train acc: 0.746667')\n",
      "('Epoch: 143/1000', 'Iteration: 720', 'Validation loss: 0.758800', 'Validation acc: 0.770000')\n",
      "('Epoch: 144/1000', 'Iteration: 725', 'Train loss: 0.749665', 'Train acc: 0.766667')\n",
      "('Epoch: 145/1000', 'Iteration: 730', 'Train loss: 0.736836', 'Train acc: 0.751667')\n",
      "('Epoch: 145/1000', 'Iteration: 730', 'Validation loss: 0.746897', 'Validation acc: 0.773333')\n",
      "('Epoch: 146/1000', 'Iteration: 735', 'Train loss: 0.709997', 'Train acc: 0.766667')\n",
      "('Epoch: 147/1000', 'Iteration: 740', 'Train loss: 0.731212', 'Train acc: 0.773333')\n",
      "('Epoch: 147/1000', 'Iteration: 740', 'Validation loss: 0.740793', 'Validation acc: 0.775000')\n",
      "('Epoch: 148/1000', 'Iteration: 745', 'Train loss: 0.732935', 'Train acc: 0.765000')\n",
      "('Epoch: 149/1000', 'Iteration: 750', 'Train loss: 0.721965', 'Train acc: 0.766667')\n",
      "('Epoch: 149/1000', 'Iteration: 750', 'Validation loss: 0.735436', 'Validation acc: 0.771667')\n",
      "('Epoch: 150/1000', 'Iteration: 755', 'Train loss: 0.710626', 'Train acc: 0.766667')\n",
      "('Epoch: 151/1000', 'Iteration: 760', 'Train loss: 0.718452', 'Train acc: 0.753333')\n",
      "('Epoch: 151/1000', 'Iteration: 760', 'Validation loss: 0.729421', 'Validation acc: 0.783333')\n",
      "('Epoch: 152/1000', 'Iteration: 765', 'Train loss: 0.723626', 'Train acc: 0.770000')\n",
      "('Epoch: 153/1000', 'Iteration: 770', 'Train loss: 0.688166', 'Train acc: 0.771667')\n",
      "('Epoch: 153/1000', 'Iteration: 770', 'Validation loss: 0.722216', 'Validation acc: 0.781667')\n",
      "('Epoch: 154/1000', 'Iteration: 775', 'Train loss: 0.708086', 'Train acc: 0.756667')\n",
      "('Epoch: 155/1000', 'Iteration: 780', 'Train loss: 0.669946', 'Train acc: 0.778333')\n",
      "('Epoch: 155/1000', 'Iteration: 780', 'Validation loss: 0.712775', 'Validation acc: 0.786667')\n",
      "('Epoch: 156/1000', 'Iteration: 785', 'Train loss: 0.703342', 'Train acc: 0.786667')\n",
      "('Epoch: 157/1000', 'Iteration: 790', 'Train loss: 0.684056', 'Train acc: 0.760000')\n",
      "('Epoch: 157/1000', 'Iteration: 790', 'Validation loss: 0.710979', 'Validation acc: 0.780000')\n",
      "('Epoch: 158/1000', 'Iteration: 795', 'Train loss: 0.694887', 'Train acc: 0.756667')\n",
      "('Epoch: 159/1000', 'Iteration: 800', 'Train loss: 0.690780', 'Train acc: 0.781667')\n",
      "('Epoch: 159/1000', 'Iteration: 800', 'Validation loss: 0.706101', 'Validation acc: 0.785000')\n",
      "('Epoch: 160/1000', 'Iteration: 805', 'Train loss: 0.681872', 'Train acc: 0.773333')\n",
      "('Epoch: 161/1000', 'Iteration: 810', 'Train loss: 0.676548', 'Train acc: 0.780000')\n",
      "('Epoch: 161/1000', 'Iteration: 810', 'Validation loss: 0.696804', 'Validation acc: 0.788333')\n",
      "('Epoch: 162/1000', 'Iteration: 815', 'Train loss: 0.647294', 'Train acc: 0.790000')\n",
      "('Epoch: 163/1000', 'Iteration: 820', 'Train loss: 0.646732', 'Train acc: 0.785000')\n",
      "('Epoch: 163/1000', 'Iteration: 820', 'Validation loss: 0.693132', 'Validation acc: 0.783333')\n",
      "('Epoch: 164/1000', 'Iteration: 825', 'Train loss: 0.685314', 'Train acc: 0.778333')\n",
      "('Epoch: 165/1000', 'Iteration: 830', 'Train loss: 0.665427', 'Train acc: 0.773333')\n",
      "('Epoch: 165/1000', 'Iteration: 830', 'Validation loss: 0.689238', 'Validation acc: 0.790000')\n",
      "('Epoch: 166/1000', 'Iteration: 835', 'Train loss: 0.646026', 'Train acc: 0.790000')\n",
      "('Epoch: 167/1000', 'Iteration: 840', 'Train loss: 0.651163', 'Train acc: 0.788333')\n",
      "('Epoch: 167/1000', 'Iteration: 840', 'Validation loss: 0.686189', 'Validation acc: 0.793333')\n",
      "('Epoch: 168/1000', 'Iteration: 845', 'Train loss: 0.648241', 'Train acc: 0.798333')\n",
      "('Epoch: 169/1000', 'Iteration: 850', 'Train loss: 0.649668', 'Train acc: 0.785000')\n",
      "('Epoch: 169/1000', 'Iteration: 850', 'Validation loss: 0.679178', 'Validation acc: 0.795000')\n",
      "('Epoch: 170/1000', 'Iteration: 855', 'Train loss: 0.621038', 'Train acc: 0.801667')\n",
      "('Epoch: 171/1000', 'Iteration: 860', 'Train loss: 0.648160', 'Train acc: 0.773333')\n",
      "('Epoch: 171/1000', 'Iteration: 860', 'Validation loss: 0.675830', 'Validation acc: 0.796667')\n",
      "('Epoch: 172/1000', 'Iteration: 865', 'Train loss: 0.635054', 'Train acc: 0.781667')\n",
      "('Epoch: 173/1000', 'Iteration: 870', 'Train loss: 0.637012', 'Train acc: 0.783333')\n",
      "('Epoch: 173/1000', 'Iteration: 870', 'Validation loss: 0.670573', 'Validation acc: 0.790000')\n",
      "('Epoch: 174/1000', 'Iteration: 875', 'Train loss: 0.615144', 'Train acc: 0.800000')\n",
      "('Epoch: 175/1000', 'Iteration: 880', 'Train loss: 0.649823', 'Train acc: 0.788333')\n",
      "('Epoch: 175/1000', 'Iteration: 880', 'Validation loss: 0.663618', 'Validation acc: 0.801667')\n",
      "('Epoch: 176/1000', 'Iteration: 885', 'Train loss: 0.624462', 'Train acc: 0.793333')\n",
      "('Epoch: 177/1000', 'Iteration: 890', 'Train loss: 0.605694', 'Train acc: 0.793333')\n",
      "('Epoch: 177/1000', 'Iteration: 890', 'Validation loss: 0.661453', 'Validation acc: 0.801667')\n",
      "('Epoch: 178/1000', 'Iteration: 895', 'Train loss: 0.621501', 'Train acc: 0.796667')\n",
      "('Epoch: 179/1000', 'Iteration: 900', 'Train loss: 0.596852', 'Train acc: 0.790000')\n",
      "('Epoch: 179/1000', 'Iteration: 900', 'Validation loss: 0.652355', 'Validation acc: 0.805000')\n",
      "('Epoch: 180/1000', 'Iteration: 905', 'Train loss: 0.582228', 'Train acc: 0.805000')\n",
      "('Epoch: 181/1000', 'Iteration: 910', 'Train loss: 0.614815', 'Train acc: 0.805000')\n",
      "('Epoch: 181/1000', 'Iteration: 910', 'Validation loss: 0.652170', 'Validation acc: 0.793333')\n",
      "('Epoch: 182/1000', 'Iteration: 915', 'Train loss: 0.611843', 'Train acc: 0.810000')\n",
      "('Epoch: 183/1000', 'Iteration: 920', 'Train loss: 0.608968', 'Train acc: 0.813333')\n",
      "('Epoch: 183/1000', 'Iteration: 920', 'Validation loss: 0.645592', 'Validation acc: 0.808333')\n",
      "('Epoch: 184/1000', 'Iteration: 925', 'Train loss: 0.590331', 'Train acc: 0.801667')\n",
      "('Epoch: 185/1000', 'Iteration: 930', 'Train loss: 0.605966', 'Train acc: 0.818333')\n",
      "('Epoch: 185/1000', 'Iteration: 930', 'Validation loss: 0.638924', 'Validation acc: 0.805000')\n",
      "('Epoch: 186/1000', 'Iteration: 935', 'Train loss: 0.589922', 'Train acc: 0.796667')\n",
      "('Epoch: 187/1000', 'Iteration: 940', 'Train loss: 0.583646', 'Train acc: 0.815000')\n",
      "('Epoch: 187/1000', 'Iteration: 940', 'Validation loss: 0.636766', 'Validation acc: 0.806667')\n",
      "('Epoch: 188/1000', 'Iteration: 945', 'Train loss: 0.563136', 'Train acc: 0.813333')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 189/1000', 'Iteration: 950', 'Train loss: 0.561135', 'Train acc: 0.815000')\n",
      "('Epoch: 189/1000', 'Iteration: 950', 'Validation loss: 0.632802', 'Validation acc: 0.813333')\n",
      "('Epoch: 190/1000', 'Iteration: 955', 'Train loss: 0.592072', 'Train acc: 0.800000')\n",
      "('Epoch: 191/1000', 'Iteration: 960', 'Train loss: 0.587844', 'Train acc: 0.803333')\n",
      "('Epoch: 191/1000', 'Iteration: 960', 'Validation loss: 0.628549', 'Validation acc: 0.816667')\n",
      "('Epoch: 192/1000', 'Iteration: 965', 'Train loss: 0.563876', 'Train acc: 0.823333')\n",
      "('Epoch: 193/1000', 'Iteration: 970', 'Train loss: 0.593133', 'Train acc: 0.808333')\n",
      "('Epoch: 193/1000', 'Iteration: 970', 'Validation loss: 0.627104', 'Validation acc: 0.811667')\n",
      "('Epoch: 194/1000', 'Iteration: 975', 'Train loss: 0.582264', 'Train acc: 0.805000')\n",
      "('Epoch: 195/1000', 'Iteration: 980', 'Train loss: 0.570583', 'Train acc: 0.810000')\n",
      "('Epoch: 195/1000', 'Iteration: 980', 'Validation loss: 0.622402', 'Validation acc: 0.811667')\n",
      "('Epoch: 196/1000', 'Iteration: 985', 'Train loss: 0.565142', 'Train acc: 0.825000')\n",
      "('Epoch: 197/1000', 'Iteration: 990', 'Train loss: 0.554443', 'Train acc: 0.838333')\n",
      "('Epoch: 197/1000', 'Iteration: 990', 'Validation loss: 0.618142', 'Validation acc: 0.813333')\n",
      "('Epoch: 198/1000', 'Iteration: 995', 'Train loss: 0.554203', 'Train acc: 0.826667')\n",
      "('Epoch: 199/1000', 'Iteration: 1000', 'Train loss: 0.543580', 'Train acc: 0.835000')\n",
      "('Epoch: 199/1000', 'Iteration: 1000', 'Validation loss: 0.614926', 'Validation acc: 0.815000')\n",
      "('Epoch: 200/1000', 'Iteration: 1005', 'Train loss: 0.548682', 'Train acc: 0.835000')\n",
      "('Epoch: 201/1000', 'Iteration: 1010', 'Train loss: 0.545942', 'Train acc: 0.828333')\n",
      "('Epoch: 201/1000', 'Iteration: 1010', 'Validation loss: 0.610561', 'Validation acc: 0.813333')\n",
      "('Epoch: 202/1000', 'Iteration: 1015', 'Train loss: 0.552407', 'Train acc: 0.830000')\n",
      "('Epoch: 203/1000', 'Iteration: 1020', 'Train loss: 0.565365', 'Train acc: 0.816667')\n",
      "('Epoch: 203/1000', 'Iteration: 1020', 'Validation loss: 0.608099', 'Validation acc: 0.816667')\n",
      "('Epoch: 204/1000', 'Iteration: 1025', 'Train loss: 0.531337', 'Train acc: 0.836667')\n",
      "('Epoch: 205/1000', 'Iteration: 1030', 'Train loss: 0.546196', 'Train acc: 0.818333')\n",
      "('Epoch: 205/1000', 'Iteration: 1030', 'Validation loss: 0.604539', 'Validation acc: 0.816667')\n",
      "('Epoch: 206/1000', 'Iteration: 1035', 'Train loss: 0.523305', 'Train acc: 0.823333')\n",
      "('Epoch: 207/1000', 'Iteration: 1040', 'Train loss: 0.547887', 'Train acc: 0.816667')\n",
      "('Epoch: 207/1000', 'Iteration: 1040', 'Validation loss: 0.604868', 'Validation acc: 0.813333')\n",
      "('Epoch: 208/1000', 'Iteration: 1045', 'Train loss: 0.534775', 'Train acc: 0.835000')\n",
      "('Epoch: 209/1000', 'Iteration: 1050', 'Train loss: 0.528221', 'Train acc: 0.835000')\n",
      "('Epoch: 209/1000', 'Iteration: 1050', 'Validation loss: 0.598006', 'Validation acc: 0.820000')\n",
      "('Epoch: 210/1000', 'Iteration: 1055', 'Train loss: 0.538090', 'Train acc: 0.826667')\n",
      "('Epoch: 211/1000', 'Iteration: 1060', 'Train loss: 0.529121', 'Train acc: 0.830000')\n",
      "('Epoch: 211/1000', 'Iteration: 1060', 'Validation loss: 0.592193', 'Validation acc: 0.815000')\n",
      "('Epoch: 212/1000', 'Iteration: 1065', 'Train loss: 0.561150', 'Train acc: 0.820000')\n",
      "('Epoch: 213/1000', 'Iteration: 1070', 'Train loss: 0.570634', 'Train acc: 0.801667')\n",
      "('Epoch: 213/1000', 'Iteration: 1070', 'Validation loss: 0.592708', 'Validation acc: 0.820000')\n",
      "('Epoch: 214/1000', 'Iteration: 1075', 'Train loss: 0.519917', 'Train acc: 0.835000')\n",
      "('Epoch: 215/1000', 'Iteration: 1080', 'Train loss: 0.532507', 'Train acc: 0.820000')\n",
      "('Epoch: 215/1000', 'Iteration: 1080', 'Validation loss: 0.588178', 'Validation acc: 0.826667')\n",
      "('Epoch: 216/1000', 'Iteration: 1085', 'Train loss: 0.529362', 'Train acc: 0.830000')\n",
      "('Epoch: 217/1000', 'Iteration: 1090', 'Train loss: 0.501562', 'Train acc: 0.838333')\n",
      "('Epoch: 217/1000', 'Iteration: 1090', 'Validation loss: 0.587490', 'Validation acc: 0.823333')\n",
      "('Epoch: 218/1000', 'Iteration: 1095', 'Train loss: 0.512965', 'Train acc: 0.835000')\n",
      "('Epoch: 219/1000', 'Iteration: 1100', 'Train loss: 0.495791', 'Train acc: 0.846667')\n",
      "('Epoch: 219/1000', 'Iteration: 1100', 'Validation loss: 0.584108', 'Validation acc: 0.826667')\n",
      "('Epoch: 220/1000', 'Iteration: 1105', 'Train loss: 0.522017', 'Train acc: 0.818333')\n",
      "('Epoch: 221/1000', 'Iteration: 1110', 'Train loss: 0.523080', 'Train acc: 0.836667')\n",
      "('Epoch: 221/1000', 'Iteration: 1110', 'Validation loss: 0.579513', 'Validation acc: 0.825000')\n",
      "('Epoch: 222/1000', 'Iteration: 1115', 'Train loss: 0.516353', 'Train acc: 0.821667')\n",
      "('Epoch: 223/1000', 'Iteration: 1120', 'Train loss: 0.490737', 'Train acc: 0.841667')\n",
      "('Epoch: 223/1000', 'Iteration: 1120', 'Validation loss: 0.580155', 'Validation acc: 0.826667')\n",
      "('Epoch: 224/1000', 'Iteration: 1125', 'Train loss: 0.466996', 'Train acc: 0.851667')\n",
      "('Epoch: 225/1000', 'Iteration: 1130', 'Train loss: 0.468169', 'Train acc: 0.860000')\n",
      "('Epoch: 225/1000', 'Iteration: 1130', 'Validation loss: 0.573888', 'Validation acc: 0.831667')\n",
      "('Epoch: 226/1000', 'Iteration: 1135', 'Train loss: 0.471302', 'Train acc: 0.850000')\n",
      "('Epoch: 227/1000', 'Iteration: 1140', 'Train loss: 0.518180', 'Train acc: 0.820000')\n",
      "('Epoch: 227/1000', 'Iteration: 1140', 'Validation loss: 0.571942', 'Validation acc: 0.821667')\n",
      "('Epoch: 228/1000', 'Iteration: 1145', 'Train loss: 0.487393', 'Train acc: 0.828333')\n",
      "('Epoch: 229/1000', 'Iteration: 1150', 'Train loss: 0.489493', 'Train acc: 0.853333')\n",
      "('Epoch: 229/1000', 'Iteration: 1150', 'Validation loss: 0.571067', 'Validation acc: 0.833333')\n",
      "('Epoch: 230/1000', 'Iteration: 1155', 'Train loss: 0.513609', 'Train acc: 0.825000')\n",
      "('Epoch: 231/1000', 'Iteration: 1160', 'Train loss: 0.486884', 'Train acc: 0.830000')\n",
      "('Epoch: 231/1000', 'Iteration: 1160', 'Validation loss: 0.569000', 'Validation acc: 0.833333')\n",
      "('Epoch: 232/1000', 'Iteration: 1165', 'Train loss: 0.466914', 'Train acc: 0.845000')\n",
      "('Epoch: 233/1000', 'Iteration: 1170', 'Train loss: 0.468166', 'Train acc: 0.843333')\n",
      "('Epoch: 233/1000', 'Iteration: 1170', 'Validation loss: 0.564476', 'Validation acc: 0.833333')\n",
      "('Epoch: 234/1000', 'Iteration: 1175', 'Train loss: 0.483278', 'Train acc: 0.850000')\n",
      "('Epoch: 235/1000', 'Iteration: 1180', 'Train loss: 0.462363', 'Train acc: 0.845000')\n",
      "('Epoch: 235/1000', 'Iteration: 1180', 'Validation loss: 0.565704', 'Validation acc: 0.833333')\n",
      "('Epoch: 236/1000', 'Iteration: 1185', 'Train loss: 0.478096', 'Train acc: 0.866667')\n",
      "('Epoch: 237/1000', 'Iteration: 1190', 'Train loss: 0.449645', 'Train acc: 0.873333')\n",
      "('Epoch: 237/1000', 'Iteration: 1190', 'Validation loss: 0.561434', 'Validation acc: 0.831667')\n",
      "('Epoch: 238/1000', 'Iteration: 1195', 'Train loss: 0.450910', 'Train acc: 0.853333')\n",
      "('Epoch: 239/1000', 'Iteration: 1200', 'Train loss: 0.498362', 'Train acc: 0.856667')\n",
      "('Epoch: 239/1000', 'Iteration: 1200', 'Validation loss: 0.557258', 'Validation acc: 0.838333')\n",
      "('Epoch: 240/1000', 'Iteration: 1205', 'Train loss: 0.455079', 'Train acc: 0.860000')\n",
      "('Epoch: 241/1000', 'Iteration: 1210', 'Train loss: 0.469522', 'Train acc: 0.851667')\n",
      "('Epoch: 241/1000', 'Iteration: 1210', 'Validation loss: 0.557768', 'Validation acc: 0.833333')\n",
      "('Epoch: 242/1000', 'Iteration: 1215', 'Train loss: 0.462866', 'Train acc: 0.855000')\n",
      "('Epoch: 243/1000', 'Iteration: 1220', 'Train loss: 0.444536', 'Train acc: 0.865000')\n",
      "('Epoch: 243/1000', 'Iteration: 1220', 'Validation loss: 0.558969', 'Validation acc: 0.831667')\n",
      "('Epoch: 244/1000', 'Iteration: 1225', 'Train loss: 0.449049', 'Train acc: 0.846667')\n",
      "('Epoch: 245/1000', 'Iteration: 1230', 'Train loss: 0.460375', 'Train acc: 0.833333')\n",
      "('Epoch: 245/1000', 'Iteration: 1230', 'Validation loss: 0.550950', 'Validation acc: 0.838333')\n",
      "('Epoch: 246/1000', 'Iteration: 1235', 'Train loss: 0.428603', 'Train acc: 0.861667')\n",
      "('Epoch: 247/1000', 'Iteration: 1240', 'Train loss: 0.446379', 'Train acc: 0.870000')\n",
      "('Epoch: 247/1000', 'Iteration: 1240', 'Validation loss: 0.548138', 'Validation acc: 0.840000')\n",
      "('Epoch: 248/1000', 'Iteration: 1245', 'Train loss: 0.448570', 'Train acc: 0.866667')\n",
      "('Epoch: 249/1000', 'Iteration: 1250', 'Train loss: 0.454683', 'Train acc: 0.848333')\n",
      "('Epoch: 249/1000', 'Iteration: 1250', 'Validation loss: 0.547115', 'Validation acc: 0.840000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 250/1000', 'Iteration: 1255', 'Train loss: 0.441625', 'Train acc: 0.860000')\n",
      "('Epoch: 251/1000', 'Iteration: 1260', 'Train loss: 0.426186', 'Train acc: 0.868333')\n",
      "('Epoch: 251/1000', 'Iteration: 1260', 'Validation loss: 0.542942', 'Validation acc: 0.840000')\n",
      "('Epoch: 252/1000', 'Iteration: 1265', 'Train loss: 0.409642', 'Train acc: 0.866667')\n",
      "('Epoch: 253/1000', 'Iteration: 1270', 'Train loss: 0.436900', 'Train acc: 0.858333')\n",
      "('Epoch: 253/1000', 'Iteration: 1270', 'Validation loss: 0.542433', 'Validation acc: 0.845000')\n",
      "('Epoch: 254/1000', 'Iteration: 1275', 'Train loss: 0.425677', 'Train acc: 0.850000')\n",
      "('Epoch: 255/1000', 'Iteration: 1280', 'Train loss: 0.452862', 'Train acc: 0.858333')\n",
      "('Epoch: 255/1000', 'Iteration: 1280', 'Validation loss: 0.540091', 'Validation acc: 0.838333')\n",
      "('Epoch: 256/1000', 'Iteration: 1285', 'Train loss: 0.428219', 'Train acc: 0.860000')\n",
      "('Epoch: 257/1000', 'Iteration: 1290', 'Train loss: 0.421145', 'Train acc: 0.871667')\n",
      "('Epoch: 257/1000', 'Iteration: 1290', 'Validation loss: 0.538433', 'Validation acc: 0.843333')\n",
      "('Epoch: 258/1000', 'Iteration: 1295', 'Train loss: 0.434094', 'Train acc: 0.861667')\n",
      "('Epoch: 259/1000', 'Iteration: 1300', 'Train loss: 0.422864', 'Train acc: 0.856667')\n",
      "('Epoch: 259/1000', 'Iteration: 1300', 'Validation loss: 0.539183', 'Validation acc: 0.838333')\n",
      "('Epoch: 260/1000', 'Iteration: 1305', 'Train loss: 0.428685', 'Train acc: 0.873333')\n",
      "('Epoch: 261/1000', 'Iteration: 1310', 'Train loss: 0.430316', 'Train acc: 0.875000')\n",
      "('Epoch: 261/1000', 'Iteration: 1310', 'Validation loss: 0.537300', 'Validation acc: 0.845000')\n",
      "('Epoch: 262/1000', 'Iteration: 1315', 'Train loss: 0.439866', 'Train acc: 0.860000')\n",
      "('Epoch: 263/1000', 'Iteration: 1320', 'Train loss: 0.428164', 'Train acc: 0.870000')\n",
      "('Epoch: 263/1000', 'Iteration: 1320', 'Validation loss: 0.533713', 'Validation acc: 0.845000')\n",
      "('Epoch: 264/1000', 'Iteration: 1325', 'Train loss: 0.415115', 'Train acc: 0.875000')\n",
      "('Epoch: 265/1000', 'Iteration: 1330', 'Train loss: 0.430870', 'Train acc: 0.870000')\n",
      "('Epoch: 265/1000', 'Iteration: 1330', 'Validation loss: 0.531711', 'Validation acc: 0.846667')\n",
      "('Epoch: 266/1000', 'Iteration: 1335', 'Train loss: 0.410616', 'Train acc: 0.865000')\n",
      "('Epoch: 267/1000', 'Iteration: 1340', 'Train loss: 0.423237', 'Train acc: 0.866667')\n",
      "('Epoch: 267/1000', 'Iteration: 1340', 'Validation loss: 0.529620', 'Validation acc: 0.846667')\n",
      "('Epoch: 268/1000', 'Iteration: 1345', 'Train loss: 0.423200', 'Train acc: 0.871667')\n",
      "('Epoch: 269/1000', 'Iteration: 1350', 'Train loss: 0.386262', 'Train acc: 0.883333')\n",
      "('Epoch: 269/1000', 'Iteration: 1350', 'Validation loss: 0.526956', 'Validation acc: 0.843333')\n",
      "('Epoch: 270/1000', 'Iteration: 1355', 'Train loss: 0.406560', 'Train acc: 0.873333')\n",
      "('Epoch: 271/1000', 'Iteration: 1360', 'Train loss: 0.411177', 'Train acc: 0.865000')\n",
      "('Epoch: 271/1000', 'Iteration: 1360', 'Validation loss: 0.529333', 'Validation acc: 0.845000')\n",
      "('Epoch: 272/1000', 'Iteration: 1365', 'Train loss: 0.397347', 'Train acc: 0.876667')\n",
      "('Epoch: 273/1000', 'Iteration: 1370', 'Train loss: 0.397305', 'Train acc: 0.871667')\n",
      "('Epoch: 273/1000', 'Iteration: 1370', 'Validation loss: 0.525507', 'Validation acc: 0.845000')\n",
      "('Epoch: 274/1000', 'Iteration: 1375', 'Train loss: 0.378012', 'Train acc: 0.876667')\n",
      "('Epoch: 275/1000', 'Iteration: 1380', 'Train loss: 0.394898', 'Train acc: 0.880000')\n",
      "('Epoch: 275/1000', 'Iteration: 1380', 'Validation loss: 0.523029', 'Validation acc: 0.848333')\n",
      "('Epoch: 276/1000', 'Iteration: 1385', 'Train loss: 0.399671', 'Train acc: 0.866667')\n",
      "('Epoch: 277/1000', 'Iteration: 1390', 'Train loss: 0.385898', 'Train acc: 0.868333')\n",
      "('Epoch: 277/1000', 'Iteration: 1390', 'Validation loss: 0.521510', 'Validation acc: 0.850000')\n",
      "('Epoch: 278/1000', 'Iteration: 1395', 'Train loss: 0.400853', 'Train acc: 0.873333')\n",
      "('Epoch: 279/1000', 'Iteration: 1400', 'Train loss: 0.396418', 'Train acc: 0.863333')\n",
      "('Epoch: 279/1000', 'Iteration: 1400', 'Validation loss: 0.520095', 'Validation acc: 0.845000')\n",
      "('Epoch: 280/1000', 'Iteration: 1405', 'Train loss: 0.370089', 'Train acc: 0.888333')\n",
      "('Epoch: 281/1000', 'Iteration: 1410', 'Train loss: 0.384609', 'Train acc: 0.880000')\n",
      "('Epoch: 281/1000', 'Iteration: 1410', 'Validation loss: 0.516691', 'Validation acc: 0.845000')\n",
      "('Epoch: 282/1000', 'Iteration: 1415', 'Train loss: 0.390866', 'Train acc: 0.873333')\n",
      "('Epoch: 283/1000', 'Iteration: 1420', 'Train loss: 0.383358', 'Train acc: 0.875000')\n",
      "('Epoch: 283/1000', 'Iteration: 1420', 'Validation loss: 0.517735', 'Validation acc: 0.845000')\n",
      "('Epoch: 284/1000', 'Iteration: 1425', 'Train loss: 0.408985', 'Train acc: 0.865000')\n",
      "('Epoch: 285/1000', 'Iteration: 1430', 'Train loss: 0.352219', 'Train acc: 0.886667')\n",
      "('Epoch: 285/1000', 'Iteration: 1430', 'Validation loss: 0.518152', 'Validation acc: 0.843333')\n",
      "('Epoch: 286/1000', 'Iteration: 1435', 'Train loss: 0.385953', 'Train acc: 0.876667')\n",
      "('Epoch: 287/1000', 'Iteration: 1440', 'Train loss: 0.376074', 'Train acc: 0.878333')\n",
      "('Epoch: 287/1000', 'Iteration: 1440', 'Validation loss: 0.517515', 'Validation acc: 0.850000')\n",
      "('Epoch: 288/1000', 'Iteration: 1445', 'Train loss: 0.368239', 'Train acc: 0.888333')\n",
      "('Epoch: 289/1000', 'Iteration: 1450', 'Train loss: 0.370911', 'Train acc: 0.885000')\n",
      "('Epoch: 289/1000', 'Iteration: 1450', 'Validation loss: 0.513983', 'Validation acc: 0.845000')\n",
      "('Epoch: 290/1000', 'Iteration: 1455', 'Train loss: 0.371070', 'Train acc: 0.888333')\n",
      "('Epoch: 291/1000', 'Iteration: 1460', 'Train loss: 0.375401', 'Train acc: 0.885000')\n",
      "('Epoch: 291/1000', 'Iteration: 1460', 'Validation loss: 0.512864', 'Validation acc: 0.846667')\n",
      "('Epoch: 292/1000', 'Iteration: 1465', 'Train loss: 0.399480', 'Train acc: 0.871667')\n",
      "('Epoch: 293/1000', 'Iteration: 1470', 'Train loss: 0.398815', 'Train acc: 0.876667')\n",
      "('Epoch: 293/1000', 'Iteration: 1470', 'Validation loss: 0.507928', 'Validation acc: 0.846667')\n",
      "('Epoch: 294/1000', 'Iteration: 1475', 'Train loss: 0.373941', 'Train acc: 0.901667')\n",
      "('Epoch: 295/1000', 'Iteration: 1480', 'Train loss: 0.372409', 'Train acc: 0.888333')\n",
      "('Epoch: 295/1000', 'Iteration: 1480', 'Validation loss: 0.508422', 'Validation acc: 0.848333')\n",
      "('Epoch: 296/1000', 'Iteration: 1485', 'Train loss: 0.349548', 'Train acc: 0.898333')\n",
      "('Epoch: 297/1000', 'Iteration: 1490', 'Train loss: 0.389942', 'Train acc: 0.868333')\n",
      "('Epoch: 297/1000', 'Iteration: 1490', 'Validation loss: 0.507670', 'Validation acc: 0.848333')\n",
      "('Epoch: 298/1000', 'Iteration: 1495', 'Train loss: 0.355597', 'Train acc: 0.898333')\n",
      "('Epoch: 299/1000', 'Iteration: 1500', 'Train loss: 0.372975', 'Train acc: 0.868333')\n",
      "('Epoch: 299/1000', 'Iteration: 1500', 'Validation loss: 0.509354', 'Validation acc: 0.850000')\n",
      "('Epoch: 300/1000', 'Iteration: 1505', 'Train loss: 0.379701', 'Train acc: 0.876667')\n",
      "('Epoch: 301/1000', 'Iteration: 1510', 'Train loss: 0.349426', 'Train acc: 0.875000')\n",
      "('Epoch: 301/1000', 'Iteration: 1510', 'Validation loss: 0.502982', 'Validation acc: 0.850000')\n",
      "('Epoch: 302/1000', 'Iteration: 1515', 'Train loss: 0.350888', 'Train acc: 0.885000')\n",
      "('Epoch: 303/1000', 'Iteration: 1520', 'Train loss: 0.351040', 'Train acc: 0.891667')\n",
      "('Epoch: 303/1000', 'Iteration: 1520', 'Validation loss: 0.506655', 'Validation acc: 0.853333')\n",
      "('Epoch: 304/1000', 'Iteration: 1525', 'Train loss: 0.351287', 'Train acc: 0.883333')\n",
      "('Epoch: 305/1000', 'Iteration: 1530', 'Train loss: 0.364094', 'Train acc: 0.890000')\n",
      "('Epoch: 305/1000', 'Iteration: 1530', 'Validation loss: 0.500330', 'Validation acc: 0.850000')\n",
      "('Epoch: 306/1000', 'Iteration: 1535', 'Train loss: 0.352939', 'Train acc: 0.883333')\n",
      "('Epoch: 307/1000', 'Iteration: 1540', 'Train loss: 0.368742', 'Train acc: 0.896667')\n",
      "('Epoch: 307/1000', 'Iteration: 1540', 'Validation loss: 0.498456', 'Validation acc: 0.848333')\n",
      "('Epoch: 308/1000', 'Iteration: 1545', 'Train loss: 0.366098', 'Train acc: 0.875000')\n",
      "('Epoch: 309/1000', 'Iteration: 1550', 'Train loss: 0.342924', 'Train acc: 0.891667')\n",
      "('Epoch: 309/1000', 'Iteration: 1550', 'Validation loss: 0.499162', 'Validation acc: 0.853333')\n",
      "('Epoch: 310/1000', 'Iteration: 1555', 'Train loss: 0.339056', 'Train acc: 0.883333')\n",
      "('Epoch: 311/1000', 'Iteration: 1560', 'Train loss: 0.345889', 'Train acc: 0.903333')\n",
      "('Epoch: 311/1000', 'Iteration: 1560', 'Validation loss: 0.492967', 'Validation acc: 0.851667')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 312/1000', 'Iteration: 1565', 'Train loss: 0.372925', 'Train acc: 0.871667')\n",
      "('Epoch: 313/1000', 'Iteration: 1570', 'Train loss: 0.335382', 'Train acc: 0.898333')\n",
      "('Epoch: 313/1000', 'Iteration: 1570', 'Validation loss: 0.496462', 'Validation acc: 0.853333')\n",
      "('Epoch: 314/1000', 'Iteration: 1575', 'Train loss: 0.337348', 'Train acc: 0.901667')\n",
      "('Epoch: 315/1000', 'Iteration: 1580', 'Train loss: 0.354965', 'Train acc: 0.895000')\n",
      "('Epoch: 315/1000', 'Iteration: 1580', 'Validation loss: 0.494432', 'Validation acc: 0.853333')\n",
      "('Epoch: 316/1000', 'Iteration: 1585', 'Train loss: 0.343749', 'Train acc: 0.885000')\n",
      "('Epoch: 317/1000', 'Iteration: 1590', 'Train loss: 0.341705', 'Train acc: 0.896667')\n",
      "('Epoch: 317/1000', 'Iteration: 1590', 'Validation loss: 0.492840', 'Validation acc: 0.850000')\n",
      "('Epoch: 318/1000', 'Iteration: 1595', 'Train loss: 0.346607', 'Train acc: 0.896667')\n",
      "('Epoch: 319/1000', 'Iteration: 1600', 'Train loss: 0.340042', 'Train acc: 0.903333')\n",
      "('Epoch: 319/1000', 'Iteration: 1600', 'Validation loss: 0.492484', 'Validation acc: 0.853333')\n",
      "('Epoch: 320/1000', 'Iteration: 1605', 'Train loss: 0.319687', 'Train acc: 0.911667')\n",
      "('Epoch: 321/1000', 'Iteration: 1610', 'Train loss: 0.345649', 'Train acc: 0.898333')\n",
      "('Epoch: 321/1000', 'Iteration: 1610', 'Validation loss: 0.490445', 'Validation acc: 0.851667')\n",
      "('Epoch: 322/1000', 'Iteration: 1615', 'Train loss: 0.336746', 'Train acc: 0.886667')\n",
      "('Epoch: 323/1000', 'Iteration: 1620', 'Train loss: 0.332020', 'Train acc: 0.891667')\n",
      "('Epoch: 323/1000', 'Iteration: 1620', 'Validation loss: 0.490929', 'Validation acc: 0.851667')\n",
      "('Epoch: 324/1000', 'Iteration: 1625', 'Train loss: 0.323579', 'Train acc: 0.900000')\n",
      "('Epoch: 325/1000', 'Iteration: 1630', 'Train loss: 0.316612', 'Train acc: 0.911667')\n",
      "('Epoch: 325/1000', 'Iteration: 1630', 'Validation loss: 0.486316', 'Validation acc: 0.853333')\n",
      "('Epoch: 326/1000', 'Iteration: 1635', 'Train loss: 0.320809', 'Train acc: 0.895000')\n",
      "('Epoch: 327/1000', 'Iteration: 1640', 'Train loss: 0.307166', 'Train acc: 0.896667')\n",
      "('Epoch: 327/1000', 'Iteration: 1640', 'Validation loss: 0.485277', 'Validation acc: 0.851667')\n",
      "('Epoch: 328/1000', 'Iteration: 1645', 'Train loss: 0.339282', 'Train acc: 0.903333')\n",
      "('Epoch: 329/1000', 'Iteration: 1650', 'Train loss: 0.316074', 'Train acc: 0.913333')\n",
      "('Epoch: 329/1000', 'Iteration: 1650', 'Validation loss: 0.487193', 'Validation acc: 0.858333')\n",
      "('Epoch: 330/1000', 'Iteration: 1655', 'Train loss: 0.309183', 'Train acc: 0.911667')\n",
      "('Epoch: 331/1000', 'Iteration: 1660', 'Train loss: 0.331862', 'Train acc: 0.893333')\n",
      "('Epoch: 331/1000', 'Iteration: 1660', 'Validation loss: 0.486098', 'Validation acc: 0.858333')\n",
      "('Epoch: 332/1000', 'Iteration: 1665', 'Train loss: 0.315056', 'Train acc: 0.901667')\n",
      "('Epoch: 333/1000', 'Iteration: 1670', 'Train loss: 0.303465', 'Train acc: 0.913333')\n",
      "('Epoch: 333/1000', 'Iteration: 1670', 'Validation loss: 0.484529', 'Validation acc: 0.853333')\n",
      "('Epoch: 334/1000', 'Iteration: 1675', 'Train loss: 0.310699', 'Train acc: 0.906667')\n",
      "('Epoch: 335/1000', 'Iteration: 1680', 'Train loss: 0.305757', 'Train acc: 0.905000')\n",
      "('Epoch: 335/1000', 'Iteration: 1680', 'Validation loss: 0.483046', 'Validation acc: 0.851667')\n",
      "('Epoch: 336/1000', 'Iteration: 1685', 'Train loss: 0.326158', 'Train acc: 0.893333')\n",
      "('Epoch: 337/1000', 'Iteration: 1690', 'Train loss: 0.311874', 'Train acc: 0.898333')\n",
      "('Epoch: 337/1000', 'Iteration: 1690', 'Validation loss: 0.482082', 'Validation acc: 0.855000')\n",
      "('Epoch: 338/1000', 'Iteration: 1695', 'Train loss: 0.339345', 'Train acc: 0.895000')\n",
      "('Epoch: 339/1000', 'Iteration: 1700', 'Train loss: 0.327862', 'Train acc: 0.896667')\n",
      "('Epoch: 339/1000', 'Iteration: 1700', 'Validation loss: 0.481815', 'Validation acc: 0.863333')\n",
      "('Epoch: 340/1000', 'Iteration: 1705', 'Train loss: 0.308800', 'Train acc: 0.898333')\n",
      "('Epoch: 341/1000', 'Iteration: 1710', 'Train loss: 0.283138', 'Train acc: 0.925000')\n",
      "('Epoch: 341/1000', 'Iteration: 1710', 'Validation loss: 0.481417', 'Validation acc: 0.861667')\n",
      "('Epoch: 342/1000', 'Iteration: 1715', 'Train loss: 0.290367', 'Train acc: 0.905000')\n",
      "('Epoch: 343/1000', 'Iteration: 1720', 'Train loss: 0.342774', 'Train acc: 0.903333')\n",
      "('Epoch: 343/1000', 'Iteration: 1720', 'Validation loss: 0.476133', 'Validation acc: 0.855000')\n",
      "('Epoch: 344/1000', 'Iteration: 1725', 'Train loss: 0.317862', 'Train acc: 0.888333')\n",
      "('Epoch: 345/1000', 'Iteration: 1730', 'Train loss: 0.334093', 'Train acc: 0.890000')\n",
      "('Epoch: 345/1000', 'Iteration: 1730', 'Validation loss: 0.479533', 'Validation acc: 0.855000')\n",
      "('Epoch: 346/1000', 'Iteration: 1735', 'Train loss: 0.282995', 'Train acc: 0.910000')\n",
      "('Epoch: 347/1000', 'Iteration: 1740', 'Train loss: 0.312124', 'Train acc: 0.900000')\n",
      "('Epoch: 347/1000', 'Iteration: 1740', 'Validation loss: 0.477969', 'Validation acc: 0.863333')\n",
      "('Epoch: 348/1000', 'Iteration: 1745', 'Train loss: 0.285072', 'Train acc: 0.915000')\n",
      "('Epoch: 349/1000', 'Iteration: 1750', 'Train loss: 0.324303', 'Train acc: 0.901667')\n",
      "('Epoch: 349/1000', 'Iteration: 1750', 'Validation loss: 0.475135', 'Validation acc: 0.861667')\n",
      "('Epoch: 350/1000', 'Iteration: 1755', 'Train loss: 0.287990', 'Train acc: 0.906667')\n",
      "('Epoch: 351/1000', 'Iteration: 1760', 'Train loss: 0.305806', 'Train acc: 0.911667')\n",
      "('Epoch: 351/1000', 'Iteration: 1760', 'Validation loss: 0.478168', 'Validation acc: 0.855000')\n",
      "('Epoch: 352/1000', 'Iteration: 1765', 'Train loss: 0.307216', 'Train acc: 0.898333')\n",
      "('Epoch: 353/1000', 'Iteration: 1770', 'Train loss: 0.293542', 'Train acc: 0.910000')\n",
      "('Epoch: 353/1000', 'Iteration: 1770', 'Validation loss: 0.474977', 'Validation acc: 0.861667')\n",
      "('Epoch: 354/1000', 'Iteration: 1775', 'Train loss: 0.290112', 'Train acc: 0.913333')\n",
      "('Epoch: 355/1000', 'Iteration: 1780', 'Train loss: 0.316379', 'Train acc: 0.905000')\n",
      "('Epoch: 355/1000', 'Iteration: 1780', 'Validation loss: 0.471479', 'Validation acc: 0.861667')\n",
      "('Epoch: 356/1000', 'Iteration: 1785', 'Train loss: 0.288005', 'Train acc: 0.905000')\n",
      "('Epoch: 357/1000', 'Iteration: 1790', 'Train loss: 0.303571', 'Train acc: 0.898333')\n",
      "('Epoch: 357/1000', 'Iteration: 1790', 'Validation loss: 0.475009', 'Validation acc: 0.858333')\n",
      "('Epoch: 358/1000', 'Iteration: 1795', 'Train loss: 0.287585', 'Train acc: 0.913333')\n",
      "('Epoch: 359/1000', 'Iteration: 1800', 'Train loss: 0.290519', 'Train acc: 0.911667')\n",
      "('Epoch: 359/1000', 'Iteration: 1800', 'Validation loss: 0.474020', 'Validation acc: 0.860000')\n",
      "('Epoch: 360/1000', 'Iteration: 1805', 'Train loss: 0.289373', 'Train acc: 0.913333')\n",
      "('Epoch: 361/1000', 'Iteration: 1810', 'Train loss: 0.276420', 'Train acc: 0.913333')\n",
      "('Epoch: 361/1000', 'Iteration: 1810', 'Validation loss: 0.471656', 'Validation acc: 0.861667')\n",
      "('Epoch: 362/1000', 'Iteration: 1815', 'Train loss: 0.300880', 'Train acc: 0.903333')\n",
      "('Epoch: 363/1000', 'Iteration: 1820', 'Train loss: 0.304844', 'Train acc: 0.901667')\n",
      "('Epoch: 363/1000', 'Iteration: 1820', 'Validation loss: 0.467746', 'Validation acc: 0.861667')\n",
      "('Epoch: 364/1000', 'Iteration: 1825', 'Train loss: 0.291294', 'Train acc: 0.905000')\n",
      "('Epoch: 365/1000', 'Iteration: 1830', 'Train loss: 0.263300', 'Train acc: 0.916667')\n",
      "('Epoch: 365/1000', 'Iteration: 1830', 'Validation loss: 0.469497', 'Validation acc: 0.865000')\n",
      "('Epoch: 366/1000', 'Iteration: 1835', 'Train loss: 0.297157', 'Train acc: 0.900000')\n",
      "('Epoch: 367/1000', 'Iteration: 1840', 'Train loss: 0.277040', 'Train acc: 0.920000')\n",
      "('Epoch: 367/1000', 'Iteration: 1840', 'Validation loss: 0.470339', 'Validation acc: 0.863333')\n",
      "('Epoch: 368/1000', 'Iteration: 1845', 'Train loss: 0.295129', 'Train acc: 0.911667')\n",
      "('Epoch: 369/1000', 'Iteration: 1850', 'Train loss: 0.270392', 'Train acc: 0.925000')\n",
      "('Epoch: 369/1000', 'Iteration: 1850', 'Validation loss: 0.461151', 'Validation acc: 0.861667')\n",
      "('Epoch: 370/1000', 'Iteration: 1855', 'Train loss: 0.291899', 'Train acc: 0.906667')\n",
      "('Epoch: 371/1000', 'Iteration: 1860', 'Train loss: 0.268274', 'Train acc: 0.913333')\n",
      "('Epoch: 371/1000', 'Iteration: 1860', 'Validation loss: 0.465345', 'Validation acc: 0.868333')\n",
      "('Epoch: 372/1000', 'Iteration: 1865', 'Train loss: 0.274493', 'Train acc: 0.910000')\n",
      "('Epoch: 373/1000', 'Iteration: 1870', 'Train loss: 0.277636', 'Train acc: 0.916667')\n",
      "('Epoch: 373/1000', 'Iteration: 1870', 'Validation loss: 0.462438', 'Validation acc: 0.863333')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 374/1000', 'Iteration: 1875', 'Train loss: 0.269969', 'Train acc: 0.918333')\n",
      "('Epoch: 375/1000', 'Iteration: 1880', 'Train loss: 0.275995', 'Train acc: 0.903333')\n",
      "('Epoch: 375/1000', 'Iteration: 1880', 'Validation loss: 0.467538', 'Validation acc: 0.865000')\n",
      "('Epoch: 376/1000', 'Iteration: 1885', 'Train loss: 0.279748', 'Train acc: 0.901667')\n",
      "('Epoch: 377/1000', 'Iteration: 1890', 'Train loss: 0.264156', 'Train acc: 0.921667')\n",
      "('Epoch: 377/1000', 'Iteration: 1890', 'Validation loss: 0.466094', 'Validation acc: 0.865000')\n",
      "('Epoch: 378/1000', 'Iteration: 1895', 'Train loss: 0.269598', 'Train acc: 0.920000')\n",
      "('Epoch: 379/1000', 'Iteration: 1900', 'Train loss: 0.260364', 'Train acc: 0.921667')\n",
      "('Epoch: 379/1000', 'Iteration: 1900', 'Validation loss: 0.465273', 'Validation acc: 0.858333')\n",
      "('Epoch: 380/1000', 'Iteration: 1905', 'Train loss: 0.260354', 'Train acc: 0.920000')\n",
      "('Epoch: 381/1000', 'Iteration: 1910', 'Train loss: 0.271053', 'Train acc: 0.918333')\n",
      "('Epoch: 381/1000', 'Iteration: 1910', 'Validation loss: 0.463505', 'Validation acc: 0.870000')\n",
      "('Epoch: 382/1000', 'Iteration: 1915', 'Train loss: 0.276293', 'Train acc: 0.911667')\n",
      "('Epoch: 383/1000', 'Iteration: 1920', 'Train loss: 0.272801', 'Train acc: 0.918333')\n",
      "('Epoch: 383/1000', 'Iteration: 1920', 'Validation loss: 0.462711', 'Validation acc: 0.870000')\n",
      "('Epoch: 384/1000', 'Iteration: 1925', 'Train loss: 0.277136', 'Train acc: 0.928333')\n",
      "('Epoch: 385/1000', 'Iteration: 1930', 'Train loss: 0.266068', 'Train acc: 0.923333')\n",
      "('Epoch: 385/1000', 'Iteration: 1930', 'Validation loss: 0.458321', 'Validation acc: 0.868333')\n",
      "('Epoch: 386/1000', 'Iteration: 1935', 'Train loss: 0.251580', 'Train acc: 0.923333')\n",
      "('Epoch: 387/1000', 'Iteration: 1940', 'Train loss: 0.259129', 'Train acc: 0.925000')\n",
      "('Epoch: 387/1000', 'Iteration: 1940', 'Validation loss: 0.462151', 'Validation acc: 0.866667')\n",
      "('Epoch: 388/1000', 'Iteration: 1945', 'Train loss: 0.263313', 'Train acc: 0.921667')\n",
      "('Epoch: 389/1000', 'Iteration: 1950', 'Train loss: 0.252344', 'Train acc: 0.920000')\n",
      "('Epoch: 389/1000', 'Iteration: 1950', 'Validation loss: 0.461102', 'Validation acc: 0.865000')\n",
      "('Epoch: 390/1000', 'Iteration: 1955', 'Train loss: 0.276423', 'Train acc: 0.921667')\n",
      "('Epoch: 391/1000', 'Iteration: 1960', 'Train loss: 0.250444', 'Train acc: 0.926667')\n",
      "('Epoch: 391/1000', 'Iteration: 1960', 'Validation loss: 0.462007', 'Validation acc: 0.861667')\n",
      "('Epoch: 392/1000', 'Iteration: 1965', 'Train loss: 0.255115', 'Train acc: 0.926667')\n",
      "('Epoch: 393/1000', 'Iteration: 1970', 'Train loss: 0.265700', 'Train acc: 0.920000')\n",
      "('Epoch: 393/1000', 'Iteration: 1970', 'Validation loss: 0.455871', 'Validation acc: 0.865000')\n",
      "('Epoch: 394/1000', 'Iteration: 1975', 'Train loss: 0.255474', 'Train acc: 0.913333')\n",
      "('Epoch: 395/1000', 'Iteration: 1980', 'Train loss: 0.262599', 'Train acc: 0.921667')\n",
      "('Epoch: 395/1000', 'Iteration: 1980', 'Validation loss: 0.458468', 'Validation acc: 0.866667')\n",
      "('Epoch: 396/1000', 'Iteration: 1985', 'Train loss: 0.260188', 'Train acc: 0.916667')\n",
      "('Epoch: 397/1000', 'Iteration: 1990', 'Train loss: 0.267782', 'Train acc: 0.930000')\n",
      "('Epoch: 397/1000', 'Iteration: 1990', 'Validation loss: 0.458703', 'Validation acc: 0.865000')\n",
      "('Epoch: 398/1000', 'Iteration: 1995', 'Train loss: 0.246772', 'Train acc: 0.921667')\n",
      "('Epoch: 399/1000', 'Iteration: 2000', 'Train loss: 0.274446', 'Train acc: 0.915000')\n",
      "('Epoch: 399/1000', 'Iteration: 2000', 'Validation loss: 0.455255', 'Validation acc: 0.868333')\n",
      "('Epoch: 400/1000', 'Iteration: 2005', 'Train loss: 0.257807', 'Train acc: 0.921667')\n",
      "('Epoch: 401/1000', 'Iteration: 2010', 'Train loss: 0.263291', 'Train acc: 0.918333')\n",
      "('Epoch: 401/1000', 'Iteration: 2010', 'Validation loss: 0.455964', 'Validation acc: 0.871667')\n",
      "('Epoch: 402/1000', 'Iteration: 2015', 'Train loss: 0.250772', 'Train acc: 0.928333')\n",
      "('Epoch: 403/1000', 'Iteration: 2020', 'Train loss: 0.254852', 'Train acc: 0.910000')\n",
      "('Epoch: 403/1000', 'Iteration: 2020', 'Validation loss: 0.457217', 'Validation acc: 0.876667')\n",
      "('Epoch: 404/1000', 'Iteration: 2025', 'Train loss: 0.237328', 'Train acc: 0.923333')\n",
      "('Epoch: 405/1000', 'Iteration: 2030', 'Train loss: 0.251641', 'Train acc: 0.925000')\n",
      "('Epoch: 405/1000', 'Iteration: 2030', 'Validation loss: 0.456792', 'Validation acc: 0.870000')\n",
      "('Epoch: 406/1000', 'Iteration: 2035', 'Train loss: 0.262386', 'Train acc: 0.916667')\n",
      "('Epoch: 407/1000', 'Iteration: 2040', 'Train loss: 0.251225', 'Train acc: 0.925000')\n",
      "('Epoch: 407/1000', 'Iteration: 2040', 'Validation loss: 0.454986', 'Validation acc: 0.868333')\n",
      "('Epoch: 408/1000', 'Iteration: 2045', 'Train loss: 0.243105', 'Train acc: 0.926667')\n",
      "('Epoch: 409/1000', 'Iteration: 2050', 'Train loss: 0.268737', 'Train acc: 0.905000')\n",
      "('Epoch: 409/1000', 'Iteration: 2050', 'Validation loss: 0.452298', 'Validation acc: 0.868333')\n",
      "('Epoch: 410/1000', 'Iteration: 2055', 'Train loss: 0.254004', 'Train acc: 0.918333')\n",
      "('Epoch: 411/1000', 'Iteration: 2060', 'Train loss: 0.252045', 'Train acc: 0.913333')\n",
      "('Epoch: 411/1000', 'Iteration: 2060', 'Validation loss: 0.451574', 'Validation acc: 0.873333')\n",
      "('Epoch: 412/1000', 'Iteration: 2065', 'Train loss: 0.251126', 'Train acc: 0.920000')\n",
      "('Epoch: 413/1000', 'Iteration: 2070', 'Train loss: 0.216847', 'Train acc: 0.938333')\n",
      "('Epoch: 413/1000', 'Iteration: 2070', 'Validation loss: 0.451733', 'Validation acc: 0.868333')\n",
      "('Epoch: 414/1000', 'Iteration: 2075', 'Train loss: 0.251707', 'Train acc: 0.928333')\n",
      "('Epoch: 415/1000', 'Iteration: 2080', 'Train loss: 0.256208', 'Train acc: 0.905000')\n",
      "('Epoch: 415/1000', 'Iteration: 2080', 'Validation loss: 0.451061', 'Validation acc: 0.870000')\n",
      "('Epoch: 416/1000', 'Iteration: 2085', 'Train loss: 0.239102', 'Train acc: 0.926667')\n",
      "('Epoch: 417/1000', 'Iteration: 2090', 'Train loss: 0.246004', 'Train acc: 0.936667')\n",
      "('Epoch: 417/1000', 'Iteration: 2090', 'Validation loss: 0.450912', 'Validation acc: 0.873333')\n",
      "('Epoch: 418/1000', 'Iteration: 2095', 'Train loss: 0.239805', 'Train acc: 0.930000')\n",
      "('Epoch: 419/1000', 'Iteration: 2100', 'Train loss: 0.248893', 'Train acc: 0.925000')\n",
      "('Epoch: 419/1000', 'Iteration: 2100', 'Validation loss: 0.451535', 'Validation acc: 0.870000')\n",
      "('Epoch: 420/1000', 'Iteration: 2105', 'Train loss: 0.234323', 'Train acc: 0.923333')\n",
      "('Epoch: 421/1000', 'Iteration: 2110', 'Train loss: 0.253861', 'Train acc: 0.930000')\n",
      "('Epoch: 421/1000', 'Iteration: 2110', 'Validation loss: 0.450547', 'Validation acc: 0.870000')\n",
      "('Epoch: 422/1000', 'Iteration: 2115', 'Train loss: 0.218040', 'Train acc: 0.933333')\n",
      "('Epoch: 423/1000', 'Iteration: 2120', 'Train loss: 0.236535', 'Train acc: 0.926667')\n",
      "('Epoch: 423/1000', 'Iteration: 2120', 'Validation loss: 0.452207', 'Validation acc: 0.870000')\n",
      "('Epoch: 424/1000', 'Iteration: 2125', 'Train loss: 0.238644', 'Train acc: 0.931667')\n",
      "('Epoch: 425/1000', 'Iteration: 2130', 'Train loss: 0.226520', 'Train acc: 0.933333')\n",
      "('Epoch: 425/1000', 'Iteration: 2130', 'Validation loss: 0.452063', 'Validation acc: 0.866667')\n",
      "('Epoch: 426/1000', 'Iteration: 2135', 'Train loss: 0.233433', 'Train acc: 0.925000')\n",
      "('Epoch: 427/1000', 'Iteration: 2140', 'Train loss: 0.245498', 'Train acc: 0.916667')\n",
      "('Epoch: 427/1000', 'Iteration: 2140', 'Validation loss: 0.449892', 'Validation acc: 0.875000')\n",
      "('Epoch: 428/1000', 'Iteration: 2145', 'Train loss: 0.258638', 'Train acc: 0.918333')\n",
      "('Epoch: 429/1000', 'Iteration: 2150', 'Train loss: 0.229099', 'Train acc: 0.920000')\n",
      "('Epoch: 429/1000', 'Iteration: 2150', 'Validation loss: 0.446568', 'Validation acc: 0.871667')\n",
      "('Epoch: 430/1000', 'Iteration: 2155', 'Train loss: 0.214640', 'Train acc: 0.931667')\n",
      "('Epoch: 431/1000', 'Iteration: 2160', 'Train loss: 0.222872', 'Train acc: 0.941667')\n",
      "('Epoch: 431/1000', 'Iteration: 2160', 'Validation loss: 0.444820', 'Validation acc: 0.873333')\n",
      "('Epoch: 432/1000', 'Iteration: 2165', 'Train loss: 0.203765', 'Train acc: 0.945000')\n",
      "('Epoch: 433/1000', 'Iteration: 2170', 'Train loss: 0.210608', 'Train acc: 0.935000')\n",
      "('Epoch: 433/1000', 'Iteration: 2170', 'Validation loss: 0.448152', 'Validation acc: 0.873333')\n",
      "('Epoch: 434/1000', 'Iteration: 2175', 'Train loss: 0.227671', 'Train acc: 0.926667')\n",
      "('Epoch: 435/1000', 'Iteration: 2180', 'Train loss: 0.217470', 'Train acc: 0.930000')\n",
      "('Epoch: 435/1000', 'Iteration: 2180', 'Validation loss: 0.448346', 'Validation acc: 0.868333')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 436/1000', 'Iteration: 2185', 'Train loss: 0.209560', 'Train acc: 0.938333')\n",
      "('Epoch: 437/1000', 'Iteration: 2190', 'Train loss: 0.211890', 'Train acc: 0.948333')\n",
      "('Epoch: 437/1000', 'Iteration: 2190', 'Validation loss: 0.445390', 'Validation acc: 0.878333')\n",
      "('Epoch: 438/1000', 'Iteration: 2195', 'Train loss: 0.224965', 'Train acc: 0.930000')\n",
      "('Epoch: 439/1000', 'Iteration: 2200', 'Train loss: 0.186890', 'Train acc: 0.953333')\n",
      "('Epoch: 439/1000', 'Iteration: 2200', 'Validation loss: 0.450256', 'Validation acc: 0.876667')\n",
      "('Epoch: 440/1000', 'Iteration: 2205', 'Train loss: 0.221490', 'Train acc: 0.926667')\n",
      "('Epoch: 441/1000', 'Iteration: 2210', 'Train loss: 0.228457', 'Train acc: 0.923333')\n",
      "('Epoch: 441/1000', 'Iteration: 2210', 'Validation loss: 0.445919', 'Validation acc: 0.875000')\n",
      "('Epoch: 442/1000', 'Iteration: 2215', 'Train loss: 0.214772', 'Train acc: 0.930000')\n",
      "('Epoch: 443/1000', 'Iteration: 2220', 'Train loss: 0.235277', 'Train acc: 0.921667')\n",
      "('Epoch: 443/1000', 'Iteration: 2220', 'Validation loss: 0.446355', 'Validation acc: 0.883333')\n",
      "('Epoch: 444/1000', 'Iteration: 2225', 'Train loss: 0.218893', 'Train acc: 0.928333')\n",
      "('Epoch: 445/1000', 'Iteration: 2230', 'Train loss: 0.213254', 'Train acc: 0.936667')\n",
      "('Epoch: 445/1000', 'Iteration: 2230', 'Validation loss: 0.446842', 'Validation acc: 0.881667')\n",
      "('Epoch: 446/1000', 'Iteration: 2235', 'Train loss: 0.210390', 'Train acc: 0.938333')\n",
      "('Epoch: 447/1000', 'Iteration: 2240', 'Train loss: 0.217939', 'Train acc: 0.923333')\n",
      "('Epoch: 447/1000', 'Iteration: 2240', 'Validation loss: 0.443671', 'Validation acc: 0.878333')\n",
      "('Epoch: 448/1000', 'Iteration: 2245', 'Train loss: 0.217150', 'Train acc: 0.915000')\n",
      "('Epoch: 449/1000', 'Iteration: 2250', 'Train loss: 0.220412', 'Train acc: 0.931667')\n",
      "('Epoch: 449/1000', 'Iteration: 2250', 'Validation loss: 0.443275', 'Validation acc: 0.875000')\n",
      "('Epoch: 450/1000', 'Iteration: 2255', 'Train loss: 0.191793', 'Train acc: 0.943333')\n",
      "('Epoch: 451/1000', 'Iteration: 2260', 'Train loss: 0.195122', 'Train acc: 0.945000')\n",
      "('Epoch: 451/1000', 'Iteration: 2260', 'Validation loss: 0.444643', 'Validation acc: 0.876667')\n",
      "('Epoch: 452/1000', 'Iteration: 2265', 'Train loss: 0.222764', 'Train acc: 0.923333')\n",
      "('Epoch: 453/1000', 'Iteration: 2270', 'Train loss: 0.208272', 'Train acc: 0.930000')\n",
      "('Epoch: 453/1000', 'Iteration: 2270', 'Validation loss: 0.444375', 'Validation acc: 0.876667')\n",
      "('Epoch: 454/1000', 'Iteration: 2275', 'Train loss: 0.207990', 'Train acc: 0.940000')\n",
      "('Epoch: 455/1000', 'Iteration: 2280', 'Train loss: 0.200532', 'Train acc: 0.946667')\n",
      "('Epoch: 455/1000', 'Iteration: 2280', 'Validation loss: 0.441368', 'Validation acc: 0.873333')\n",
      "('Epoch: 456/1000', 'Iteration: 2285', 'Train loss: 0.215786', 'Train acc: 0.933333')\n",
      "('Epoch: 457/1000', 'Iteration: 2290', 'Train loss: 0.209046', 'Train acc: 0.921667')\n",
      "('Epoch: 457/1000', 'Iteration: 2290', 'Validation loss: 0.441432', 'Validation acc: 0.876667')\n",
      "('Epoch: 458/1000', 'Iteration: 2295', 'Train loss: 0.198398', 'Train acc: 0.936667')\n",
      "('Epoch: 459/1000', 'Iteration: 2300', 'Train loss: 0.216483', 'Train acc: 0.935000')\n",
      "('Epoch: 459/1000', 'Iteration: 2300', 'Validation loss: 0.446262', 'Validation acc: 0.876667')\n",
      "('Epoch: 460/1000', 'Iteration: 2305', 'Train loss: 0.185769', 'Train acc: 0.951667')\n",
      "('Epoch: 461/1000', 'Iteration: 2310', 'Train loss: 0.214956', 'Train acc: 0.935000')\n",
      "('Epoch: 461/1000', 'Iteration: 2310', 'Validation loss: 0.443259', 'Validation acc: 0.878333')\n",
      "('Epoch: 462/1000', 'Iteration: 2315', 'Train loss: 0.213071', 'Train acc: 0.930000')\n",
      "('Epoch: 463/1000', 'Iteration: 2320', 'Train loss: 0.214544', 'Train acc: 0.938333')\n",
      "('Epoch: 463/1000', 'Iteration: 2320', 'Validation loss: 0.441991', 'Validation acc: 0.883333')\n",
      "('Epoch: 464/1000', 'Iteration: 2325', 'Train loss: 0.230536', 'Train acc: 0.933333')\n",
      "('Epoch: 465/1000', 'Iteration: 2330', 'Train loss: 0.197775', 'Train acc: 0.936667')\n",
      "('Epoch: 465/1000', 'Iteration: 2330', 'Validation loss: 0.442295', 'Validation acc: 0.883333')\n",
      "('Epoch: 466/1000', 'Iteration: 2335', 'Train loss: 0.201461', 'Train acc: 0.940000')\n",
      "('Epoch: 467/1000', 'Iteration: 2340', 'Train loss: 0.227126', 'Train acc: 0.920000')\n",
      "('Epoch: 467/1000', 'Iteration: 2340', 'Validation loss: 0.440198', 'Validation acc: 0.876667')\n",
      "('Epoch: 468/1000', 'Iteration: 2345', 'Train loss: 0.208568', 'Train acc: 0.930000')\n",
      "('Epoch: 469/1000', 'Iteration: 2350', 'Train loss: 0.208284', 'Train acc: 0.928333')\n",
      "('Epoch: 469/1000', 'Iteration: 2350', 'Validation loss: 0.436599', 'Validation acc: 0.880000')\n",
      "('Epoch: 470/1000', 'Iteration: 2355', 'Train loss: 0.193681', 'Train acc: 0.938333')\n",
      "('Epoch: 471/1000', 'Iteration: 2360', 'Train loss: 0.189341', 'Train acc: 0.948333')\n",
      "('Epoch: 471/1000', 'Iteration: 2360', 'Validation loss: 0.444234', 'Validation acc: 0.880000')\n",
      "('Epoch: 472/1000', 'Iteration: 2365', 'Train loss: 0.194690', 'Train acc: 0.941667')\n",
      "('Epoch: 473/1000', 'Iteration: 2370', 'Train loss: 0.190908', 'Train acc: 0.943333')\n",
      "('Epoch: 473/1000', 'Iteration: 2370', 'Validation loss: 0.443536', 'Validation acc: 0.881667')\n",
      "('Epoch: 474/1000', 'Iteration: 2375', 'Train loss: 0.204329', 'Train acc: 0.941667')\n",
      "('Epoch: 475/1000', 'Iteration: 2380', 'Train loss: 0.176827', 'Train acc: 0.946667')\n",
      "('Epoch: 475/1000', 'Iteration: 2380', 'Validation loss: 0.439184', 'Validation acc: 0.875000')\n",
      "('Epoch: 476/1000', 'Iteration: 2385', 'Train loss: 0.190234', 'Train acc: 0.940000')\n",
      "('Epoch: 477/1000', 'Iteration: 2390', 'Train loss: 0.188161', 'Train acc: 0.941667')\n",
      "('Epoch: 477/1000', 'Iteration: 2390', 'Validation loss: 0.440306', 'Validation acc: 0.881667')\n",
      "('Epoch: 478/1000', 'Iteration: 2395', 'Train loss: 0.207196', 'Train acc: 0.925000')\n",
      "('Epoch: 479/1000', 'Iteration: 2400', 'Train loss: 0.190881', 'Train acc: 0.945000')\n",
      "('Epoch: 479/1000', 'Iteration: 2400', 'Validation loss: 0.440004', 'Validation acc: 0.880000')\n",
      "('Epoch: 480/1000', 'Iteration: 2405', 'Train loss: 0.190088', 'Train acc: 0.951667')\n",
      "('Epoch: 481/1000', 'Iteration: 2410', 'Train loss: 0.209992', 'Train acc: 0.926667')\n",
      "('Epoch: 481/1000', 'Iteration: 2410', 'Validation loss: 0.440564', 'Validation acc: 0.876667')\n",
      "('Epoch: 482/1000', 'Iteration: 2415', 'Train loss: 0.159296', 'Train acc: 0.958333')\n",
      "('Epoch: 483/1000', 'Iteration: 2420', 'Train loss: 0.172535', 'Train acc: 0.946667')\n",
      "('Epoch: 483/1000', 'Iteration: 2420', 'Validation loss: 0.443312', 'Validation acc: 0.880000')\n",
      "('Epoch: 484/1000', 'Iteration: 2425', 'Train loss: 0.195388', 'Train acc: 0.935000')\n",
      "('Epoch: 485/1000', 'Iteration: 2430', 'Train loss: 0.201396', 'Train acc: 0.928333')\n",
      "('Epoch: 485/1000', 'Iteration: 2430', 'Validation loss: 0.440764', 'Validation acc: 0.883333')\n",
      "('Epoch: 486/1000', 'Iteration: 2435', 'Train loss: 0.198013', 'Train acc: 0.931667')\n",
      "('Epoch: 487/1000', 'Iteration: 2440', 'Train loss: 0.201411', 'Train acc: 0.935000')\n",
      "('Epoch: 487/1000', 'Iteration: 2440', 'Validation loss: 0.435528', 'Validation acc: 0.881667')\n",
      "('Epoch: 488/1000', 'Iteration: 2445', 'Train loss: 0.189001', 'Train acc: 0.943333')\n",
      "('Epoch: 489/1000', 'Iteration: 2450', 'Train loss: 0.181244', 'Train acc: 0.943333')\n",
      "('Epoch: 489/1000', 'Iteration: 2450', 'Validation loss: 0.437528', 'Validation acc: 0.888333')\n",
      "('Epoch: 490/1000', 'Iteration: 2455', 'Train loss: 0.195690', 'Train acc: 0.936667')\n",
      "('Epoch: 491/1000', 'Iteration: 2460', 'Train loss: 0.199244', 'Train acc: 0.941667')\n",
      "('Epoch: 491/1000', 'Iteration: 2460', 'Validation loss: 0.437261', 'Validation acc: 0.885000')\n",
      "('Epoch: 492/1000', 'Iteration: 2465', 'Train loss: 0.178632', 'Train acc: 0.948333')\n",
      "('Epoch: 493/1000', 'Iteration: 2470', 'Train loss: 0.186909', 'Train acc: 0.931667')\n",
      "('Epoch: 493/1000', 'Iteration: 2470', 'Validation loss: 0.435422', 'Validation acc: 0.885000')\n",
      "('Epoch: 494/1000', 'Iteration: 2475', 'Train loss: 0.183595', 'Train acc: 0.950000')\n",
      "('Epoch: 495/1000', 'Iteration: 2480', 'Train loss: 0.163458', 'Train acc: 0.946667')\n",
      "('Epoch: 495/1000', 'Iteration: 2480', 'Validation loss: 0.434203', 'Validation acc: 0.885000')\n",
      "('Epoch: 496/1000', 'Iteration: 2485', 'Train loss: 0.180421', 'Train acc: 0.931667')\n",
      "('Epoch: 497/1000', 'Iteration: 2490', 'Train loss: 0.179842', 'Train acc: 0.945000')\n",
      "('Epoch: 497/1000', 'Iteration: 2490', 'Validation loss: 0.436391', 'Validation acc: 0.886667')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 498/1000', 'Iteration: 2495', 'Train loss: 0.182657', 'Train acc: 0.938333')\n",
      "('Epoch: 499/1000', 'Iteration: 2500', 'Train loss: 0.194995', 'Train acc: 0.946667')\n",
      "('Epoch: 499/1000', 'Iteration: 2500', 'Validation loss: 0.435361', 'Validation acc: 0.883333')\n",
      "('Epoch: 500/1000', 'Iteration: 2505', 'Train loss: 0.175719', 'Train acc: 0.946667')\n",
      "('Epoch: 501/1000', 'Iteration: 2510', 'Train loss: 0.164178', 'Train acc: 0.955000')\n",
      "('Epoch: 501/1000', 'Iteration: 2510', 'Validation loss: 0.437956', 'Validation acc: 0.883333')\n",
      "('Epoch: 502/1000', 'Iteration: 2515', 'Train loss: 0.200657', 'Train acc: 0.938333')\n",
      "('Epoch: 503/1000', 'Iteration: 2520', 'Train loss: 0.160587', 'Train acc: 0.950000')\n",
      "('Epoch: 503/1000', 'Iteration: 2520', 'Validation loss: 0.433999', 'Validation acc: 0.886667')\n",
      "('Epoch: 504/1000', 'Iteration: 2525', 'Train loss: 0.182114', 'Train acc: 0.940000')\n",
      "('Epoch: 505/1000', 'Iteration: 2530', 'Train loss: 0.182104', 'Train acc: 0.940000')\n",
      "('Epoch: 505/1000', 'Iteration: 2530', 'Validation loss: 0.435095', 'Validation acc: 0.891667')\n",
      "('Epoch: 506/1000', 'Iteration: 2535', 'Train loss: 0.166044', 'Train acc: 0.953333')\n",
      "('Epoch: 507/1000', 'Iteration: 2540', 'Train loss: 0.171594', 'Train acc: 0.948333')\n",
      "('Epoch: 507/1000', 'Iteration: 2540', 'Validation loss: 0.432734', 'Validation acc: 0.890000')\n",
      "('Epoch: 508/1000', 'Iteration: 2545', 'Train loss: 0.179090', 'Train acc: 0.945000')\n",
      "('Epoch: 509/1000', 'Iteration: 2550', 'Train loss: 0.178148', 'Train acc: 0.951667')\n",
      "('Epoch: 509/1000', 'Iteration: 2550', 'Validation loss: 0.435862', 'Validation acc: 0.888333')\n",
      "('Epoch: 510/1000', 'Iteration: 2555', 'Train loss: 0.170813', 'Train acc: 0.956667')\n",
      "('Epoch: 511/1000', 'Iteration: 2560', 'Train loss: 0.178437', 'Train acc: 0.946667')\n",
      "('Epoch: 511/1000', 'Iteration: 2560', 'Validation loss: 0.434372', 'Validation acc: 0.885000')\n",
      "('Epoch: 512/1000', 'Iteration: 2565', 'Train loss: 0.169989', 'Train acc: 0.950000')\n",
      "('Epoch: 513/1000', 'Iteration: 2570', 'Train loss: 0.169016', 'Train acc: 0.945000')\n",
      "('Epoch: 513/1000', 'Iteration: 2570', 'Validation loss: 0.436695', 'Validation acc: 0.888333')\n",
      "('Epoch: 514/1000', 'Iteration: 2575', 'Train loss: 0.183721', 'Train acc: 0.945000')\n",
      "('Epoch: 515/1000', 'Iteration: 2580', 'Train loss: 0.173147', 'Train acc: 0.953333')\n",
      "('Epoch: 515/1000', 'Iteration: 2580', 'Validation loss: 0.435472', 'Validation acc: 0.885000')\n",
      "('Epoch: 516/1000', 'Iteration: 2585', 'Train loss: 0.175535', 'Train acc: 0.951667')\n",
      "('Epoch: 517/1000', 'Iteration: 2590', 'Train loss: 0.179966', 'Train acc: 0.940000')\n",
      "('Epoch: 517/1000', 'Iteration: 2590', 'Validation loss: 0.435662', 'Validation acc: 0.890000')\n",
      "('Epoch: 518/1000', 'Iteration: 2595', 'Train loss: 0.171388', 'Train acc: 0.948333')\n",
      "('Epoch: 519/1000', 'Iteration: 2600', 'Train loss: 0.167984', 'Train acc: 0.953333')\n",
      "('Epoch: 519/1000', 'Iteration: 2600', 'Validation loss: 0.434490', 'Validation acc: 0.893333')\n",
      "('Epoch: 520/1000', 'Iteration: 2605', 'Train loss: 0.172301', 'Train acc: 0.936667')\n",
      "('Epoch: 521/1000', 'Iteration: 2610', 'Train loss: 0.151028', 'Train acc: 0.965000')\n",
      "('Epoch: 521/1000', 'Iteration: 2610', 'Validation loss: 0.433977', 'Validation acc: 0.888333')\n",
      "('Epoch: 522/1000', 'Iteration: 2615', 'Train loss: 0.190107', 'Train acc: 0.948333')\n",
      "('Epoch: 523/1000', 'Iteration: 2620', 'Train loss: 0.153919', 'Train acc: 0.955000')\n",
      "('Epoch: 523/1000', 'Iteration: 2620', 'Validation loss: 0.431694', 'Validation acc: 0.888333')\n",
      "('Epoch: 524/1000', 'Iteration: 2625', 'Train loss: 0.156570', 'Train acc: 0.960000')\n",
      "('Epoch: 525/1000', 'Iteration: 2630', 'Train loss: 0.191028', 'Train acc: 0.945000')\n",
      "('Epoch: 525/1000', 'Iteration: 2630', 'Validation loss: 0.433245', 'Validation acc: 0.890000')\n",
      "('Epoch: 526/1000', 'Iteration: 2635', 'Train loss: 0.176719', 'Train acc: 0.941667')\n",
      "('Epoch: 527/1000', 'Iteration: 2640', 'Train loss: 0.163760', 'Train acc: 0.951667')\n",
      "('Epoch: 527/1000', 'Iteration: 2640', 'Validation loss: 0.432414', 'Validation acc: 0.893333')\n",
      "('Epoch: 528/1000', 'Iteration: 2645', 'Train loss: 0.154922', 'Train acc: 0.961667')\n",
      "('Epoch: 529/1000', 'Iteration: 2650', 'Train loss: 0.148210', 'Train acc: 0.955000')\n",
      "('Epoch: 529/1000', 'Iteration: 2650', 'Validation loss: 0.436608', 'Validation acc: 0.891667')\n",
      "('Epoch: 530/1000', 'Iteration: 2655', 'Train loss: 0.145259', 'Train acc: 0.956667')\n",
      "('Epoch: 531/1000', 'Iteration: 2660', 'Train loss: 0.185241', 'Train acc: 0.928333')\n",
      "('Epoch: 531/1000', 'Iteration: 2660', 'Validation loss: 0.434708', 'Validation acc: 0.888333')\n",
      "('Epoch: 532/1000', 'Iteration: 2665', 'Train loss: 0.148171', 'Train acc: 0.958333')\n",
      "('Epoch: 533/1000', 'Iteration: 2670', 'Train loss: 0.181175', 'Train acc: 0.941667')\n",
      "('Epoch: 533/1000', 'Iteration: 2670', 'Validation loss: 0.431380', 'Validation acc: 0.891667')\n",
      "('Epoch: 534/1000', 'Iteration: 2675', 'Train loss: 0.182567', 'Train acc: 0.935000')\n",
      "('Epoch: 535/1000', 'Iteration: 2680', 'Train loss: 0.177406', 'Train acc: 0.948333')\n",
      "('Epoch: 535/1000', 'Iteration: 2680', 'Validation loss: 0.433624', 'Validation acc: 0.891667')\n",
      "('Epoch: 536/1000', 'Iteration: 2685', 'Train loss: 0.170752', 'Train acc: 0.943333')\n",
      "('Epoch: 537/1000', 'Iteration: 2690', 'Train loss: 0.169401', 'Train acc: 0.945000')\n",
      "('Epoch: 537/1000', 'Iteration: 2690', 'Validation loss: 0.426372', 'Validation acc: 0.893333')\n",
      "('Epoch: 538/1000', 'Iteration: 2695', 'Train loss: 0.145984', 'Train acc: 0.958333')\n",
      "('Epoch: 539/1000', 'Iteration: 2700', 'Train loss: 0.163871', 'Train acc: 0.948333')\n",
      "('Epoch: 539/1000', 'Iteration: 2700', 'Validation loss: 0.436313', 'Validation acc: 0.891667')\n",
      "('Epoch: 540/1000', 'Iteration: 2705', 'Train loss: 0.139898', 'Train acc: 0.965000')\n",
      "('Epoch: 541/1000', 'Iteration: 2710', 'Train loss: 0.155815', 'Train acc: 0.955000')\n",
      "('Epoch: 541/1000', 'Iteration: 2710', 'Validation loss: 0.428318', 'Validation acc: 0.890000')\n",
      "('Epoch: 542/1000', 'Iteration: 2715', 'Train loss: 0.158562', 'Train acc: 0.956667')\n",
      "('Epoch: 543/1000', 'Iteration: 2720', 'Train loss: 0.181062', 'Train acc: 0.941667')\n",
      "('Epoch: 543/1000', 'Iteration: 2720', 'Validation loss: 0.427885', 'Validation acc: 0.896667')\n",
      "('Epoch: 544/1000', 'Iteration: 2725', 'Train loss: 0.128001', 'Train acc: 0.968333')\n",
      "('Epoch: 545/1000', 'Iteration: 2730', 'Train loss: 0.157631', 'Train acc: 0.956667')\n",
      "('Epoch: 545/1000', 'Iteration: 2730', 'Validation loss: 0.432036', 'Validation acc: 0.893333')\n",
      "('Epoch: 546/1000', 'Iteration: 2735', 'Train loss: 0.164763', 'Train acc: 0.956667')\n",
      "('Epoch: 547/1000', 'Iteration: 2740', 'Train loss: 0.146551', 'Train acc: 0.955000')\n",
      "('Epoch: 547/1000', 'Iteration: 2740', 'Validation loss: 0.430152', 'Validation acc: 0.895000')\n",
      "('Epoch: 548/1000', 'Iteration: 2745', 'Train loss: 0.183326', 'Train acc: 0.938333')\n",
      "('Epoch: 549/1000', 'Iteration: 2750', 'Train loss: 0.132653', 'Train acc: 0.963333')\n",
      "('Epoch: 549/1000', 'Iteration: 2750', 'Validation loss: 0.429099', 'Validation acc: 0.893333')\n",
      "('Epoch: 550/1000', 'Iteration: 2755', 'Train loss: 0.170498', 'Train acc: 0.945000')\n",
      "('Epoch: 551/1000', 'Iteration: 2760', 'Train loss: 0.162640', 'Train acc: 0.946667')\n",
      "('Epoch: 551/1000', 'Iteration: 2760', 'Validation loss: 0.429444', 'Validation acc: 0.891667')\n",
      "('Epoch: 552/1000', 'Iteration: 2765', 'Train loss: 0.162305', 'Train acc: 0.945000')\n",
      "('Epoch: 553/1000', 'Iteration: 2770', 'Train loss: 0.141922', 'Train acc: 0.958333')\n",
      "('Epoch: 553/1000', 'Iteration: 2770', 'Validation loss: 0.432196', 'Validation acc: 0.893333')\n",
      "('Epoch: 554/1000', 'Iteration: 2775', 'Train loss: 0.153456', 'Train acc: 0.955000')\n",
      "('Epoch: 555/1000', 'Iteration: 2780', 'Train loss: 0.139528', 'Train acc: 0.960000')\n",
      "('Epoch: 555/1000', 'Iteration: 2780', 'Validation loss: 0.427169', 'Validation acc: 0.896667')\n",
      "('Epoch: 556/1000', 'Iteration: 2785', 'Train loss: 0.144420', 'Train acc: 0.961667')\n",
      "('Epoch: 557/1000', 'Iteration: 2790', 'Train loss: 0.136966', 'Train acc: 0.958333')\n",
      "('Epoch: 557/1000', 'Iteration: 2790', 'Validation loss: 0.429078', 'Validation acc: 0.893333')\n",
      "('Epoch: 558/1000', 'Iteration: 2795', 'Train loss: 0.161393', 'Train acc: 0.946667')\n",
      "('Epoch: 559/1000', 'Iteration: 2800', 'Train loss: 0.140260', 'Train acc: 0.966667')\n",
      "('Epoch: 559/1000', 'Iteration: 2800', 'Validation loss: 0.429346', 'Validation acc: 0.891667')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 560/1000', 'Iteration: 2805', 'Train loss: 0.162644', 'Train acc: 0.951667')\n",
      "('Epoch: 561/1000', 'Iteration: 2810', 'Train loss: 0.124960', 'Train acc: 0.970000')\n",
      "('Epoch: 561/1000', 'Iteration: 2810', 'Validation loss: 0.430324', 'Validation acc: 0.900000')\n",
      "('Epoch: 562/1000', 'Iteration: 2815', 'Train loss: 0.131733', 'Train acc: 0.958333')\n",
      "('Epoch: 563/1000', 'Iteration: 2820', 'Train loss: 0.157889', 'Train acc: 0.950000')\n",
      "('Epoch: 563/1000', 'Iteration: 2820', 'Validation loss: 0.429022', 'Validation acc: 0.890000')\n",
      "('Epoch: 564/1000', 'Iteration: 2825', 'Train loss: 0.161140', 'Train acc: 0.946667')\n",
      "('Epoch: 565/1000', 'Iteration: 2830', 'Train loss: 0.161333', 'Train acc: 0.945000')\n",
      "('Epoch: 565/1000', 'Iteration: 2830', 'Validation loss: 0.428663', 'Validation acc: 0.896667')\n",
      "('Epoch: 566/1000', 'Iteration: 2835', 'Train loss: 0.145725', 'Train acc: 0.956667')\n",
      "('Epoch: 567/1000', 'Iteration: 2840', 'Train loss: 0.166999', 'Train acc: 0.943333')\n",
      "('Epoch: 567/1000', 'Iteration: 2840', 'Validation loss: 0.430822', 'Validation acc: 0.893333')\n",
      "('Epoch: 568/1000', 'Iteration: 2845', 'Train loss: 0.178824', 'Train acc: 0.941667')\n",
      "('Epoch: 569/1000', 'Iteration: 2850', 'Train loss: 0.156014', 'Train acc: 0.955000')\n",
      "('Epoch: 569/1000', 'Iteration: 2850', 'Validation loss: 0.426758', 'Validation acc: 0.895000')\n",
      "('Epoch: 570/1000', 'Iteration: 2855', 'Train loss: 0.139830', 'Train acc: 0.963333')\n",
      "('Epoch: 571/1000', 'Iteration: 2860', 'Train loss: 0.146198', 'Train acc: 0.953333')\n",
      "('Epoch: 571/1000', 'Iteration: 2860', 'Validation loss: 0.433009', 'Validation acc: 0.893333')\n",
      "('Epoch: 572/1000', 'Iteration: 2865', 'Train loss: 0.137076', 'Train acc: 0.965000')\n",
      "('Epoch: 573/1000', 'Iteration: 2870', 'Train loss: 0.153501', 'Train acc: 0.953333')\n",
      "('Epoch: 573/1000', 'Iteration: 2870', 'Validation loss: 0.431528', 'Validation acc: 0.895000')\n",
      "('Epoch: 574/1000', 'Iteration: 2875', 'Train loss: 0.150101', 'Train acc: 0.955000')\n",
      "('Epoch: 575/1000', 'Iteration: 2880', 'Train loss: 0.142585', 'Train acc: 0.958333')\n",
      "('Epoch: 575/1000', 'Iteration: 2880', 'Validation loss: 0.426753', 'Validation acc: 0.900000')\n",
      "('Epoch: 576/1000', 'Iteration: 2885', 'Train loss: 0.146719', 'Train acc: 0.951667')\n",
      "('Epoch: 577/1000', 'Iteration: 2890', 'Train loss: 0.138612', 'Train acc: 0.956667')\n",
      "('Epoch: 577/1000', 'Iteration: 2890', 'Validation loss: 0.424155', 'Validation acc: 0.896667')\n",
      "('Epoch: 578/1000', 'Iteration: 2895', 'Train loss: 0.141335', 'Train acc: 0.961667')\n",
      "('Epoch: 579/1000', 'Iteration: 2900', 'Train loss: 0.142920', 'Train acc: 0.963333')\n",
      "('Epoch: 579/1000', 'Iteration: 2900', 'Validation loss: 0.424057', 'Validation acc: 0.900000')\n",
      "('Epoch: 580/1000', 'Iteration: 2905', 'Train loss: 0.128749', 'Train acc: 0.958333')\n",
      "('Epoch: 581/1000', 'Iteration: 2910', 'Train loss: 0.128839', 'Train acc: 0.970000')\n",
      "('Epoch: 581/1000', 'Iteration: 2910', 'Validation loss: 0.426073', 'Validation acc: 0.898333')\n",
      "('Epoch: 582/1000', 'Iteration: 2915', 'Train loss: 0.138439', 'Train acc: 0.960000')\n",
      "('Epoch: 583/1000', 'Iteration: 2920', 'Train loss: 0.136048', 'Train acc: 0.958333')\n",
      "('Epoch: 583/1000', 'Iteration: 2920', 'Validation loss: 0.428116', 'Validation acc: 0.898333')\n",
      "('Epoch: 584/1000', 'Iteration: 2925', 'Train loss: 0.129104', 'Train acc: 0.966667')\n",
      "('Epoch: 585/1000', 'Iteration: 2930', 'Train loss: 0.142377', 'Train acc: 0.955000')\n",
      "('Epoch: 585/1000', 'Iteration: 2930', 'Validation loss: 0.427887', 'Validation acc: 0.898333')\n",
      "('Epoch: 586/1000', 'Iteration: 2935', 'Train loss: 0.159335', 'Train acc: 0.946667')\n",
      "('Epoch: 587/1000', 'Iteration: 2940', 'Train loss: 0.152082', 'Train acc: 0.950000')\n",
      "('Epoch: 587/1000', 'Iteration: 2940', 'Validation loss: 0.430809', 'Validation acc: 0.900000')\n",
      "('Epoch: 588/1000', 'Iteration: 2945', 'Train loss: 0.145475', 'Train acc: 0.958333')\n",
      "('Epoch: 589/1000', 'Iteration: 2950', 'Train loss: 0.134856', 'Train acc: 0.961667')\n",
      "('Epoch: 589/1000', 'Iteration: 2950', 'Validation loss: 0.425245', 'Validation acc: 0.900000')\n",
      "('Epoch: 590/1000', 'Iteration: 2955', 'Train loss: 0.132387', 'Train acc: 0.961667')\n",
      "('Epoch: 591/1000', 'Iteration: 2960', 'Train loss: 0.148112', 'Train acc: 0.956667')\n",
      "('Epoch: 591/1000', 'Iteration: 2960', 'Validation loss: 0.423773', 'Validation acc: 0.898333')\n",
      "('Epoch: 592/1000', 'Iteration: 2965', 'Train loss: 0.135904', 'Train acc: 0.968333')\n",
      "('Epoch: 593/1000', 'Iteration: 2970', 'Train loss: 0.135922', 'Train acc: 0.960000')\n",
      "('Epoch: 593/1000', 'Iteration: 2970', 'Validation loss: 0.427682', 'Validation acc: 0.898333')\n",
      "('Epoch: 594/1000', 'Iteration: 2975', 'Train loss: 0.127649', 'Train acc: 0.961667')\n",
      "('Epoch: 595/1000', 'Iteration: 2980', 'Train loss: 0.151138', 'Train acc: 0.953333')\n",
      "('Epoch: 595/1000', 'Iteration: 2980', 'Validation loss: 0.423460', 'Validation acc: 0.898333')\n",
      "('Epoch: 596/1000', 'Iteration: 2985', 'Train loss: 0.156279', 'Train acc: 0.946667')\n",
      "('Epoch: 597/1000', 'Iteration: 2990', 'Train loss: 0.147257', 'Train acc: 0.960000')\n",
      "('Epoch: 597/1000', 'Iteration: 2990', 'Validation loss: 0.425967', 'Validation acc: 0.898333')\n",
      "('Epoch: 598/1000', 'Iteration: 2995', 'Train loss: 0.142573', 'Train acc: 0.963333')\n",
      "('Epoch: 599/1000', 'Iteration: 3000', 'Train loss: 0.143490', 'Train acc: 0.961667')\n",
      "('Epoch: 599/1000', 'Iteration: 3000', 'Validation loss: 0.425276', 'Validation acc: 0.896667')\n",
      "('Epoch: 600/1000', 'Iteration: 3005', 'Train loss: 0.124210', 'Train acc: 0.966667')\n",
      "('Epoch: 601/1000', 'Iteration: 3010', 'Train loss: 0.135044', 'Train acc: 0.963333')\n",
      "('Epoch: 601/1000', 'Iteration: 3010', 'Validation loss: 0.424899', 'Validation acc: 0.900000')\n",
      "('Epoch: 602/1000', 'Iteration: 3015', 'Train loss: 0.126603', 'Train acc: 0.968333')\n",
      "('Epoch: 603/1000', 'Iteration: 3020', 'Train loss: 0.145538', 'Train acc: 0.950000')\n",
      "('Epoch: 603/1000', 'Iteration: 3020', 'Validation loss: 0.425073', 'Validation acc: 0.903333')\n",
      "('Epoch: 604/1000', 'Iteration: 3025', 'Train loss: 0.121042', 'Train acc: 0.968333')\n",
      "('Epoch: 605/1000', 'Iteration: 3030', 'Train loss: 0.157877', 'Train acc: 0.940000')\n",
      "('Epoch: 605/1000', 'Iteration: 3030', 'Validation loss: 0.429088', 'Validation acc: 0.898333')\n",
      "('Epoch: 606/1000', 'Iteration: 3035', 'Train loss: 0.131223', 'Train acc: 0.955000')\n",
      "('Epoch: 607/1000', 'Iteration: 3040', 'Train loss: 0.127041', 'Train acc: 0.965000')\n",
      "('Epoch: 607/1000', 'Iteration: 3040', 'Validation loss: 0.427304', 'Validation acc: 0.896667')\n",
      "('Epoch: 608/1000', 'Iteration: 3045', 'Train loss: 0.140481', 'Train acc: 0.960000')\n",
      "('Epoch: 609/1000', 'Iteration: 3050', 'Train loss: 0.131584', 'Train acc: 0.965000')\n",
      "('Epoch: 609/1000', 'Iteration: 3050', 'Validation loss: 0.426929', 'Validation acc: 0.901667')\n",
      "('Epoch: 610/1000', 'Iteration: 3055', 'Train loss: 0.119274', 'Train acc: 0.970000')\n",
      "('Epoch: 611/1000', 'Iteration: 3060', 'Train loss: 0.128455', 'Train acc: 0.960000')\n",
      "('Epoch: 611/1000', 'Iteration: 3060', 'Validation loss: 0.429328', 'Validation acc: 0.903333')\n",
      "('Epoch: 612/1000', 'Iteration: 3065', 'Train loss: 0.152676', 'Train acc: 0.960000')\n",
      "('Epoch: 613/1000', 'Iteration: 3070', 'Train loss: 0.126761', 'Train acc: 0.966667')\n",
      "('Epoch: 613/1000', 'Iteration: 3070', 'Validation loss: 0.424192', 'Validation acc: 0.900000')\n",
      "('Epoch: 614/1000', 'Iteration: 3075', 'Train loss: 0.134324', 'Train acc: 0.960000')\n",
      "('Epoch: 615/1000', 'Iteration: 3080', 'Train loss: 0.135318', 'Train acc: 0.961667')\n",
      "('Epoch: 615/1000', 'Iteration: 3080', 'Validation loss: 0.420795', 'Validation acc: 0.905000')\n",
      "('Epoch: 616/1000', 'Iteration: 3085', 'Train loss: 0.115968', 'Train acc: 0.976667')\n",
      "('Epoch: 617/1000', 'Iteration: 3090', 'Train loss: 0.110106', 'Train acc: 0.965000')\n",
      "('Epoch: 617/1000', 'Iteration: 3090', 'Validation loss: 0.423764', 'Validation acc: 0.905000')\n",
      "('Epoch: 618/1000', 'Iteration: 3095', 'Train loss: 0.144721', 'Train acc: 0.956667')\n",
      "('Epoch: 619/1000', 'Iteration: 3100', 'Train loss: 0.138709', 'Train acc: 0.961667')\n",
      "('Epoch: 619/1000', 'Iteration: 3100', 'Validation loss: 0.419866', 'Validation acc: 0.898333')\n",
      "('Epoch: 620/1000', 'Iteration: 3105', 'Train loss: 0.113025', 'Train acc: 0.975000')\n",
      "('Epoch: 621/1000', 'Iteration: 3110', 'Train loss: 0.116715', 'Train acc: 0.968333')\n",
      "('Epoch: 621/1000', 'Iteration: 3110', 'Validation loss: 0.430857', 'Validation acc: 0.903333')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 622/1000', 'Iteration: 3115', 'Train loss: 0.127726', 'Train acc: 0.960000')\n",
      "('Epoch: 623/1000', 'Iteration: 3120', 'Train loss: 0.139020', 'Train acc: 0.958333')\n",
      "('Epoch: 623/1000', 'Iteration: 3120', 'Validation loss: 0.418684', 'Validation acc: 0.905000')\n",
      "('Epoch: 624/1000', 'Iteration: 3125', 'Train loss: 0.116131', 'Train acc: 0.970000')\n",
      "('Epoch: 625/1000', 'Iteration: 3130', 'Train loss: 0.144370', 'Train acc: 0.953333')\n",
      "('Epoch: 625/1000', 'Iteration: 3130', 'Validation loss: 0.425543', 'Validation acc: 0.905000')\n",
      "('Epoch: 626/1000', 'Iteration: 3135', 'Train loss: 0.126299', 'Train acc: 0.968333')\n",
      "('Epoch: 627/1000', 'Iteration: 3140', 'Train loss: 0.128388', 'Train acc: 0.965000')\n",
      "('Epoch: 627/1000', 'Iteration: 3140', 'Validation loss: 0.424330', 'Validation acc: 0.901667')\n",
      "('Epoch: 628/1000', 'Iteration: 3145', 'Train loss: 0.116216', 'Train acc: 0.973333')\n",
      "('Epoch: 629/1000', 'Iteration: 3150', 'Train loss: 0.140697', 'Train acc: 0.953333')\n",
      "('Epoch: 629/1000', 'Iteration: 3150', 'Validation loss: 0.426946', 'Validation acc: 0.901667')\n",
      "('Epoch: 630/1000', 'Iteration: 3155', 'Train loss: 0.129133', 'Train acc: 0.958333')\n",
      "('Epoch: 631/1000', 'Iteration: 3160', 'Train loss: 0.132378', 'Train acc: 0.963333')\n",
      "('Epoch: 631/1000', 'Iteration: 3160', 'Validation loss: 0.423015', 'Validation acc: 0.905000')\n",
      "('Epoch: 632/1000', 'Iteration: 3165', 'Train loss: 0.120043', 'Train acc: 0.966667')\n",
      "('Epoch: 633/1000', 'Iteration: 3170', 'Train loss: 0.121667', 'Train acc: 0.963333')\n",
      "('Epoch: 633/1000', 'Iteration: 3170', 'Validation loss: 0.425230', 'Validation acc: 0.903333')\n",
      "('Epoch: 634/1000', 'Iteration: 3175', 'Train loss: 0.123201', 'Train acc: 0.948333')\n",
      "('Epoch: 635/1000', 'Iteration: 3180', 'Train loss: 0.113998', 'Train acc: 0.973333')\n",
      "('Epoch: 635/1000', 'Iteration: 3180', 'Validation loss: 0.421408', 'Validation acc: 0.900000')\n",
      "('Epoch: 636/1000', 'Iteration: 3185', 'Train loss: 0.137913', 'Train acc: 0.955000')\n",
      "('Epoch: 637/1000', 'Iteration: 3190', 'Train loss: 0.121898', 'Train acc: 0.961667')\n",
      "('Epoch: 637/1000', 'Iteration: 3190', 'Validation loss: 0.423352', 'Validation acc: 0.903333')\n",
      "('Epoch: 638/1000', 'Iteration: 3195', 'Train loss: 0.132058', 'Train acc: 0.958333')\n",
      "('Epoch: 639/1000', 'Iteration: 3200', 'Train loss: 0.136296', 'Train acc: 0.955000')\n",
      "('Epoch: 639/1000', 'Iteration: 3200', 'Validation loss: 0.425022', 'Validation acc: 0.901667')\n",
      "('Epoch: 640/1000', 'Iteration: 3205', 'Train loss: 0.121836', 'Train acc: 0.970000')\n",
      "('Epoch: 641/1000', 'Iteration: 3210', 'Train loss: 0.110082', 'Train acc: 0.970000')\n",
      "('Epoch: 641/1000', 'Iteration: 3210', 'Validation loss: 0.422870', 'Validation acc: 0.903333')\n",
      "('Epoch: 642/1000', 'Iteration: 3215', 'Train loss: 0.128668', 'Train acc: 0.970000')\n",
      "('Epoch: 643/1000', 'Iteration: 3220', 'Train loss: 0.108691', 'Train acc: 0.961667')\n",
      "('Epoch: 643/1000', 'Iteration: 3220', 'Validation loss: 0.421935', 'Validation acc: 0.903333')\n",
      "('Epoch: 644/1000', 'Iteration: 3225', 'Train loss: 0.129861', 'Train acc: 0.956667')\n",
      "('Epoch: 645/1000', 'Iteration: 3230', 'Train loss: 0.113873', 'Train acc: 0.973333')\n",
      "('Epoch: 645/1000', 'Iteration: 3230', 'Validation loss: 0.425349', 'Validation acc: 0.905000')\n",
      "('Epoch: 646/1000', 'Iteration: 3235', 'Train loss: 0.121411', 'Train acc: 0.960000')\n",
      "('Epoch: 647/1000', 'Iteration: 3240', 'Train loss: 0.122472', 'Train acc: 0.966667')\n",
      "('Epoch: 647/1000', 'Iteration: 3240', 'Validation loss: 0.426092', 'Validation acc: 0.900000')\n",
      "('Epoch: 648/1000', 'Iteration: 3245', 'Train loss: 0.119935', 'Train acc: 0.971667')\n",
      "('Epoch: 649/1000', 'Iteration: 3250', 'Train loss: 0.119715', 'Train acc: 0.968333')\n",
      "('Epoch: 649/1000', 'Iteration: 3250', 'Validation loss: 0.427479', 'Validation acc: 0.900000')\n",
      "('Epoch: 650/1000', 'Iteration: 3255', 'Train loss: 0.129706', 'Train acc: 0.956667')\n",
      "('Epoch: 651/1000', 'Iteration: 3260', 'Train loss: 0.106497', 'Train acc: 0.973333')\n",
      "('Epoch: 651/1000', 'Iteration: 3260', 'Validation loss: 0.421925', 'Validation acc: 0.898333')\n",
      "('Epoch: 652/1000', 'Iteration: 3265', 'Train loss: 0.118509', 'Train acc: 0.968333')\n",
      "('Epoch: 653/1000', 'Iteration: 3270', 'Train loss: 0.116590', 'Train acc: 0.963333')\n",
      "('Epoch: 653/1000', 'Iteration: 3270', 'Validation loss: 0.420407', 'Validation acc: 0.903333')\n",
      "('Epoch: 654/1000', 'Iteration: 3275', 'Train loss: 0.127340', 'Train acc: 0.963333')\n",
      "('Epoch: 655/1000', 'Iteration: 3280', 'Train loss: 0.120105', 'Train acc: 0.968333')\n",
      "('Epoch: 655/1000', 'Iteration: 3280', 'Validation loss: 0.418105', 'Validation acc: 0.905000')\n",
      "('Epoch: 656/1000', 'Iteration: 3285', 'Train loss: 0.114042', 'Train acc: 0.966667')\n",
      "('Epoch: 657/1000', 'Iteration: 3290', 'Train loss: 0.126766', 'Train acc: 0.960000')\n",
      "('Epoch: 657/1000', 'Iteration: 3290', 'Validation loss: 0.422879', 'Validation acc: 0.903333')\n",
      "('Epoch: 658/1000', 'Iteration: 3295', 'Train loss: 0.126193', 'Train acc: 0.965000')\n",
      "('Epoch: 659/1000', 'Iteration: 3300', 'Train loss: 0.122228', 'Train acc: 0.961667')\n",
      "('Epoch: 659/1000', 'Iteration: 3300', 'Validation loss: 0.422291', 'Validation acc: 0.901667')\n",
      "('Epoch: 660/1000', 'Iteration: 3305', 'Train loss: 0.103064', 'Train acc: 0.965000')\n",
      "('Epoch: 661/1000', 'Iteration: 3310', 'Train loss: 0.108709', 'Train acc: 0.966667')\n",
      "('Epoch: 661/1000', 'Iteration: 3310', 'Validation loss: 0.421672', 'Validation acc: 0.901667')\n",
      "('Epoch: 662/1000', 'Iteration: 3315', 'Train loss: 0.119778', 'Train acc: 0.956667')\n",
      "('Epoch: 663/1000', 'Iteration: 3320', 'Train loss: 0.094684', 'Train acc: 0.976667')\n",
      "('Epoch: 663/1000', 'Iteration: 3320', 'Validation loss: 0.417609', 'Validation acc: 0.901667')\n",
      "('Epoch: 664/1000', 'Iteration: 3325', 'Train loss: 0.105356', 'Train acc: 0.975000')\n",
      "('Epoch: 665/1000', 'Iteration: 3330', 'Train loss: 0.136599', 'Train acc: 0.956667')\n",
      "('Epoch: 665/1000', 'Iteration: 3330', 'Validation loss: 0.414906', 'Validation acc: 0.901667')\n",
      "('Epoch: 666/1000', 'Iteration: 3335', 'Train loss: 0.103083', 'Train acc: 0.966667')\n",
      "('Epoch: 667/1000', 'Iteration: 3340', 'Train loss: 0.108203', 'Train acc: 0.973333')\n",
      "('Epoch: 667/1000', 'Iteration: 3340', 'Validation loss: 0.429550', 'Validation acc: 0.903333')\n",
      "('Epoch: 668/1000', 'Iteration: 3345', 'Train loss: 0.132009', 'Train acc: 0.958333')\n",
      "('Epoch: 669/1000', 'Iteration: 3350', 'Train loss: 0.109979', 'Train acc: 0.968333')\n",
      "('Epoch: 669/1000', 'Iteration: 3350', 'Validation loss: 0.424081', 'Validation acc: 0.903333')\n",
      "('Epoch: 670/1000', 'Iteration: 3355', 'Train loss: 0.134676', 'Train acc: 0.968333')\n",
      "('Epoch: 671/1000', 'Iteration: 3360', 'Train loss: 0.106532', 'Train acc: 0.966667')\n",
      "('Epoch: 671/1000', 'Iteration: 3360', 'Validation loss: 0.427042', 'Validation acc: 0.901667')\n",
      "('Epoch: 672/1000', 'Iteration: 3365', 'Train loss: 0.108412', 'Train acc: 0.965000')\n",
      "('Epoch: 673/1000', 'Iteration: 3370', 'Train loss: 0.109190', 'Train acc: 0.966667')\n",
      "('Epoch: 673/1000', 'Iteration: 3370', 'Validation loss: 0.416380', 'Validation acc: 0.901667')\n",
      "('Epoch: 674/1000', 'Iteration: 3375', 'Train loss: 0.114476', 'Train acc: 0.968333')\n",
      "('Epoch: 675/1000', 'Iteration: 3380', 'Train loss: 0.103961', 'Train acc: 0.965000')\n",
      "('Epoch: 675/1000', 'Iteration: 3380', 'Validation loss: 0.420389', 'Validation acc: 0.906667')\n",
      "('Epoch: 676/1000', 'Iteration: 3385', 'Train loss: 0.111920', 'Train acc: 0.976667')\n",
      "('Epoch: 677/1000', 'Iteration: 3390', 'Train loss: 0.129264', 'Train acc: 0.953333')\n",
      "('Epoch: 677/1000', 'Iteration: 3390', 'Validation loss: 0.425975', 'Validation acc: 0.900000')\n",
      "('Epoch: 678/1000', 'Iteration: 3395', 'Train loss: 0.122240', 'Train acc: 0.966667')\n",
      "('Epoch: 679/1000', 'Iteration: 3400', 'Train loss: 0.104992', 'Train acc: 0.976667')\n",
      "('Epoch: 679/1000', 'Iteration: 3400', 'Validation loss: 0.422105', 'Validation acc: 0.901667')\n",
      "('Epoch: 680/1000', 'Iteration: 3405', 'Train loss: 0.111634', 'Train acc: 0.968333')\n",
      "('Epoch: 681/1000', 'Iteration: 3410', 'Train loss: 0.117761', 'Train acc: 0.966667')\n",
      "('Epoch: 681/1000', 'Iteration: 3410', 'Validation loss: 0.416330', 'Validation acc: 0.903333')\n",
      "('Epoch: 682/1000', 'Iteration: 3415', 'Train loss: 0.117312', 'Train acc: 0.966667')\n",
      "('Epoch: 683/1000', 'Iteration: 3420', 'Train loss: 0.094614', 'Train acc: 0.970000')\n",
      "('Epoch: 683/1000', 'Iteration: 3420', 'Validation loss: 0.424693', 'Validation acc: 0.905000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 684/1000', 'Iteration: 3425', 'Train loss: 0.097759', 'Train acc: 0.975000')\n",
      "('Epoch: 685/1000', 'Iteration: 3430', 'Train loss: 0.087298', 'Train acc: 0.983333')\n",
      "('Epoch: 685/1000', 'Iteration: 3430', 'Validation loss: 0.420427', 'Validation acc: 0.898333')\n",
      "('Epoch: 686/1000', 'Iteration: 3435', 'Train loss: 0.112059', 'Train acc: 0.968333')\n",
      "('Epoch: 687/1000', 'Iteration: 3440', 'Train loss: 0.098510', 'Train acc: 0.971667')\n",
      "('Epoch: 687/1000', 'Iteration: 3440', 'Validation loss: 0.426070', 'Validation acc: 0.905000')\n",
      "('Epoch: 688/1000', 'Iteration: 3445', 'Train loss: 0.110767', 'Train acc: 0.971667')\n",
      "('Epoch: 689/1000', 'Iteration: 3450', 'Train loss: 0.136130', 'Train acc: 0.956667')\n",
      "('Epoch: 689/1000', 'Iteration: 3450', 'Validation loss: 0.421321', 'Validation acc: 0.906667')\n",
      "('Epoch: 690/1000', 'Iteration: 3455', 'Train loss: 0.118248', 'Train acc: 0.963333')\n",
      "('Epoch: 691/1000', 'Iteration: 3460', 'Train loss: 0.101930', 'Train acc: 0.968333')\n",
      "('Epoch: 691/1000', 'Iteration: 3460', 'Validation loss: 0.414483', 'Validation acc: 0.901667')\n",
      "('Epoch: 692/1000', 'Iteration: 3465', 'Train loss: 0.106260', 'Train acc: 0.965000')\n",
      "('Epoch: 693/1000', 'Iteration: 3470', 'Train loss: 0.109350', 'Train acc: 0.963333')\n",
      "('Epoch: 693/1000', 'Iteration: 3470', 'Validation loss: 0.425411', 'Validation acc: 0.900000')\n",
      "('Epoch: 694/1000', 'Iteration: 3475', 'Train loss: 0.119195', 'Train acc: 0.965000')\n",
      "('Epoch: 695/1000', 'Iteration: 3480', 'Train loss: 0.098893', 'Train acc: 0.971667')\n",
      "('Epoch: 695/1000', 'Iteration: 3480', 'Validation loss: 0.421914', 'Validation acc: 0.900000')\n",
      "('Epoch: 696/1000', 'Iteration: 3485', 'Train loss: 0.098976', 'Train acc: 0.973333')\n",
      "('Epoch: 697/1000', 'Iteration: 3490', 'Train loss: 0.107334', 'Train acc: 0.970000')\n",
      "('Epoch: 697/1000', 'Iteration: 3490', 'Validation loss: 0.416330', 'Validation acc: 0.906667')\n",
      "('Epoch: 698/1000', 'Iteration: 3495', 'Train loss: 0.097165', 'Train acc: 0.971667')\n",
      "('Epoch: 699/1000', 'Iteration: 3500', 'Train loss: 0.097820', 'Train acc: 0.971667')\n",
      "('Epoch: 699/1000', 'Iteration: 3500', 'Validation loss: 0.418507', 'Validation acc: 0.908333')\n",
      "('Epoch: 700/1000', 'Iteration: 3505', 'Train loss: 0.106659', 'Train acc: 0.970000')\n",
      "('Epoch: 701/1000', 'Iteration: 3510', 'Train loss: 0.096495', 'Train acc: 0.978333')\n",
      "('Epoch: 701/1000', 'Iteration: 3510', 'Validation loss: 0.419203', 'Validation acc: 0.903333')\n",
      "('Epoch: 702/1000', 'Iteration: 3515', 'Train loss: 0.108206', 'Train acc: 0.958333')\n",
      "('Epoch: 703/1000', 'Iteration: 3520', 'Train loss: 0.094358', 'Train acc: 0.975000')\n",
      "('Epoch: 703/1000', 'Iteration: 3520', 'Validation loss: 0.425903', 'Validation acc: 0.905000')\n",
      "('Epoch: 704/1000', 'Iteration: 3525', 'Train loss: 0.101921', 'Train acc: 0.975000')\n",
      "('Epoch: 705/1000', 'Iteration: 3530', 'Train loss: 0.094482', 'Train acc: 0.980000')\n",
      "('Epoch: 705/1000', 'Iteration: 3530', 'Validation loss: 0.420568', 'Validation acc: 0.903333')\n",
      "('Epoch: 706/1000', 'Iteration: 3535', 'Train loss: 0.091993', 'Train acc: 0.980000')\n",
      "('Epoch: 707/1000', 'Iteration: 3540', 'Train loss: 0.110093', 'Train acc: 0.963333')\n",
      "('Epoch: 707/1000', 'Iteration: 3540', 'Validation loss: 0.417797', 'Validation acc: 0.901667')\n",
      "('Epoch: 708/1000', 'Iteration: 3545', 'Train loss: 0.101025', 'Train acc: 0.970000')\n",
      "('Epoch: 709/1000', 'Iteration: 3550', 'Train loss: 0.099143', 'Train acc: 0.965000')\n",
      "('Epoch: 709/1000', 'Iteration: 3550', 'Validation loss: 0.418807', 'Validation acc: 0.905000')\n",
      "('Epoch: 710/1000', 'Iteration: 3555', 'Train loss: 0.108705', 'Train acc: 0.968333')\n",
      "('Epoch: 711/1000', 'Iteration: 3560', 'Train loss: 0.093768', 'Train acc: 0.973333')\n",
      "('Epoch: 711/1000', 'Iteration: 3560', 'Validation loss: 0.423355', 'Validation acc: 0.905000')\n",
      "('Epoch: 712/1000', 'Iteration: 3565', 'Train loss: 0.089979', 'Train acc: 0.980000')\n",
      "('Epoch: 713/1000', 'Iteration: 3570', 'Train loss: 0.099595', 'Train acc: 0.971667')\n",
      "('Epoch: 713/1000', 'Iteration: 3570', 'Validation loss: 0.420994', 'Validation acc: 0.906667')\n",
      "('Epoch: 714/1000', 'Iteration: 3575', 'Train loss: 0.091735', 'Train acc: 0.971667')\n",
      "('Epoch: 715/1000', 'Iteration: 3580', 'Train loss: 0.109511', 'Train acc: 0.965000')\n",
      "('Epoch: 715/1000', 'Iteration: 3580', 'Validation loss: 0.420344', 'Validation acc: 0.905000')\n",
      "('Epoch: 716/1000', 'Iteration: 3585', 'Train loss: 0.099069', 'Train acc: 0.970000')\n",
      "('Epoch: 717/1000', 'Iteration: 3590', 'Train loss: 0.083763', 'Train acc: 0.980000')\n",
      "('Epoch: 717/1000', 'Iteration: 3590', 'Validation loss: 0.421373', 'Validation acc: 0.906667')\n",
      "('Epoch: 718/1000', 'Iteration: 3595', 'Train loss: 0.109233', 'Train acc: 0.968333')\n",
      "('Epoch: 719/1000', 'Iteration: 3600', 'Train loss: 0.106456', 'Train acc: 0.973333')\n",
      "('Epoch: 719/1000', 'Iteration: 3600', 'Validation loss: 0.422915', 'Validation acc: 0.903333')\n",
      "('Epoch: 720/1000', 'Iteration: 3605', 'Train loss: 0.109014', 'Train acc: 0.971667')\n",
      "('Epoch: 721/1000', 'Iteration: 3610', 'Train loss: 0.107063', 'Train acc: 0.968333')\n",
      "('Epoch: 721/1000', 'Iteration: 3610', 'Validation loss: 0.417812', 'Validation acc: 0.905000')\n",
      "('Epoch: 722/1000', 'Iteration: 3615', 'Train loss: 0.091454', 'Train acc: 0.976667')\n",
      "('Epoch: 723/1000', 'Iteration: 3620', 'Train loss: 0.085485', 'Train acc: 0.976667')\n",
      "('Epoch: 723/1000', 'Iteration: 3620', 'Validation loss: 0.424937', 'Validation acc: 0.903333')\n",
      "('Epoch: 724/1000', 'Iteration: 3625', 'Train loss: 0.094324', 'Train acc: 0.966667')\n",
      "('Epoch: 725/1000', 'Iteration: 3630', 'Train loss: 0.114127', 'Train acc: 0.965000')\n",
      "('Epoch: 725/1000', 'Iteration: 3630', 'Validation loss: 0.415793', 'Validation acc: 0.903333')\n",
      "('Epoch: 726/1000', 'Iteration: 3635', 'Train loss: 0.103706', 'Train acc: 0.973333')\n",
      "('Epoch: 727/1000', 'Iteration: 3640', 'Train loss: 0.100129', 'Train acc: 0.970000')\n",
      "('Epoch: 727/1000', 'Iteration: 3640', 'Validation loss: 0.426597', 'Validation acc: 0.903333')\n",
      "('Epoch: 728/1000', 'Iteration: 3645', 'Train loss: 0.069017', 'Train acc: 0.986667')\n",
      "('Epoch: 729/1000', 'Iteration: 3650', 'Train loss: 0.095645', 'Train acc: 0.971667')\n",
      "('Epoch: 729/1000', 'Iteration: 3650', 'Validation loss: 0.421447', 'Validation acc: 0.905000')\n",
      "('Epoch: 730/1000', 'Iteration: 3655', 'Train loss: 0.104041', 'Train acc: 0.968333')\n",
      "('Epoch: 731/1000', 'Iteration: 3660', 'Train loss: 0.109194', 'Train acc: 0.970000')\n",
      "('Epoch: 731/1000', 'Iteration: 3660', 'Validation loss: 0.420410', 'Validation acc: 0.903333')\n",
      "('Epoch: 732/1000', 'Iteration: 3665', 'Train loss: 0.097218', 'Train acc: 0.970000')\n",
      "('Epoch: 733/1000', 'Iteration: 3670', 'Train loss: 0.086718', 'Train acc: 0.976667')\n",
      "('Epoch: 733/1000', 'Iteration: 3670', 'Validation loss: 0.419088', 'Validation acc: 0.906667')\n",
      "('Epoch: 734/1000', 'Iteration: 3675', 'Train loss: 0.085331', 'Train acc: 0.983333')\n",
      "('Epoch: 735/1000', 'Iteration: 3680', 'Train loss: 0.099854', 'Train acc: 0.966667')\n",
      "('Epoch: 735/1000', 'Iteration: 3680', 'Validation loss: 0.416350', 'Validation acc: 0.903333')\n",
      "('Epoch: 736/1000', 'Iteration: 3685', 'Train loss: 0.088117', 'Train acc: 0.978333')\n",
      "('Epoch: 737/1000', 'Iteration: 3690', 'Train loss: 0.089438', 'Train acc: 0.980000')\n",
      "('Epoch: 737/1000', 'Iteration: 3690', 'Validation loss: 0.416901', 'Validation acc: 0.903333')\n",
      "('Epoch: 738/1000', 'Iteration: 3695', 'Train loss: 0.088898', 'Train acc: 0.981667')\n",
      "('Epoch: 739/1000', 'Iteration: 3700', 'Train loss: 0.092740', 'Train acc: 0.976667')\n",
      "('Epoch: 739/1000', 'Iteration: 3700', 'Validation loss: 0.419945', 'Validation acc: 0.905000')\n",
      "('Epoch: 740/1000', 'Iteration: 3705', 'Train loss: 0.091250', 'Train acc: 0.973333')\n",
      "('Epoch: 741/1000', 'Iteration: 3710', 'Train loss: 0.095171', 'Train acc: 0.976667')\n",
      "('Epoch: 741/1000', 'Iteration: 3710', 'Validation loss: 0.420959', 'Validation acc: 0.905000')\n",
      "('Epoch: 742/1000', 'Iteration: 3715', 'Train loss: 0.102356', 'Train acc: 0.966667')\n",
      "('Epoch: 743/1000', 'Iteration: 3720', 'Train loss: 0.096327', 'Train acc: 0.975000')\n",
      "('Epoch: 743/1000', 'Iteration: 3720', 'Validation loss: 0.427041', 'Validation acc: 0.906667')\n",
      "('Epoch: 744/1000', 'Iteration: 3725', 'Train loss: 0.084702', 'Train acc: 0.981667')\n",
      "('Epoch: 745/1000', 'Iteration: 3730', 'Train loss: 0.106856', 'Train acc: 0.966667')\n",
      "('Epoch: 745/1000', 'Iteration: 3730', 'Validation loss: 0.422080', 'Validation acc: 0.905000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 746/1000', 'Iteration: 3735', 'Train loss: 0.107045', 'Train acc: 0.971667')\n",
      "('Epoch: 747/1000', 'Iteration: 3740', 'Train loss: 0.078905', 'Train acc: 0.978333')\n",
      "('Epoch: 747/1000', 'Iteration: 3740', 'Validation loss: 0.421543', 'Validation acc: 0.905000')\n",
      "('Epoch: 748/1000', 'Iteration: 3745', 'Train loss: 0.080518', 'Train acc: 0.973333')\n",
      "('Epoch: 749/1000', 'Iteration: 3750', 'Train loss: 0.086559', 'Train acc: 0.976667')\n",
      "('Epoch: 749/1000', 'Iteration: 3750', 'Validation loss: 0.429889', 'Validation acc: 0.905000')\n",
      "('Epoch: 750/1000', 'Iteration: 3755', 'Train loss: 0.096279', 'Train acc: 0.970000')\n",
      "('Epoch: 751/1000', 'Iteration: 3760', 'Train loss: 0.090832', 'Train acc: 0.978333')\n",
      "('Epoch: 751/1000', 'Iteration: 3760', 'Validation loss: 0.422002', 'Validation acc: 0.908333')\n",
      "('Epoch: 752/1000', 'Iteration: 3765', 'Train loss: 0.082833', 'Train acc: 0.976667')\n",
      "('Epoch: 753/1000', 'Iteration: 3770', 'Train loss: 0.092224', 'Train acc: 0.973333')\n",
      "('Epoch: 753/1000', 'Iteration: 3770', 'Validation loss: 0.418487', 'Validation acc: 0.906667')\n",
      "('Epoch: 754/1000', 'Iteration: 3775', 'Train loss: 0.085346', 'Train acc: 0.976667')\n",
      "('Epoch: 755/1000', 'Iteration: 3780', 'Train loss: 0.096427', 'Train acc: 0.970000')\n",
      "('Epoch: 755/1000', 'Iteration: 3780', 'Validation loss: 0.426716', 'Validation acc: 0.905000')\n",
      "('Epoch: 756/1000', 'Iteration: 3785', 'Train loss: 0.087342', 'Train acc: 0.978333')\n",
      "('Epoch: 757/1000', 'Iteration: 3790', 'Train loss: 0.108519', 'Train acc: 0.965000')\n",
      "('Epoch: 757/1000', 'Iteration: 3790', 'Validation loss: 0.419511', 'Validation acc: 0.906667')\n",
      "('Epoch: 758/1000', 'Iteration: 3795', 'Train loss: 0.087436', 'Train acc: 0.970000')\n",
      "('Epoch: 759/1000', 'Iteration: 3800', 'Train loss: 0.093557', 'Train acc: 0.970000')\n",
      "('Epoch: 759/1000', 'Iteration: 3800', 'Validation loss: 0.421509', 'Validation acc: 0.905000')\n",
      "('Epoch: 760/1000', 'Iteration: 3805', 'Train loss: 0.099106', 'Train acc: 0.976667')\n",
      "('Epoch: 761/1000', 'Iteration: 3810', 'Train loss: 0.072539', 'Train acc: 0.981667')\n",
      "('Epoch: 761/1000', 'Iteration: 3810', 'Validation loss: 0.421148', 'Validation acc: 0.906667')\n",
      "('Epoch: 762/1000', 'Iteration: 3815', 'Train loss: 0.085420', 'Train acc: 0.975000')\n",
      "('Epoch: 763/1000', 'Iteration: 3820', 'Train loss: 0.092779', 'Train acc: 0.976667')\n",
      "('Epoch: 763/1000', 'Iteration: 3820', 'Validation loss: 0.415413', 'Validation acc: 0.910000')\n",
      "('Epoch: 764/1000', 'Iteration: 3825', 'Train loss: 0.092722', 'Train acc: 0.976667')\n",
      "('Epoch: 765/1000', 'Iteration: 3830', 'Train loss: 0.079623', 'Train acc: 0.985000')\n",
      "('Epoch: 765/1000', 'Iteration: 3830', 'Validation loss: 0.418816', 'Validation acc: 0.905000')\n",
      "('Epoch: 766/1000', 'Iteration: 3835', 'Train loss: 0.081692', 'Train acc: 0.980000')\n",
      "('Epoch: 767/1000', 'Iteration: 3840', 'Train loss: 0.091833', 'Train acc: 0.971667')\n",
      "('Epoch: 767/1000', 'Iteration: 3840', 'Validation loss: 0.415695', 'Validation acc: 0.906667')\n",
      "('Epoch: 768/1000', 'Iteration: 3845', 'Train loss: 0.090001', 'Train acc: 0.973333')\n",
      "('Epoch: 769/1000', 'Iteration: 3850', 'Train loss: 0.097277', 'Train acc: 0.970000')\n",
      "('Epoch: 769/1000', 'Iteration: 3850', 'Validation loss: 0.416665', 'Validation acc: 0.905000')\n",
      "('Epoch: 770/1000', 'Iteration: 3855', 'Train loss: 0.066785', 'Train acc: 0.986667')\n",
      "('Epoch: 771/1000', 'Iteration: 3860', 'Train loss: 0.076782', 'Train acc: 0.976667')\n",
      "('Epoch: 771/1000', 'Iteration: 3860', 'Validation loss: 0.418376', 'Validation acc: 0.906667')\n",
      "('Epoch: 772/1000', 'Iteration: 3865', 'Train loss: 0.099543', 'Train acc: 0.973333')\n",
      "('Epoch: 773/1000', 'Iteration: 3870', 'Train loss: 0.083772', 'Train acc: 0.970000')\n",
      "('Epoch: 773/1000', 'Iteration: 3870', 'Validation loss: 0.426788', 'Validation acc: 0.905000')\n",
      "('Epoch: 774/1000', 'Iteration: 3875', 'Train loss: 0.078388', 'Train acc: 0.975000')\n",
      "('Epoch: 775/1000', 'Iteration: 3880', 'Train loss: 0.094413', 'Train acc: 0.971667')\n",
      "('Epoch: 775/1000', 'Iteration: 3880', 'Validation loss: 0.418781', 'Validation acc: 0.905000')\n",
      "('Epoch: 776/1000', 'Iteration: 3885', 'Train loss: 0.093029', 'Train acc: 0.976667')\n",
      "('Epoch: 777/1000', 'Iteration: 3890', 'Train loss: 0.083515', 'Train acc: 0.973333')\n",
      "('Epoch: 777/1000', 'Iteration: 3890', 'Validation loss: 0.424533', 'Validation acc: 0.903333')\n",
      "('Epoch: 778/1000', 'Iteration: 3895', 'Train loss: 0.095093', 'Train acc: 0.970000')\n",
      "('Epoch: 779/1000', 'Iteration: 3900', 'Train loss: 0.086558', 'Train acc: 0.970000')\n",
      "('Epoch: 779/1000', 'Iteration: 3900', 'Validation loss: 0.428000', 'Validation acc: 0.908333')\n",
      "('Epoch: 780/1000', 'Iteration: 3905', 'Train loss: 0.070896', 'Train acc: 0.985000')\n",
      "('Epoch: 781/1000', 'Iteration: 3910', 'Train loss: 0.079578', 'Train acc: 0.983333')\n",
      "('Epoch: 781/1000', 'Iteration: 3910', 'Validation loss: 0.420488', 'Validation acc: 0.903333')\n",
      "('Epoch: 782/1000', 'Iteration: 3915', 'Train loss: 0.088343', 'Train acc: 0.970000')\n",
      "('Epoch: 783/1000', 'Iteration: 3920', 'Train loss: 0.096366', 'Train acc: 0.966667')\n",
      "('Epoch: 783/1000', 'Iteration: 3920', 'Validation loss: 0.414155', 'Validation acc: 0.906667')\n",
      "('Epoch: 784/1000', 'Iteration: 3925', 'Train loss: 0.075469', 'Train acc: 0.983333')\n",
      "('Epoch: 785/1000', 'Iteration: 3930', 'Train loss: 0.073321', 'Train acc: 0.985000')\n",
      "('Epoch: 785/1000', 'Iteration: 3930', 'Validation loss: 0.422883', 'Validation acc: 0.905000')\n",
      "('Epoch: 786/1000', 'Iteration: 3935', 'Train loss: 0.084244', 'Train acc: 0.976667')\n",
      "('Epoch: 787/1000', 'Iteration: 3940', 'Train loss: 0.077314', 'Train acc: 0.986667')\n",
      "('Epoch: 787/1000', 'Iteration: 3940', 'Validation loss: 0.419223', 'Validation acc: 0.905000')\n",
      "('Epoch: 788/1000', 'Iteration: 3945', 'Train loss: 0.099124', 'Train acc: 0.965000')\n",
      "('Epoch: 789/1000', 'Iteration: 3950', 'Train loss: 0.083088', 'Train acc: 0.976667')\n",
      "('Epoch: 789/1000', 'Iteration: 3950', 'Validation loss: 0.419894', 'Validation acc: 0.908333')\n",
      "('Epoch: 790/1000', 'Iteration: 3955', 'Train loss: 0.094092', 'Train acc: 0.975000')\n",
      "('Epoch: 791/1000', 'Iteration: 3960', 'Train loss: 0.082825', 'Train acc: 0.978333')\n",
      "('Epoch: 791/1000', 'Iteration: 3960', 'Validation loss: 0.420281', 'Validation acc: 0.905000')\n",
      "('Epoch: 792/1000', 'Iteration: 3965', 'Train loss: 0.077047', 'Train acc: 0.973333')\n",
      "('Epoch: 793/1000', 'Iteration: 3970', 'Train loss: 0.088509', 'Train acc: 0.971667')\n",
      "('Epoch: 793/1000', 'Iteration: 3970', 'Validation loss: 0.419887', 'Validation acc: 0.905000')\n",
      "('Epoch: 794/1000', 'Iteration: 3975', 'Train loss: 0.080532', 'Train acc: 0.975000')\n",
      "('Epoch: 795/1000', 'Iteration: 3980', 'Train loss: 0.081286', 'Train acc: 0.976667')\n",
      "('Epoch: 795/1000', 'Iteration: 3980', 'Validation loss: 0.423499', 'Validation acc: 0.908333')\n",
      "('Epoch: 796/1000', 'Iteration: 3985', 'Train loss: 0.082511', 'Train acc: 0.975000')\n",
      "('Epoch: 797/1000', 'Iteration: 3990', 'Train loss: 0.090508', 'Train acc: 0.970000')\n",
      "('Epoch: 797/1000', 'Iteration: 3990', 'Validation loss: 0.421171', 'Validation acc: 0.906667')\n",
      "('Epoch: 798/1000', 'Iteration: 3995', 'Train loss: 0.091864', 'Train acc: 0.975000')\n",
      "('Epoch: 799/1000', 'Iteration: 4000', 'Train loss: 0.084720', 'Train acc: 0.976667')\n",
      "('Epoch: 799/1000', 'Iteration: 4000', 'Validation loss: 0.422146', 'Validation acc: 0.906667')\n",
      "('Epoch: 800/1000', 'Iteration: 4005', 'Train loss: 0.079828', 'Train acc: 0.978333')\n",
      "('Epoch: 801/1000', 'Iteration: 4010', 'Train loss: 0.090092', 'Train acc: 0.975000')\n",
      "('Epoch: 801/1000', 'Iteration: 4010', 'Validation loss: 0.426221', 'Validation acc: 0.906667')\n",
      "('Epoch: 802/1000', 'Iteration: 4015', 'Train loss: 0.076316', 'Train acc: 0.981667')\n",
      "('Epoch: 803/1000', 'Iteration: 4020', 'Train loss: 0.075817', 'Train acc: 0.980000')\n",
      "('Epoch: 803/1000', 'Iteration: 4020', 'Validation loss: 0.421911', 'Validation acc: 0.905000')\n",
      "('Epoch: 804/1000', 'Iteration: 4025', 'Train loss: 0.085470', 'Train acc: 0.973333')\n",
      "('Epoch: 805/1000', 'Iteration: 4030', 'Train loss: 0.094499', 'Train acc: 0.973333')\n",
      "('Epoch: 805/1000', 'Iteration: 4030', 'Validation loss: 0.428114', 'Validation acc: 0.910000')\n",
      "('Epoch: 806/1000', 'Iteration: 4035', 'Train loss: 0.075614', 'Train acc: 0.981667')\n",
      "('Epoch: 807/1000', 'Iteration: 4040', 'Train loss: 0.063762', 'Train acc: 0.983333')\n",
      "('Epoch: 807/1000', 'Iteration: 4040', 'Validation loss: 0.422198', 'Validation acc: 0.903333')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 808/1000', 'Iteration: 4045', 'Train loss: 0.082532', 'Train acc: 0.980000')\n",
      "('Epoch: 809/1000', 'Iteration: 4050', 'Train loss: 0.082716', 'Train acc: 0.973333')\n",
      "('Epoch: 809/1000', 'Iteration: 4050', 'Validation loss: 0.424025', 'Validation acc: 0.905000')\n",
      "('Epoch: 810/1000', 'Iteration: 4055', 'Train loss: 0.086620', 'Train acc: 0.975000')\n",
      "('Epoch: 811/1000', 'Iteration: 4060', 'Train loss: 0.069511', 'Train acc: 0.980000')\n",
      "('Epoch: 811/1000', 'Iteration: 4060', 'Validation loss: 0.420671', 'Validation acc: 0.906667')\n",
      "('Epoch: 812/1000', 'Iteration: 4065', 'Train loss: 0.086281', 'Train acc: 0.976667')\n",
      "('Epoch: 813/1000', 'Iteration: 4070', 'Train loss: 0.087651', 'Train acc: 0.981667')\n",
      "('Epoch: 813/1000', 'Iteration: 4070', 'Validation loss: 0.424474', 'Validation acc: 0.906667')\n",
      "('Epoch: 814/1000', 'Iteration: 4075', 'Train loss: 0.088786', 'Train acc: 0.975000')\n",
      "('Epoch: 815/1000', 'Iteration: 4080', 'Train loss: 0.086005', 'Train acc: 0.973333')\n",
      "('Epoch: 815/1000', 'Iteration: 4080', 'Validation loss: 0.423965', 'Validation acc: 0.906667')\n",
      "('Epoch: 816/1000', 'Iteration: 4085', 'Train loss: 0.085599', 'Train acc: 0.976667')\n",
      "('Epoch: 817/1000', 'Iteration: 4090', 'Train loss: 0.077043', 'Train acc: 0.976667')\n",
      "('Epoch: 817/1000', 'Iteration: 4090', 'Validation loss: 0.425583', 'Validation acc: 0.905000')\n",
      "('Epoch: 818/1000', 'Iteration: 4095', 'Train loss: 0.080402', 'Train acc: 0.973333')\n",
      "('Epoch: 819/1000', 'Iteration: 4100', 'Train loss: 0.068103', 'Train acc: 0.985000')\n",
      "('Epoch: 819/1000', 'Iteration: 4100', 'Validation loss: 0.432976', 'Validation acc: 0.906667')\n",
      "('Epoch: 820/1000', 'Iteration: 4105', 'Train loss: 0.065755', 'Train acc: 0.986667')\n",
      "('Epoch: 821/1000', 'Iteration: 4110', 'Train loss: 0.072315', 'Train acc: 0.981667')\n",
      "('Epoch: 821/1000', 'Iteration: 4110', 'Validation loss: 0.421084', 'Validation acc: 0.906667')\n",
      "('Epoch: 822/1000', 'Iteration: 4115', 'Train loss: 0.068279', 'Train acc: 0.985000')\n",
      "('Epoch: 823/1000', 'Iteration: 4120', 'Train loss: 0.068638', 'Train acc: 0.978333')\n",
      "('Epoch: 823/1000', 'Iteration: 4120', 'Validation loss: 0.425534', 'Validation acc: 0.908333')\n",
      "('Epoch: 824/1000', 'Iteration: 4125', 'Train loss: 0.088901', 'Train acc: 0.971667')\n",
      "('Epoch: 825/1000', 'Iteration: 4130', 'Train loss: 0.070862', 'Train acc: 0.978333')\n",
      "('Epoch: 825/1000', 'Iteration: 4130', 'Validation loss: 0.428556', 'Validation acc: 0.906667')\n",
      "('Epoch: 826/1000', 'Iteration: 4135', 'Train loss: 0.059509', 'Train acc: 0.990000')\n",
      "('Epoch: 827/1000', 'Iteration: 4140', 'Train loss: 0.078513', 'Train acc: 0.980000')\n",
      "('Epoch: 827/1000', 'Iteration: 4140', 'Validation loss: 0.424025', 'Validation acc: 0.908333')\n",
      "('Epoch: 828/1000', 'Iteration: 4145', 'Train loss: 0.071053', 'Train acc: 0.975000')\n",
      "('Epoch: 829/1000', 'Iteration: 4150', 'Train loss: 0.090863', 'Train acc: 0.975000')\n",
      "('Epoch: 829/1000', 'Iteration: 4150', 'Validation loss: 0.430772', 'Validation acc: 0.911667')\n",
      "('Epoch: 830/1000', 'Iteration: 4155', 'Train loss: 0.070082', 'Train acc: 0.986667')\n",
      "('Epoch: 831/1000', 'Iteration: 4160', 'Train loss: 0.073935', 'Train acc: 0.983333')\n",
      "('Epoch: 831/1000', 'Iteration: 4160', 'Validation loss: 0.424991', 'Validation acc: 0.906667')\n",
      "('Epoch: 832/1000', 'Iteration: 4165', 'Train loss: 0.068867', 'Train acc: 0.980000')\n",
      "('Epoch: 833/1000', 'Iteration: 4170', 'Train loss: 0.075567', 'Train acc: 0.983333')\n",
      "('Epoch: 833/1000', 'Iteration: 4170', 'Validation loss: 0.418050', 'Validation acc: 0.906667')\n",
      "('Epoch: 834/1000', 'Iteration: 4175', 'Train loss: 0.078689', 'Train acc: 0.975000')\n",
      "('Epoch: 835/1000', 'Iteration: 4180', 'Train loss: 0.057643', 'Train acc: 0.990000')\n",
      "('Epoch: 835/1000', 'Iteration: 4180', 'Validation loss: 0.422566', 'Validation acc: 0.910000')\n",
      "('Epoch: 836/1000', 'Iteration: 4185', 'Train loss: 0.062138', 'Train acc: 0.986667')\n",
      "('Epoch: 837/1000', 'Iteration: 4190', 'Train loss: 0.086738', 'Train acc: 0.973333')\n",
      "('Epoch: 837/1000', 'Iteration: 4190', 'Validation loss: 0.421846', 'Validation acc: 0.906667')\n",
      "('Epoch: 838/1000', 'Iteration: 4195', 'Train loss: 0.071740', 'Train acc: 0.983333')\n",
      "('Epoch: 839/1000', 'Iteration: 4200', 'Train loss: 0.063681', 'Train acc: 0.985000')\n",
      "('Epoch: 839/1000', 'Iteration: 4200', 'Validation loss: 0.425587', 'Validation acc: 0.908333')\n",
      "('Epoch: 840/1000', 'Iteration: 4205', 'Train loss: 0.062601', 'Train acc: 0.988333')\n",
      "('Epoch: 841/1000', 'Iteration: 4210', 'Train loss: 0.071983', 'Train acc: 0.978333')\n",
      "('Epoch: 841/1000', 'Iteration: 4210', 'Validation loss: 0.416259', 'Validation acc: 0.903333')\n",
      "('Epoch: 842/1000', 'Iteration: 4215', 'Train loss: 0.067091', 'Train acc: 0.985000')\n",
      "('Epoch: 843/1000', 'Iteration: 4220', 'Train loss: 0.063150', 'Train acc: 0.988333')\n",
      "('Epoch: 843/1000', 'Iteration: 4220', 'Validation loss: 0.425238', 'Validation acc: 0.903333')\n",
      "('Epoch: 844/1000', 'Iteration: 4225', 'Train loss: 0.068735', 'Train acc: 0.983333')\n",
      "('Epoch: 845/1000', 'Iteration: 4230', 'Train loss: 0.085978', 'Train acc: 0.971667')\n",
      "('Epoch: 845/1000', 'Iteration: 4230', 'Validation loss: 0.424537', 'Validation acc: 0.905000')\n",
      "('Epoch: 846/1000', 'Iteration: 4235', 'Train loss: 0.084128', 'Train acc: 0.973333')\n",
      "('Epoch: 847/1000', 'Iteration: 4240', 'Train loss: 0.082303', 'Train acc: 0.976667')\n",
      "('Epoch: 847/1000', 'Iteration: 4240', 'Validation loss: 0.426738', 'Validation acc: 0.905000')\n",
      "('Epoch: 848/1000', 'Iteration: 4245', 'Train loss: 0.067068', 'Train acc: 0.981667')\n",
      "('Epoch: 849/1000', 'Iteration: 4250', 'Train loss: 0.078226', 'Train acc: 0.983333')\n",
      "('Epoch: 849/1000', 'Iteration: 4250', 'Validation loss: 0.422431', 'Validation acc: 0.908333')\n",
      "('Epoch: 850/1000', 'Iteration: 4255', 'Train loss: 0.063064', 'Train acc: 0.986667')\n",
      "('Epoch: 851/1000', 'Iteration: 4260', 'Train loss: 0.067027', 'Train acc: 0.978333')\n",
      "('Epoch: 851/1000', 'Iteration: 4260', 'Validation loss: 0.431193', 'Validation acc: 0.906667')\n",
      "('Epoch: 852/1000', 'Iteration: 4265', 'Train loss: 0.075913', 'Train acc: 0.973333')\n",
      "('Epoch: 853/1000', 'Iteration: 4270', 'Train loss: 0.076717', 'Train acc: 0.975000')\n",
      "('Epoch: 853/1000', 'Iteration: 4270', 'Validation loss: 0.424824', 'Validation acc: 0.908333')\n",
      "('Epoch: 854/1000', 'Iteration: 4275', 'Train loss: 0.080484', 'Train acc: 0.975000')\n",
      "('Epoch: 855/1000', 'Iteration: 4280', 'Train loss: 0.081272', 'Train acc: 0.978333')\n",
      "('Epoch: 855/1000', 'Iteration: 4280', 'Validation loss: 0.423605', 'Validation acc: 0.908333')\n",
      "('Epoch: 856/1000', 'Iteration: 4285', 'Train loss: 0.078306', 'Train acc: 0.975000')\n",
      "('Epoch: 857/1000', 'Iteration: 4290', 'Train loss: 0.076378', 'Train acc: 0.973333')\n",
      "('Epoch: 857/1000', 'Iteration: 4290', 'Validation loss: 0.423631', 'Validation acc: 0.908333')\n",
      "('Epoch: 858/1000', 'Iteration: 4295', 'Train loss: 0.070326', 'Train acc: 0.976667')\n",
      "('Epoch: 859/1000', 'Iteration: 4300', 'Train loss: 0.060552', 'Train acc: 0.990000')\n",
      "('Epoch: 859/1000', 'Iteration: 4300', 'Validation loss: 0.419860', 'Validation acc: 0.903333')\n",
      "('Epoch: 860/1000', 'Iteration: 4305', 'Train loss: 0.069010', 'Train acc: 0.981667')\n",
      "('Epoch: 861/1000', 'Iteration: 4310', 'Train loss: 0.085671', 'Train acc: 0.973333')\n",
      "('Epoch: 861/1000', 'Iteration: 4310', 'Validation loss: 0.420111', 'Validation acc: 0.906667')\n",
      "('Epoch: 862/1000', 'Iteration: 4315', 'Train loss: 0.066141', 'Train acc: 0.985000')\n",
      "('Epoch: 863/1000', 'Iteration: 4320', 'Train loss: 0.075861', 'Train acc: 0.981667')\n",
      "('Epoch: 863/1000', 'Iteration: 4320', 'Validation loss: 0.425705', 'Validation acc: 0.908333')\n",
      "('Epoch: 864/1000', 'Iteration: 4325', 'Train loss: 0.071857', 'Train acc: 0.983333')\n",
      "('Epoch: 865/1000', 'Iteration: 4330', 'Train loss: 0.075605', 'Train acc: 0.980000')\n",
      "('Epoch: 865/1000', 'Iteration: 4330', 'Validation loss: 0.425316', 'Validation acc: 0.905000')\n",
      "('Epoch: 866/1000', 'Iteration: 4335', 'Train loss: 0.071427', 'Train acc: 0.980000')\n",
      "('Epoch: 867/1000', 'Iteration: 4340', 'Train loss: 0.074695', 'Train acc: 0.978333')\n",
      "('Epoch: 867/1000', 'Iteration: 4340', 'Validation loss: 0.422393', 'Validation acc: 0.910000')\n",
      "('Epoch: 868/1000', 'Iteration: 4345', 'Train loss: 0.064019', 'Train acc: 0.986667')\n",
      "('Epoch: 869/1000', 'Iteration: 4350', 'Train loss: 0.074278', 'Train acc: 0.976667')\n",
      "('Epoch: 869/1000', 'Iteration: 4350', 'Validation loss: 0.427245', 'Validation acc: 0.908333')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 870/1000', 'Iteration: 4355', 'Train loss: 0.063499', 'Train acc: 0.983333')\n",
      "('Epoch: 871/1000', 'Iteration: 4360', 'Train loss: 0.075857', 'Train acc: 0.981667')\n",
      "('Epoch: 871/1000', 'Iteration: 4360', 'Validation loss: 0.423340', 'Validation acc: 0.911667')\n",
      "('Epoch: 872/1000', 'Iteration: 4365', 'Train loss: 0.076479', 'Train acc: 0.983333')\n",
      "('Epoch: 873/1000', 'Iteration: 4370', 'Train loss: 0.068776', 'Train acc: 0.980000')\n",
      "('Epoch: 873/1000', 'Iteration: 4370', 'Validation loss: 0.420535', 'Validation acc: 0.908333')\n",
      "('Epoch: 874/1000', 'Iteration: 4375', 'Train loss: 0.065453', 'Train acc: 0.978333')\n",
      "('Epoch: 875/1000', 'Iteration: 4380', 'Train loss: 0.062546', 'Train acc: 0.983333')\n",
      "('Epoch: 875/1000', 'Iteration: 4380', 'Validation loss: 0.419145', 'Validation acc: 0.905000')\n",
      "('Epoch: 876/1000', 'Iteration: 4385', 'Train loss: 0.073090', 'Train acc: 0.983333')\n",
      "('Epoch: 877/1000', 'Iteration: 4390', 'Train loss: 0.077036', 'Train acc: 0.976667')\n",
      "('Epoch: 877/1000', 'Iteration: 4390', 'Validation loss: 0.424522', 'Validation acc: 0.906667')\n",
      "('Epoch: 878/1000', 'Iteration: 4395', 'Train loss: 0.084110', 'Train acc: 0.966667')\n",
      "('Epoch: 879/1000', 'Iteration: 4400', 'Train loss: 0.060298', 'Train acc: 0.980000')\n",
      "('Epoch: 879/1000', 'Iteration: 4400', 'Validation loss: 0.422112', 'Validation acc: 0.908333')\n",
      "('Epoch: 880/1000', 'Iteration: 4405', 'Train loss: 0.058663', 'Train acc: 0.990000')\n",
      "('Epoch: 881/1000', 'Iteration: 4410', 'Train loss: 0.053679', 'Train acc: 0.993333')\n",
      "('Epoch: 881/1000', 'Iteration: 4410', 'Validation loss: 0.429584', 'Validation acc: 0.911667')\n",
      "('Epoch: 882/1000', 'Iteration: 4415', 'Train loss: 0.069911', 'Train acc: 0.978333')\n",
      "('Epoch: 883/1000', 'Iteration: 4420', 'Train loss: 0.056518', 'Train acc: 0.986667')\n",
      "('Epoch: 883/1000', 'Iteration: 4420', 'Validation loss: 0.430438', 'Validation acc: 0.908333')\n",
      "('Epoch: 884/1000', 'Iteration: 4425', 'Train loss: 0.066800', 'Train acc: 0.980000')\n",
      "('Epoch: 885/1000', 'Iteration: 4430', 'Train loss: 0.069233', 'Train acc: 0.983333')\n",
      "('Epoch: 885/1000', 'Iteration: 4430', 'Validation loss: 0.426950', 'Validation acc: 0.906667')\n",
      "('Epoch: 886/1000', 'Iteration: 4435', 'Train loss: 0.078620', 'Train acc: 0.978333')\n",
      "('Epoch: 887/1000', 'Iteration: 4440', 'Train loss: 0.061863', 'Train acc: 0.983333')\n",
      "('Epoch: 887/1000', 'Iteration: 4440', 'Validation loss: 0.424489', 'Validation acc: 0.905000')\n",
      "('Epoch: 888/1000', 'Iteration: 4445', 'Train loss: 0.059593', 'Train acc: 0.986667')\n",
      "('Epoch: 889/1000', 'Iteration: 4450', 'Train loss: 0.070823', 'Train acc: 0.980000')\n",
      "('Epoch: 889/1000', 'Iteration: 4450', 'Validation loss: 0.424729', 'Validation acc: 0.906667')\n",
      "('Epoch: 890/1000', 'Iteration: 4455', 'Train loss: 0.061971', 'Train acc: 0.980000')\n",
      "('Epoch: 891/1000', 'Iteration: 4460', 'Train loss: 0.067251', 'Train acc: 0.985000')\n",
      "('Epoch: 891/1000', 'Iteration: 4460', 'Validation loss: 0.431146', 'Validation acc: 0.910000')\n",
      "('Epoch: 892/1000', 'Iteration: 4465', 'Train loss: 0.057981', 'Train acc: 0.986667')\n",
      "('Epoch: 893/1000', 'Iteration: 4470', 'Train loss: 0.074066', 'Train acc: 0.980000')\n",
      "('Epoch: 893/1000', 'Iteration: 4470', 'Validation loss: 0.433690', 'Validation acc: 0.905000')\n",
      "('Epoch: 894/1000', 'Iteration: 4475', 'Train loss: 0.057966', 'Train acc: 0.986667')\n",
      "('Epoch: 895/1000', 'Iteration: 4480', 'Train loss: 0.052998', 'Train acc: 0.988333')\n",
      "('Epoch: 895/1000', 'Iteration: 4480', 'Validation loss: 0.429074', 'Validation acc: 0.910000')\n",
      "('Epoch: 896/1000', 'Iteration: 4485', 'Train loss: 0.053628', 'Train acc: 0.986667')\n",
      "('Epoch: 897/1000', 'Iteration: 4490', 'Train loss: 0.058909', 'Train acc: 0.983333')\n",
      "('Epoch: 897/1000', 'Iteration: 4490', 'Validation loss: 0.428197', 'Validation acc: 0.903333')\n",
      "('Epoch: 898/1000', 'Iteration: 4495', 'Train loss: 0.060469', 'Train acc: 0.981667')\n",
      "('Epoch: 899/1000', 'Iteration: 4500', 'Train loss: 0.058093', 'Train acc: 0.986667')\n",
      "('Epoch: 899/1000', 'Iteration: 4500', 'Validation loss: 0.429252', 'Validation acc: 0.905000')\n",
      "('Epoch: 900/1000', 'Iteration: 4505', 'Train loss: 0.058581', 'Train acc: 0.988333')\n",
      "('Epoch: 901/1000', 'Iteration: 4510', 'Train loss: 0.058786', 'Train acc: 0.983333')\n",
      "('Epoch: 901/1000', 'Iteration: 4510', 'Validation loss: 0.427590', 'Validation acc: 0.906667')\n",
      "('Epoch: 902/1000', 'Iteration: 4515', 'Train loss: 0.060211', 'Train acc: 0.985000')\n",
      "('Epoch: 903/1000', 'Iteration: 4520', 'Train loss: 0.053436', 'Train acc: 0.988333')\n",
      "('Epoch: 903/1000', 'Iteration: 4520', 'Validation loss: 0.423784', 'Validation acc: 0.908333')\n",
      "('Epoch: 904/1000', 'Iteration: 4525', 'Train loss: 0.070046', 'Train acc: 0.980000')\n",
      "('Epoch: 905/1000', 'Iteration: 4530', 'Train loss: 0.069965', 'Train acc: 0.980000')\n",
      "('Epoch: 905/1000', 'Iteration: 4530', 'Validation loss: 0.431208', 'Validation acc: 0.908333')\n",
      "('Epoch: 906/1000', 'Iteration: 4535', 'Train loss: 0.061818', 'Train acc: 0.983333')\n",
      "('Epoch: 907/1000', 'Iteration: 4540', 'Train loss: 0.056761', 'Train acc: 0.983333')\n",
      "('Epoch: 907/1000', 'Iteration: 4540', 'Validation loss: 0.427957', 'Validation acc: 0.903333')\n",
      "('Epoch: 908/1000', 'Iteration: 4545', 'Train loss: 0.061568', 'Train acc: 0.981667')\n",
      "('Epoch: 909/1000', 'Iteration: 4550', 'Train loss: 0.064610', 'Train acc: 0.985000')\n",
      "('Epoch: 909/1000', 'Iteration: 4550', 'Validation loss: 0.425314', 'Validation acc: 0.908333')\n",
      "('Epoch: 910/1000', 'Iteration: 4555', 'Train loss: 0.052709', 'Train acc: 0.990000')\n",
      "('Epoch: 911/1000', 'Iteration: 4560', 'Train loss: 0.054485', 'Train acc: 0.988333')\n",
      "('Epoch: 911/1000', 'Iteration: 4560', 'Validation loss: 0.436058', 'Validation acc: 0.910000')\n",
      "('Epoch: 912/1000', 'Iteration: 4565', 'Train loss: 0.063415', 'Train acc: 0.983333')\n",
      "('Epoch: 913/1000', 'Iteration: 4570', 'Train loss: 0.067932', 'Train acc: 0.985000')\n",
      "('Epoch: 913/1000', 'Iteration: 4570', 'Validation loss: 0.420323', 'Validation acc: 0.908333')\n",
      "('Epoch: 914/1000', 'Iteration: 4575', 'Train loss: 0.067904', 'Train acc: 0.976667')\n",
      "('Epoch: 915/1000', 'Iteration: 4580', 'Train loss: 0.059933', 'Train acc: 0.981667')\n",
      "('Epoch: 915/1000', 'Iteration: 4580', 'Validation loss: 0.431306', 'Validation acc: 0.906667')\n",
      "('Epoch: 916/1000', 'Iteration: 4585', 'Train loss: 0.061154', 'Train acc: 0.990000')\n",
      "('Epoch: 917/1000', 'Iteration: 4590', 'Train loss: 0.046895', 'Train acc: 0.988333')\n",
      "('Epoch: 917/1000', 'Iteration: 4590', 'Validation loss: 0.428429', 'Validation acc: 0.908333')\n",
      "('Epoch: 918/1000', 'Iteration: 4595', 'Train loss: 0.068218', 'Train acc: 0.980000')\n",
      "('Epoch: 919/1000', 'Iteration: 4600', 'Train loss: 0.054825', 'Train acc: 0.988333')\n",
      "('Epoch: 919/1000', 'Iteration: 4600', 'Validation loss: 0.422027', 'Validation acc: 0.906667')\n",
      "('Epoch: 920/1000', 'Iteration: 4605', 'Train loss: 0.055716', 'Train acc: 0.990000')\n",
      "('Epoch: 921/1000', 'Iteration: 4610', 'Train loss: 0.061880', 'Train acc: 0.981667')\n",
      "('Epoch: 921/1000', 'Iteration: 4610', 'Validation loss: 0.426242', 'Validation acc: 0.910000')\n",
      "('Epoch: 922/1000', 'Iteration: 4615', 'Train loss: 0.054908', 'Train acc: 0.986667')\n",
      "('Epoch: 923/1000', 'Iteration: 4620', 'Train loss: 0.055043', 'Train acc: 0.986667')\n",
      "('Epoch: 923/1000', 'Iteration: 4620', 'Validation loss: 0.437413', 'Validation acc: 0.905000')\n",
      "('Epoch: 924/1000', 'Iteration: 4625', 'Train loss: 0.059689', 'Train acc: 0.981667')\n",
      "('Epoch: 925/1000', 'Iteration: 4630', 'Train loss: 0.060096', 'Train acc: 0.990000')\n",
      "('Epoch: 925/1000', 'Iteration: 4630', 'Validation loss: 0.427531', 'Validation acc: 0.911667')\n",
      "('Epoch: 926/1000', 'Iteration: 4635', 'Train loss: 0.059133', 'Train acc: 0.990000')\n",
      "('Epoch: 927/1000', 'Iteration: 4640', 'Train loss: 0.062275', 'Train acc: 0.983333')\n",
      "('Epoch: 927/1000', 'Iteration: 4640', 'Validation loss: 0.425883', 'Validation acc: 0.905000')\n",
      "('Epoch: 928/1000', 'Iteration: 4645', 'Train loss: 0.060130', 'Train acc: 0.990000')\n",
      "('Epoch: 929/1000', 'Iteration: 4650', 'Train loss: 0.056262', 'Train acc: 0.985000')\n",
      "('Epoch: 929/1000', 'Iteration: 4650', 'Validation loss: 0.428722', 'Validation acc: 0.906667')\n",
      "('Epoch: 930/1000', 'Iteration: 4655', 'Train loss: 0.057387', 'Train acc: 0.983333')\n",
      "('Epoch: 931/1000', 'Iteration: 4660', 'Train loss: 0.066136', 'Train acc: 0.980000')\n",
      "('Epoch: 931/1000', 'Iteration: 4660', 'Validation loss: 0.428365', 'Validation acc: 0.911667')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 932/1000', 'Iteration: 4665', 'Train loss: 0.069175', 'Train acc: 0.980000')\n",
      "('Epoch: 933/1000', 'Iteration: 4670', 'Train loss: 0.060801', 'Train acc: 0.986667')\n",
      "('Epoch: 933/1000', 'Iteration: 4670', 'Validation loss: 0.434911', 'Validation acc: 0.906667')\n",
      "('Epoch: 934/1000', 'Iteration: 4675', 'Train loss: 0.057967', 'Train acc: 0.988333')\n",
      "('Epoch: 935/1000', 'Iteration: 4680', 'Train loss: 0.061983', 'Train acc: 0.986667')\n",
      "('Epoch: 935/1000', 'Iteration: 4680', 'Validation loss: 0.433776', 'Validation acc: 0.910000')\n",
      "('Epoch: 936/1000', 'Iteration: 4685', 'Train loss: 0.053252', 'Train acc: 0.988333')\n",
      "('Epoch: 937/1000', 'Iteration: 4690', 'Train loss: 0.060521', 'Train acc: 0.980000')\n",
      "('Epoch: 937/1000', 'Iteration: 4690', 'Validation loss: 0.427028', 'Validation acc: 0.903333')\n",
      "('Epoch: 938/1000', 'Iteration: 4695', 'Train loss: 0.051916', 'Train acc: 0.991667')\n",
      "('Epoch: 939/1000', 'Iteration: 4700', 'Train loss: 0.058900', 'Train acc: 0.985000')\n",
      "('Epoch: 939/1000', 'Iteration: 4700', 'Validation loss: 0.424141', 'Validation acc: 0.908333')\n",
      "('Epoch: 940/1000', 'Iteration: 4705', 'Train loss: 0.062137', 'Train acc: 0.988333')\n",
      "('Epoch: 941/1000', 'Iteration: 4710', 'Train loss: 0.051992', 'Train acc: 0.988333')\n",
      "('Epoch: 941/1000', 'Iteration: 4710', 'Validation loss: 0.430317', 'Validation acc: 0.911667')\n",
      "('Epoch: 942/1000', 'Iteration: 4715', 'Train loss: 0.049758', 'Train acc: 0.988333')\n",
      "('Epoch: 943/1000', 'Iteration: 4720', 'Train loss: 0.054725', 'Train acc: 0.986667')\n",
      "('Epoch: 943/1000', 'Iteration: 4720', 'Validation loss: 0.431743', 'Validation acc: 0.905000')\n",
      "('Epoch: 944/1000', 'Iteration: 4725', 'Train loss: 0.065113', 'Train acc: 0.980000')\n",
      "('Epoch: 945/1000', 'Iteration: 4730', 'Train loss: 0.056846', 'Train acc: 0.986667')\n",
      "('Epoch: 945/1000', 'Iteration: 4730', 'Validation loss: 0.430686', 'Validation acc: 0.905000')\n",
      "('Epoch: 946/1000', 'Iteration: 4735', 'Train loss: 0.055275', 'Train acc: 0.990000')\n",
      "('Epoch: 947/1000', 'Iteration: 4740', 'Train loss: 0.056382', 'Train acc: 0.990000')\n",
      "('Epoch: 947/1000', 'Iteration: 4740', 'Validation loss: 0.428099', 'Validation acc: 0.905000')\n",
      "('Epoch: 948/1000', 'Iteration: 4745', 'Train loss: 0.086643', 'Train acc: 0.965000')\n",
      "('Epoch: 949/1000', 'Iteration: 4750', 'Train loss: 0.052413', 'Train acc: 0.988333')\n",
      "('Epoch: 949/1000', 'Iteration: 4750', 'Validation loss: 0.425001', 'Validation acc: 0.911667')\n",
      "('Epoch: 950/1000', 'Iteration: 4755', 'Train loss: 0.048335', 'Train acc: 0.988333')\n",
      "('Epoch: 951/1000', 'Iteration: 4760', 'Train loss: 0.067568', 'Train acc: 0.978333')\n",
      "('Epoch: 951/1000', 'Iteration: 4760', 'Validation loss: 0.433873', 'Validation acc: 0.901667')\n",
      "('Epoch: 952/1000', 'Iteration: 4765', 'Train loss: 0.052970', 'Train acc: 0.986667')\n",
      "('Epoch: 953/1000', 'Iteration: 4770', 'Train loss: 0.053087', 'Train acc: 0.986667')\n",
      "('Epoch: 953/1000', 'Iteration: 4770', 'Validation loss: 0.422744', 'Validation acc: 0.918333')\n",
      "('Epoch: 954/1000', 'Iteration: 4775', 'Train loss: 0.058648', 'Train acc: 0.991667')\n",
      "('Epoch: 955/1000', 'Iteration: 4780', 'Train loss: 0.053796', 'Train acc: 0.981667')\n",
      "('Epoch: 955/1000', 'Iteration: 4780', 'Validation loss: 0.428819', 'Validation acc: 0.906667')\n",
      "('Epoch: 956/1000', 'Iteration: 4785', 'Train loss: 0.054065', 'Train acc: 0.986667')\n",
      "('Epoch: 957/1000', 'Iteration: 4790', 'Train loss: 0.046044', 'Train acc: 0.995000')\n",
      "('Epoch: 957/1000', 'Iteration: 4790', 'Validation loss: 0.429000', 'Validation acc: 0.903333')\n",
      "('Epoch: 958/1000', 'Iteration: 4795', 'Train loss: 0.067647', 'Train acc: 0.976667')\n",
      "('Epoch: 959/1000', 'Iteration: 4800', 'Train loss: 0.054637', 'Train acc: 0.985000')\n",
      "('Epoch: 959/1000', 'Iteration: 4800', 'Validation loss: 0.432401', 'Validation acc: 0.910000')\n",
      "('Epoch: 960/1000', 'Iteration: 4805', 'Train loss: 0.058352', 'Train acc: 0.981667')\n",
      "('Epoch: 961/1000', 'Iteration: 4810', 'Train loss: 0.055085', 'Train acc: 0.981667')\n",
      "('Epoch: 961/1000', 'Iteration: 4810', 'Validation loss: 0.437985', 'Validation acc: 0.906667')\n",
      "('Epoch: 962/1000', 'Iteration: 4815', 'Train loss: 0.066285', 'Train acc: 0.980000')\n",
      "('Epoch: 963/1000', 'Iteration: 4820', 'Train loss: 0.050305', 'Train acc: 0.988333')\n",
      "('Epoch: 963/1000', 'Iteration: 4820', 'Validation loss: 0.432672', 'Validation acc: 0.910000')\n",
      "('Epoch: 964/1000', 'Iteration: 4825', 'Train loss: 0.066542', 'Train acc: 0.981667')\n",
      "('Epoch: 965/1000', 'Iteration: 4830', 'Train loss: 0.053277', 'Train acc: 0.985000')\n",
      "('Epoch: 965/1000', 'Iteration: 4830', 'Validation loss: 0.426176', 'Validation acc: 0.908333')\n",
      "('Epoch: 966/1000', 'Iteration: 4835', 'Train loss: 0.052627', 'Train acc: 0.986667')\n",
      "('Epoch: 967/1000', 'Iteration: 4840', 'Train loss: 0.050593', 'Train acc: 0.990000')\n",
      "('Epoch: 967/1000', 'Iteration: 4840', 'Validation loss: 0.433437', 'Validation acc: 0.906667')\n",
      "('Epoch: 968/1000', 'Iteration: 4845', 'Train loss: 0.050886', 'Train acc: 0.988333')\n",
      "('Epoch: 969/1000', 'Iteration: 4850', 'Train loss: 0.066029', 'Train acc: 0.981667')\n",
      "('Epoch: 969/1000', 'Iteration: 4850', 'Validation loss: 0.426704', 'Validation acc: 0.911667')\n",
      "('Epoch: 970/1000', 'Iteration: 4855', 'Train loss: 0.052232', 'Train acc: 0.983333')\n",
      "('Epoch: 971/1000', 'Iteration: 4860', 'Train loss: 0.064022', 'Train acc: 0.980000')\n",
      "('Epoch: 971/1000', 'Iteration: 4860', 'Validation loss: 0.438240', 'Validation acc: 0.908333')\n",
      "('Epoch: 972/1000', 'Iteration: 4865', 'Train loss: 0.050683', 'Train acc: 0.988333')\n",
      "('Epoch: 973/1000', 'Iteration: 4870', 'Train loss: 0.055238', 'Train acc: 0.983333')\n",
      "('Epoch: 973/1000', 'Iteration: 4870', 'Validation loss: 0.426454', 'Validation acc: 0.910000')\n",
      "('Epoch: 974/1000', 'Iteration: 4875', 'Train loss: 0.067407', 'Train acc: 0.978333')\n",
      "('Epoch: 975/1000', 'Iteration: 4880', 'Train loss: 0.047634', 'Train acc: 0.988333')\n",
      "('Epoch: 975/1000', 'Iteration: 4880', 'Validation loss: 0.428832', 'Validation acc: 0.911667')\n",
      "('Epoch: 976/1000', 'Iteration: 4885', 'Train loss: 0.054144', 'Train acc: 0.983333')\n",
      "('Epoch: 977/1000', 'Iteration: 4890', 'Train loss: 0.054988', 'Train acc: 0.986667')\n",
      "('Epoch: 977/1000', 'Iteration: 4890', 'Validation loss: 0.421191', 'Validation acc: 0.908333')\n",
      "('Epoch: 978/1000', 'Iteration: 4895', 'Train loss: 0.058093', 'Train acc: 0.985000')\n",
      "('Epoch: 979/1000', 'Iteration: 4900', 'Train loss: 0.051775', 'Train acc: 0.986667')\n",
      "('Epoch: 979/1000', 'Iteration: 4900', 'Validation loss: 0.433712', 'Validation acc: 0.908333')\n",
      "('Epoch: 980/1000', 'Iteration: 4905', 'Train loss: 0.056202', 'Train acc: 0.981667')\n",
      "('Epoch: 981/1000', 'Iteration: 4910', 'Train loss: 0.048469', 'Train acc: 0.995000')\n",
      "('Epoch: 981/1000', 'Iteration: 4910', 'Validation loss: 0.428328', 'Validation acc: 0.910000')\n",
      "('Epoch: 982/1000', 'Iteration: 4915', 'Train loss: 0.065336', 'Train acc: 0.981667')\n",
      "('Epoch: 983/1000', 'Iteration: 4920', 'Train loss: 0.054910', 'Train acc: 0.985000')\n",
      "('Epoch: 983/1000', 'Iteration: 4920', 'Validation loss: 0.426806', 'Validation acc: 0.911667')\n",
      "('Epoch: 984/1000', 'Iteration: 4925', 'Train loss: 0.054508', 'Train acc: 0.986667')\n",
      "('Epoch: 985/1000', 'Iteration: 4930', 'Train loss: 0.059124', 'Train acc: 0.985000')\n",
      "('Epoch: 985/1000', 'Iteration: 4930', 'Validation loss: 0.434336', 'Validation acc: 0.911667')\n",
      "('Epoch: 986/1000', 'Iteration: 4935', 'Train loss: 0.051991', 'Train acc: 0.986667')\n",
      "('Epoch: 987/1000', 'Iteration: 4940', 'Train loss: 0.053309', 'Train acc: 0.990000')\n",
      "('Epoch: 987/1000', 'Iteration: 4940', 'Validation loss: 0.429211', 'Validation acc: 0.905000')\n",
      "('Epoch: 988/1000', 'Iteration: 4945', 'Train loss: 0.050981', 'Train acc: 0.990000')\n",
      "('Epoch: 989/1000', 'Iteration: 4950', 'Train loss: 0.059374', 'Train acc: 0.976667')\n",
      "('Epoch: 989/1000', 'Iteration: 4950', 'Validation loss: 0.430037', 'Validation acc: 0.908333')\n",
      "('Epoch: 990/1000', 'Iteration: 4955', 'Train loss: 0.051650', 'Train acc: 0.986667')\n",
      "('Epoch: 991/1000', 'Iteration: 4960', 'Train loss: 0.048533', 'Train acc: 0.990000')\n",
      "('Epoch: 991/1000', 'Iteration: 4960', 'Validation loss: 0.429392', 'Validation acc: 0.908333')\n",
      "('Epoch: 992/1000', 'Iteration: 4965', 'Train loss: 0.051981', 'Train acc: 0.990000')\n",
      "('Epoch: 993/1000', 'Iteration: 4970', 'Train loss: 0.040199', 'Train acc: 0.991667')\n",
      "('Epoch: 993/1000', 'Iteration: 4970', 'Validation loss: 0.430684', 'Validation acc: 0.906667')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 994/1000', 'Iteration: 4975', 'Train loss: 0.060409', 'Train acc: 0.985000')\n",
      "('Epoch: 995/1000', 'Iteration: 4980', 'Train loss: 0.053200', 'Train acc: 0.981667')\n",
      "('Epoch: 995/1000', 'Iteration: 4980', 'Validation loss: 0.434322', 'Validation acc: 0.906667')\n",
      "('Epoch: 996/1000', 'Iteration: 4985', 'Train loss: 0.049375', 'Train acc: 0.985000')\n",
      "('Epoch: 997/1000', 'Iteration: 4990', 'Train loss: 0.048639', 'Train acc: 0.983333')\n",
      "('Epoch: 997/1000', 'Iteration: 4990', 'Validation loss: 0.435820', 'Validation acc: 0.910000')\n",
      "('Epoch: 998/1000', 'Iteration: 4995', 'Train loss: 0.046673', 'Train acc: 0.986667')\n",
      "('Epoch: 999/1000', 'Iteration: 5000', 'Train loss: 0.053669', 'Train acc: 0.988333')\n",
      "('Epoch: 999/1000', 'Iteration: 5000', 'Validation loss: 0.427848', 'Validation acc: 0.905000')\n"
     ]
    }
   ],
   "source": [
    "validation_acc = []\n",
    "validation_loss = []\n",
    "\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "   \n",
    "    # Loop over epochs\n",
    "    for e in range(epochs):\n",
    "        \n",
    "        # Loop over batches\n",
    "        for x,y in get_batches(X_tr, y_tr, batch_size):\n",
    "            \n",
    "            # Feed dictionary\n",
    "            feed = {inputs_ : x, labels_ : y, keep_prob_ : 0.5, learning_rate_ : learning_rate}\n",
    "            \n",
    "            # Loss\n",
    "            loss, _ , acc = sess.run([cost, optimizer, accuracy], feed_dict = feed)\n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss)\n",
    "            \n",
    "            # Print at each 5 iters\n",
    "            if (iteration % 5 == 0):\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Train loss: {:6f}\".format(loss),\n",
    "                      \"Train acc: {:.6f}\".format(acc))\n",
    "            \n",
    "            # Compute validation loss at every 10 iterations\n",
    "            if (iteration%10 == 0):                \n",
    "                val_acc_ = []\n",
    "                val_loss_ = []\n",
    "                \n",
    "                for x_v, y_v in get_batches(X_vld, y_vld, batch_size):\n",
    "                    # Feed\n",
    "                    feed = {inputs_ : x_v, labels_ : y_v, keep_prob_ : 1.0}  \n",
    "                    \n",
    "                    # Loss\n",
    "                    loss_v, acc_v = sess.run([cost, accuracy], feed_dict = feed)                    \n",
    "                    val_acc_.append(acc_v)\n",
    "                    val_loss_.append(loss_v)\n",
    "                \n",
    "                # Print info\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Validation loss: {:6f}\".format(np.mean(val_loss_)),\n",
    "                      \"Validation acc: {:.6f}\".format(np.mean(val_acc_)))\n",
    "                \n",
    "                # Store\n",
    "                validation_acc.append(np.mean(val_acc_))\n",
    "                validation_loss.append(np.mean(val_loss_))\n",
    "            \n",
    "            # Iterate \n",
    "            iteration += 1\n",
    "    \n",
    "    saver.save(sess,\"checkpoints-cnn/har.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAF3CAYAAABKeVdaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIrWUFEREpJaSgoiI1FJSEBGRWv8f7rySZTPXUDUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbdb55e2f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and test loss\n",
    "t = np.arange(iteration-1)\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.plot(t, np.array(train_loss), 'r-', t[t % 10 == 0], np.array(validation_loss), 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAF3CAYAAABKeVdaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nawAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbdbb9e3fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Accuracies\n",
    "plt.figure(figsize = (6,6))\n",
    "\n",
    "plt.plot(t, np.array(train_acc), 'r-', t[t % 10 == 0], validation_acc, 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Accuray\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints-cnn/har.ckpt\n",
      "Test accuracy: 0.765000\n",
      "(array([ 0.8       ,  1.        ,  0.9375    ,  0.93333333,  1.        ,\n",
      "        0.86315789,  0.8       ,  0.77419355,  0.3358209 ,  0.41221374,\n",
      "        0.94117647,  0.91525424,  0.35714286,  0.88235294,  0.86486486,\n",
      "        0.87804878,  1.        ,  0.94736842]), array([ 1.        ,  0.95238095,  1.        ,  1.        ,  0.86725664,\n",
      "        1.        ,  0.85714286,  0.75      ,  0.9375    ,  1.        ,\n",
      "        0.88888889,  0.9       ,  0.14285714,  0.13513514,  0.88888889,\n",
      "        0.70588235,  0.625     ,  1.        ]), array([ 0.88888889,  0.97560976,  0.96774194,  0.96551724,  0.92890995,\n",
      "        0.92655367,  0.82758621,  0.76190476,  0.49450549,  0.58378378,\n",
      "        0.91428571,  0.90756303,  0.20408163,  0.234375  ,  0.87671233,\n",
      "        0.7826087 ,  0.76923077,  0.97297297]), array([ 60,  63,  45,  42, 113,  82,  70,  32,  48,  54,  54,  60, 105,\n",
      "       111, 108,  51,  48,  54]))\n",
      "Accuracy: 0.765\n",
      "F1 score: 0.765\n",
      "Recall: 0.765\n",
      "Precision: 0.765\n",
      "\n",
      " clasification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89        60\n",
      "          1       1.00      0.95      0.98        63\n",
      "          2       0.94      1.00      0.97        45\n",
      "          3       0.93      1.00      0.97        42\n",
      "          4       1.00      0.87      0.93       113\n",
      "          5       0.86      1.00      0.93        82\n",
      "          6       0.80      0.86      0.83        70\n",
      "          7       0.77      0.75      0.76        32\n",
      "          8       0.34      0.94      0.49        48\n",
      "          9       0.41      1.00      0.58        54\n",
      "         10       0.94      0.89      0.91        54\n",
      "         11       0.92      0.90      0.91        60\n",
      "         12       0.36      0.14      0.20       105\n",
      "         13       0.88      0.14      0.23       111\n",
      "         14       0.86      0.89      0.88       108\n",
      "         15       0.88      0.71      0.78        51\n",
      "         16       1.00      0.62      0.77        48\n",
      "         17       0.95      1.00      0.97        54\n",
      "\n",
      "avg / total       0.81      0.77      0.74      1200\n",
      "\n",
      "\n",
      " confussion matrix:\n",
      "[[60  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 60  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 45  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  3 98 10  0  0  0  0  0  0  0  0  0  2  0  0]\n",
      " [ 0  0  0  0  0 82  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 60  4  2  0  0  2  0  2  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 24  0  8  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 45  0  0  0  0  0  3  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 54  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  3 48  0  0  0  3  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 54  0  0  6  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 87  0  0  0 15  0  3  0  0  0]\n",
      " [15  0  0  0  0  0  0  0  0 54  0  0 27 15  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 12  0  0  0  0 96  0  0  0]\n",
      " [ 0  0  0  0  0  3  0  3  0  0  3  3  0  0  0 36  0  3]\n",
      " [ 0  0  0  0  0  0 15  0  0  0  0  0  0  0  0  3 30  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 54]]\n"
     ]
    }
   ],
   "source": [
    "test_acc = []\n",
    "with graph.as_default():\n",
    "    prediction=tf.argmax(logits,1)\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Restore\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints-cnn'))\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for x_t, y_t in get_batches(X_test, y_test, batch_size):\n",
    "        feed = {inputs_: x_t,\n",
    "                labels_: y_t,\n",
    "                keep_prob_: 1}\n",
    "        batch_acc, batch_y_pred = sess.run([accuracy, prediction], feed_dict=feed)\n",
    "        y_pred.extend(batch_y_pred)\n",
    "        y_true.extend(np.where(r==1)[0][0] for r in y_t )\n",
    "        \n",
    "        test_acc.append(batch_acc)\n",
    "    print(\"Test accuracy: {:.6f}\".format(np.mean(test_acc)))\n",
    "#     print y_true\n",
    "#     print y_pred\n",
    "    sk_class_labels = [i for i in range(NUM_CLASS)]\n",
    "    print precision_recall_fscore_support(y_true, y_pred, average=None, labels=sk_class_labels)\n",
    "    print 'Accuracy:', accuracy_score(y_true, y_pred)\n",
    "    print 'F1 score:', f1_score(y_true, y_pred, average='micro')\n",
    "    print 'Recall:', recall_score(y_true, y_pred, average='micro')\n",
    "    print 'Precision:', precision_score(y_true, y_pred, average='micro')\n",
    "    print '\\n clasification report:\\n', classification_report(y_true,y_pred)\n",
    "    print '\\n confussion matrix:\\n',confusion_matrix(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
