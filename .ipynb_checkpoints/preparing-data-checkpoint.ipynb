{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Non-ASCII character '\\xe1' in file /home/tuyenlv17/data/learning/school/diploma/code/UCI-HAR/deep-learning-HAR/utils/utilities.py on line 15, but no encoding declared; see http://python.org/dev/peps/pep-0263/ for details (utilities.py, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/home/tuyenlv17/data/learning/school/diploma/code/UCI-HAR/deep-learning-HAR/utils/utilities.py\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    # class_label_vn = [u\"Cổ tay\",u\"Cổ chân\",u\"Bả vai\",u\"Xoay người\",u\"Xoay đầu gối\",u\"Đi bộ\",u\"Chạy\",u\"Đá bóng\",u\"Đạp\",u\"Đánh răng\",u\"Rửa tay\",u\"Lau bàn\",u\"Quét nhà\",u\"Nạo\",u\"Thái\",u\"Trộn\",u\"Lên cầu thang\",u\"Xuống cầu thang\"]\u001b[0m\n\u001b[0m                                                                                                                                                                                                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Non-ASCII character '\\xe1' in file /home/tuyenlv17/data/learning/school/diploma/code/UCI-HAR/deep-learning-HAR/utils/utilities.py on line 15, but no encoding declared; see http://python.org/dev/peps/pep-0263/ for details\n"
     ]
    }
   ],
   "source": [
    "%run utils/utilities.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_label_vn = [u\"Cổ tay\",u\"Cổ chân\",u\"Bả vai\",u\"Xoay người\",u\"Xoay đầu gối\",u\"Đi bộ\",u\"Chạy\",u\"Đá bóng\",u\"Đạp xe\",u\"Đánh răng\",u\"Rửa tay\",u\"Lau bàn\",u\"Quét nhà\",u\"Nạo\",u\"Thái\",u\"Trộn\",u\"Lên cầu thang\",u\"Xuống cầu thang\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATASET_ROOT = './datasets/PTIT'\n",
    "DATASET_NORM = DATASET_ROOT + '/normalized'\n",
    "DATASET_TRAIN = DATASET_NORM + '/train'\n",
    "DATASET_TEST = DATASET_NORM + '/test'\n",
    "WINDONW_OVERLAP = 0.5\n",
    "WINDOWN_OVERLAP_SIZE = WINDONW_OVERLAP * WINDOWN_SIZE\n",
    "ANNO_FILE = 'anno.eaf'\n",
    "WAX3_FILE = 'wax3.csv'\n",
    "GEARS2_FILE = 'gears2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_window_cnt = {}\n",
    "test_window_cnt = {}\n",
    "total_window = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getAnno(anno_path):\n",
    "    timestamp = {}\n",
    "    annotation = []\n",
    "    time_range = []\n",
    "    root_ele = xml.etree.ElementTree.parse(anno_path).getroot()\n",
    "    for time_slot in root_ele.iter('TIME_SLOT'):\n",
    "        att = time_slot.attrib\n",
    "        timestamp[att['TIME_SLOT_ID']]  = att['TIME_VALUE']\n",
    "    for anno in root_ele.find('TIER').iter('ANNOTATION'):\n",
    "        alig_anno = anno.find('ALIGNABLE_ANNOTATION')\n",
    "        anno_text = alig_anno.find('ANNOTATION_VALUE').text.strip()\n",
    "        startTs = timestamp[alig_anno.attrib['TIME_SLOT_REF1']]\n",
    "        endTs = timestamp[alig_anno.attrib['TIME_SLOT_REF2']]\n",
    "#         annotation[anno_text] = {'start': startTs, 'end': endTs}\n",
    "        annotation.append(anno_text)\n",
    "        time_range.append({'start': int(startTs), 'end': int(endTs)})\n",
    "    return annotation, time_range\n",
    "\n",
    "def getMilisecond(s):\n",
    "    try:\n",
    "        hours, minutes, seconds = ([\"0\", \"0\"] + s.split(\":\"))[-3:]\n",
    "        hours = int(hours)\n",
    "        minutes = int(minutes)\n",
    "        seconds = float(seconds)\n",
    "        miliseconds = int(3600000 * hours + 60000 * minutes + 1000 * seconds)\n",
    "        return miliseconds\n",
    "    except:\n",
    "#         print \"format exception \" + s\n",
    "        return 0\n",
    "\n",
    "def getTotalWindowSize(len):\n",
    "    total_size = (len // WINDOWN_SIZE) * 2 - 1 + (len % WINDOWN_SIZE) // WINDOWN_OVERLAP_SIZE\n",
    "    return int(total_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def exportData(dir_path, target_path, is_training=True):\n",
    "    global total_window\n",
    "    anno_file = dir_path + '/' + ANNO_FILE\n",
    "    sensor_data_path = target_path + '/sensor'\n",
    "    x_watch_acc_file = sensor_data_path + '/x_watch_acc.txt'\n",
    "    y_watch_acc_file = sensor_data_path + '/y_watch_acc.txt'\n",
    "    z_watch_acc_file = sensor_data_path + '/z_watch_acc.txt'\n",
    "    x_watch_gyr_file = sensor_data_path + '/x_watch_gyr.txt'\n",
    "    y_watch_gyr_file = sensor_data_path + '/y_watch_gyr.txt'\n",
    "    z_watch_gyr_file = sensor_data_path + '/z_watch_gyr.txt'\n",
    "    x_sensor_acc_file = sensor_data_path + '/x_sensor_acc.txt'\n",
    "    y_sensor_acc_file = sensor_data_path + '/y_sensor_acc.txt'\n",
    "    z_sensor_acc_file = sensor_data_path + '/z_sensor_acc.txt'\n",
    "    class_file = target_path + '/class.txt'\n",
    "    annotation, time_range = getAnno(anno_file)\n",
    "    num_anno = len(annotation)\n",
    "    gears2_data = [[] for anno in annotation];\n",
    "    wax3_data = [[] for anno in annotation];\n",
    "    start_annotation = 0\n",
    "    wax3_file = dir_path + '/' + WAX3_FILE\n",
    "    gears2_file = dir_path + '/' + GEARS2_FILE\n",
    "    with open(gears2_file, 'r') as gears2_csv, open(wax3_file, 'r') as wax3_csv:\n",
    "        gears2_csv_reader = csv.reader(gears2_csv, delimiter=',')\n",
    "        wax3_csv_reader = csv.reader(wax3_csv, delimiter=',')\n",
    "        for row in gears2_csv_reader:\n",
    "            ts = getMilisecond(row[0].strip())\n",
    "            for i in range(num_anno):\n",
    "                if ts >= time_range[i]['start'] and ts < time_range[i]['end']:\n",
    "                    x_acc = float(row[1].strip())\n",
    "                    y_acc = float(row[2].strip())\n",
    "                    z_acc = float(row[3].strip())\n",
    "                    x_gyr = float(row[4].strip())\n",
    "                    y_gyr = float(row[5].strip())\n",
    "                    z_gyr = float(row[6].strip())\n",
    "                    gears2_data[i].append([ts, x_acc, y_acc, z_acc, x_gyr, y_gyr, z_gyr])\n",
    "                    \n",
    "        for row in wax3_csv_reader:\n",
    "            ts = getMilisecond(row[0].strip())\n",
    "            for i in range(num_anno):\n",
    "                if ts >= time_range[i]['start'] and ts < time_range[i]['end']:\n",
    "                    x_acc = float(row[1].strip())\n",
    "                    y_acc = float(row[2].strip())\n",
    "                    z_acc = float(row[3].strip())\n",
    "                    wax3_data[i].append([ts, x_acc, y_acc, z_acc])\n",
    "         \n",
    "    for i in range(num_anno):\n",
    "        num_windows = getTotalWindowSize(len(gears2_data[i]))\n",
    "        startWindow = 0\n",
    "#         print num_windows\n",
    "        for j in range(num_windows):\n",
    "            windowSliced = gears2_data[i][startWindow:startWindow+WINDOWN_SIZE]\n",
    "            if(len(windowSliced) < WINDOWN_SIZE):\n",
    "                break\n",
    "            startWindow += WINDOWN_SIZE\n",
    "            startTs = windowSliced[0][0]\n",
    "            endTs = windowSliced[WINDOWN_SIZE - 1][0]\n",
    "            equivWax3Data = []\n",
    "            # get data from wax3 and group with gears2\n",
    "            for k in range(len(wax3_data[i])):\n",
    "                wax3Ts = wax3_data[i][k][0]\n",
    "                if(wax3Ts > endTs):\n",
    "                    break\n",
    "                if wax3Ts >= startTs and wax3Ts <= endTs:\n",
    "                    equivWax3Data.append(wax3_data[i][k])\n",
    "            zero_arr = [0 for zit in range(WINDOWN_SIZE)]\n",
    "            while len(equivWax3Data) < WINDOWN_SIZE:\n",
    "                equivWax3Data.append(zero_arr);\n",
    "            equivWax3Data = equivWax3Data[0:WINDOWN_SIZE]\n",
    "#             print (startTs, endTs, len(windowSliced), len(equivWax3Data))\n",
    "            #export windows to file\n",
    "            x_watch_acc = y_watch_acc = z_watch_acc = \"\";\n",
    "            x_watch_gyr = y_watch_gyr = z_watch_gyr = \"\";\n",
    "            x_sensor_acc = y_sensor_acc = z_sensor_acc = \"\";\n",
    "#             if len(windowSliced) > 150 or len(equivWax3Data) > 150:\n",
    "#                 print(i, j, len(windowSliced), len(equivWax3Data))\n",
    "            for k in range(WINDOWN_SIZE):\n",
    "                x_watch_acc = x_watch_acc + \" \" + str(windowSliced[k][1])\n",
    "                y_watch_acc = y_watch_acc + \" \" + str(windowSliced[k][2])\n",
    "                z_watch_acc = z_watch_acc + \" \" + str(windowSliced[k][3])\n",
    "                \n",
    "                x_watch_gyr = x_watch_gyr + \" \" + str(windowSliced[k][4])\n",
    "                y_watch_gyr = y_watch_gyr + \" \" + str(windowSliced[k][5])\n",
    "                z_watch_gyr = z_watch_gyr + \" \" + str(windowSliced[k][6])\n",
    "                \n",
    "                x_sensor_acc = x_sensor_acc + \" \" + str(equivWax3Data[k][1])\n",
    "                y_sensor_acc = y_sensor_acc + \" \" + str(equivWax3Data[k][2])\n",
    "                z_sensor_acc = z_sensor_acc + \" \" + str(equivWax3Data[k][3])\n",
    "                \n",
    "\n",
    "            with open(x_watch_acc_file, \"a\") as fw:\n",
    "                fw.write(x_watch_acc + \"\\n\")\n",
    "            with open(y_watch_acc_file, \"a\") as fw:\n",
    "                fw.write(y_watch_acc + \"\\n\")\n",
    "            with open(z_watch_acc_file, \"a\") as fw:\n",
    "                fw.write(z_watch_acc + \"\\n\")\n",
    "                \n",
    "            with open(x_watch_gyr_file, \"a\") as fw:\n",
    "                fw.write(x_watch_gyr + \"\\n\")\n",
    "            with open(y_watch_gyr_file, \"a\") as fw:\n",
    "                fw.write(y_watch_gyr + \"\\n\")\n",
    "            with open(z_watch_gyr_file, \"a\") as fw:\n",
    "                fw.write(z_watch_gyr + \"\\n\")\n",
    "                \n",
    "            with open(x_sensor_acc_file, \"a\") as fw:\n",
    "                fw.write(x_sensor_acc + \"\\n\")\n",
    "            with open(y_sensor_acc_file, \"a\") as fw:\n",
    "                fw.write(y_sensor_acc + \"\\n\")\n",
    "            with open(z_sensor_acc_file, \"a\") as fw:\n",
    "                fw.write(z_sensor_acc + \"\\n\")\n",
    "            with open(class_file, \"a\") as fw:\n",
    "                fw.write(str(class_label_int[annotation[i]]) + \"\\n\")\n",
    "        train_window_cnt[class_label_vn[int(class_label_int[annotation[i]])]]+=num_windows\n",
    "        total_window+=num_windows;\n",
    "#     return wax3_data\n",
    "        \n",
    "# exportData('./datasets/PTIT/001/in/', DATASET_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prepareTrainTestFile(trainDir, testDir, name=\"default\"):\n",
    "    for dirPath in trainDir:\n",
    "        print dirPath\n",
    "        exportData(DATASET_ROOT + '/' + dirPath + '/in', DATASET_TRAIN, True)\n",
    "        exportData(DATASET_ROOT + '/' + dirPath + '/out', DATASET_TRAIN, True)\n",
    "    for dir in testDir:\n",
    "        print dir\n",
    "        exportData(DATASET_ROOT + '/' + dirPath + '/in', DATASET_TEST, False)\n",
    "        exportData(DATASET_ROOT + '/' + dirPath + '/out', DATASET_TEST, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def prepareTempTrainTestFormat():\n",
    "    global train_window_cnt\n",
    "    global test_window_cnt\n",
    "    global total_train_window\n",
    "    trainDir = [\"001\", \"002\", \"003\", \"004\", \"005\", \"006\", \"007\", \"008\", \"009\"]\n",
    "    testDir = [\"010\", \"011\", \"012\", \"013\"]\n",
    "    total_train_window = 0\n",
    "    train_window_cnt = dict.fromkeys(class_label_vn, 0)\n",
    "    test_window_cnt = dict.fromkeys(class_label_vn, 0)\n",
    "    prepareTrainTestFile(trainDir, testDir)\n",
    "    print (\"training window count \", train_window_cnt)\n",
    "    print (\"test window count \", test_window_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def randomTrainFile():\n",
    "    records = None\n",
    "    random_dir = DATASET_NORM + \"_random/train\"\n",
    "    files = [DATASET_TRAIN + \"/\" + \"class.txt\"]\n",
    "    files_random  = [random_dir + \"/\" + \"class.txt\"]\n",
    "    for channel in CHANNEL_LIST:\n",
    "        filePath = DATASET_TRAIN + \"/sensor/\" + channel + \".txt\"\n",
    "        files.append(filePath)\n",
    "        files_random.append(random_dir + \"/sensor/\" + channel + \".txt\")\n",
    "    for file in files:\n",
    "        print \"read file \" + file\n",
    "        with open(file) as f:\n",
    "            lines = f.readlines()\n",
    "            lines = [line.strip() for line in lines]\n",
    "            if records == None:\n",
    "                print \"create records\"\n",
    "                records = [[] for _ in range(len(lines))]\n",
    "            for idx, line in enumerate(lines):\n",
    "                records[idx].append(line)\n",
    "#                 print (idx, line, records[idx][0])\n",
    "#             return\n",
    "    print \"record len %d\" % len(records)\n",
    "    shuffle(records)\n",
    "    total10 = total0 = 0;\n",
    "    for file_idx, file in enumerate(files_random):\n",
    "        print \"write file \" + file\n",
    "        with open(file, \"a\") as wf:\n",
    "            for record in records:\n",
    "#                 print record[file_idx]\n",
    "                wf.write(record[file_idx] + \"\\n\")\n",
    "    print(total0, total10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001\n",
      "002\n",
      "003\n",
      "004\n"
     ]
    }
   ],
   "source": [
    "!rm -rf datasets/PTIT/normalized*\n",
    "#!mkdir -p datasets/PTIT/normalized/{train,test}/sensor\n",
    "!mkdir -p datasets/PTIT/normalized/train/sensor\n",
    "!mkdir -p datasets/PTIT/normalized/test/sensor\n",
    "!mkdir -p datasets/PTIT/normalized_random/train/sensor\n",
    "!mkdir -p datasets/PTIT/normalized_random/test/sensor\n",
    "prepareTempTrainTestFormat()\n",
    "randomTrainFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots() \n",
    "\n",
    "# Get current size\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 20\n",
    "fig_size[1] = 10\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "newlist = train_window_cnt\n",
    "print [val[1] for val in newlist]\n",
    "ax.set_title(u\"Số lượng của sổ mỗi hành động\")\n",
    "ax.set_xlabel(u\"Hành động\", fontsize=20)\n",
    "ax.set_ylabel(u\"Số ô cửa số\", fontsize=20)\n",
    "plt.bar(range(len(newlist)), list(newlist.values()), align='center')\n",
    "plt.xticks(range(len(newlist)), list(newlist.keys()), rotation=70, fontsize=20)\n",
    "\n",
    "# plt.bar(range(len(top20)), [val[1] for val in top20], align='center')\n",
    "# plt.xticks(range(len(top20)), [val[0] for val in top20])\n",
    "# plt.xticks(rotation=70)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = list(train_window_cnt.keys())\n",
    "y = list(train_window_cnt.values())\n",
    "plt.bar(x, y)\n",
    "for a,b in zip(x, y):\n",
    "    plt.text(a, b, str(b))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
